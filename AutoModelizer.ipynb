{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoModelizer\n",
    "---\n",
    "\n",
    "La idea de este proyecto es encontrar el mejor modelo de CNN que se adapte al dataset correspondiente, para ello usando algoritmos evolutivos. Este tipo de soluciones se conocen como neuroevoluciones\n",
    "\n",
    "A continuación un ejemplo básico de como funcionan este tipo de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def fitness(x):\n",
    "    return x ** 2\n",
    "\n",
    "population_size = 10\n",
    "population = np.random.uniform(-10, 10, population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parent_tournament(population, scores, k=3):\n",
    "    selection_ix = np.random.randint(len(population), size=k)\n",
    "    selected = population[selection_ix]\n",
    "    ix = np.argmax(scores[selection_ix])\n",
    "    return selected[ix]\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    child = (p1 + p2) / 2\n",
    "    return child\n",
    "\n",
    "def mutate(x):\n",
    "    mutation_chance = 0.1\n",
    "    if np.random.rand() < mutation_chance:\n",
    "        x += np.random.uniform(-1, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 0, x = -9.001734441583004 Mejor puntuación 95.16401276872769\n",
      "Generación 1, x = -8.640179586999352 Mejor puntuación 85.21707341903098\n",
      "Generación 2, x = -9.116521925679828 Mejor puntuación 85.21707341903098\n",
      "Generación 3, x = -9.862386487780679 Mejor puntuación 97.52195724624808\n",
      "Generación 4, x = -9.606629541695465 Mejor puntuación 98.35796302680987\n",
      "Generación 5, x = -9.860328975381039 Mejor puntuación 98.35796302680987\n",
      "Generación 6, x = -10.673578261068279 Mejor puntuación 115.26228863097212\n",
      "Generación 7, x = -10.61112892199636 Mejor puntuación 113.92527289514935\n",
      "Generación 8, x = -10.64235359153232 Mejor puntuación 113.25968996720087\n",
      "Generación 9, x = -10.981532148251194 Mejor puntuación 120.59404832307449\n",
      "Generación 10, x = -10.811942869891757 Mejor puntuación 120.59404832307449\n",
      "Generación 11, x = -10.939134828661334 Mejor puntuación 136.67665899820378\n",
      "Generación 12, x = -10.981532148251194 Mejor puntuación 128.50956031231783\n",
      "Generación 13, x = -11.315007068415802 Mejor puntuación 128.02938495829957\n",
      "Generación 14, x = -11.275972535869592 Mejor puntuación 128.02938495829957\n",
      "Generación 15, x = -11.661156074644797 Mejor puntuación 144.17537530517757\n",
      "Generación 16, x = -11.641638808371692 Mejor puntuación 135.98256099722525\n",
      "Generación 17, x = -11.94352841533616 Mejor puntuación 149.71136068763903\n",
      "Generación 18, x = -11.780385320433236 Mejor puntuación 154.78546991810802\n",
      "Generación 19, x = -12.192404647327571 Mejor puntuación 148.65473108417495\n",
      "Generación 20, x = -12.192404647327571 Mejor puntuación 169.68186048627035\n",
      "Generación 21, x = -12.961102377419651 Mejor puntuación 167.99017483795333\n",
      "Generación 22, x = -12.924734548067025 Mejor puntuación 167.99017483795333\n",
      "Generación 23, x = -12.952010420081496 Mejor puntuación 167.99017483795333\n",
      "Generación 24, x = -12.93837248407426 Mejor puntuación 194.09633689730563\n",
      "Generación 25, x = -13.585954682611638 Mejor puntuación 180.68543589959148\n",
      "Generación 26, x = -13.441928280555267 Mejor puntuación 184.57816463797707\n",
      "Generación 27, x = -13.441928280555267 Mejor puntuación 184.57816463797707\n",
      "Generación 28, x = -13.513941481583451 Mejor puntuación 184.57816463797707\n",
      "Generación 29, x = -13.56997315893534 Mejor puntuación 198.28741989683652\n",
      "Generación 30, x = -13.345327377597016 Mejor puntuación 191.37141173058413\n",
      "Generación 31, x = -13.833705639870473 Mejor puntuación 191.37141173058413\n",
      "Generación 32, x = -13.831960671483529 Mejor puntuación 191.37141173058413\n",
      "Generación 33, x = -13.833705639870473 Mejor puntuación 191.37141173058413\n",
      "Generación 34, x = -13.833269397773737 Mejor puntuación 191.37141173058413\n",
      "Generación 35, x = -14.033766151886915 Mejor puntuación 213.39538261786447\n",
      "Generación 36, x = -14.127269661755262 Mejor puntuación 213.39538261786447\n",
      "Generación 37, x = -14.511237411224737 Mejor puntuación 213.39538261786447\n",
      "Generación 38, x = -14.514555314556768 Mejor puntuación 216.81413760771605\n",
      "Generación 39, x = -14.514555314556768 Mejor puntuación 216.81413760771605\n",
      "Generación 40, x = -14.672096276573706 Mejor puntuación 216.81413760771605\n",
      "Generación 41, x = -14.61958262256806 Mejor puntuación 215.270409149048\n",
      "Generación 42, x = -14.70456501575024 Mejor puntuación 217.95474880649127\n",
      "Generación 43, x = -15.092153593901568 Mejor puntuación 223.07645452488725\n",
      "Generación 44, x = -14.883990478093459 Mejor puntuación 227.77310010191601\n",
      "Generación 45, x = -14.925252906508094 Mejor puntuación 237.57058067815885\n",
      "Generación 46, x = -15.081457811773536 Mejor puntuación 230.79929878213602\n",
      "Generación 47, x = -15.532684762699116 Mejor puntuación 251.96131611952288\n",
      "Generación 48, x = -15.495441608421672 Mejor puntuación 279.5703509687177\n",
      "Generación 49, x = -15.608390596942137 Mejor puntuación 279.5703509687177\n",
      "Generación 50, x = -17.312709612835484 Mejor puntuación 272.53355647282626\n",
      "Generación 51, x = -16.929572044022773 Mejor puntuación 299.72991413836615\n",
      "Generación 52, x = -16.744474763373375 Mejor puntuación 286.6104095937574\n",
      "Generación 53, x = -16.929572044022773 Mejor puntuación 286.6104095937574\n",
      "Generación 54, x = -16.929036688724715 Mejor puntuación 286.6104095937574\n",
      "Generación 55, x = -17.105844149173294 Mejor puntuación 298.849479893999\n",
      "Generación 56, x = -17.017708096598035 Mejor puntuación 298.76050443740394\n",
      "Generación 57, x = -17.284689885485477 Mejor puntuación 298.76050443740394\n",
      "Generación 58, x = -17.26265587234166 Mejor puntuación 298.76050443740394\n",
      "Generación 59, x = -17.534119902358725 Mejor puntuación 316.25464772981564\n",
      "Generación 60, x = -17.284689885485477 Mejor puntuación 307.44536075029237\n",
      "Generación 61, x = -17.471762398140413 Mejor puntuación 307.44536075029237\n",
      "Generación 62, x = -17.534119902358725 Mejor puntuación 307.44536075029237\n",
      "Generación 63, x = -17.534119902358725 Mejor puntuación 307.44536075029237\n",
      "Generación 64, x = -17.534119902358725 Mejor puntuación 307.44536075029237\n",
      "Generación 65, x = -17.900524842629164 Mejor puntuación 333.6807236933845\n",
      "Generación 66, x = -17.717322372493946 Mejor puntuación 333.6807236933845\n",
      "Generación 67, x = -17.992126077696774 Mejor puntuación 331.35023540567124\n",
      "Generación 68, x = -17.946325460162967 Mejor puntuación 329.1821562890223\n",
      "Generación 69, x = -18.059764216660376 Mejor puntuación 326.4436592750568\n",
      "Generación 70, x = -18.06775191536171 Mejor puntuación 326.4436592750568\n",
      "Generación 71, x = -18.06775191536171 Mejor puntuación 326.4436592750568\n",
      "Generación 72, x = -18.06775191536171 Mejor puntuación 326.4436592750568\n",
      "Generación 73, x = -18.06775191536171 Mejor puntuación 326.4436592750568\n",
      "Generación 74, x = -18.06775191536171 Mejor puntuación 343.5825432988535\n",
      "Generación 75, x = -18.184808860577455 Mejor puntuación 335.5639111237888\n",
      "Generación 76, x = -18.467025050158707 Mejor puntuación 346.8502243890423\n",
      "Generación 77, x = -18.467025050158707 Mejor puntuación 346.8502243890423\n",
      "Generación 78, x = -18.62391538825932 Mejor puntuación 346.8502243890423\n",
      "Generación 79, x = -18.62391538825932 Mejor puntuación 346.8502243890423\n",
      "Generación 80, x = -18.62391538825932 Mejor puntuación 346.8502243890423\n",
      "Generación 81, x = -18.62391538825932 Mejor puntuación 362.230673543408\n",
      "Generación 82, x = -18.828136989721564 Mejor puntuación 354.4987425037214\n",
      "Generación 83, x = -18.828136989721564 Mejor puntuación 354.4987425037214\n",
      "Generación 84, x = -18.828136989721564 Mejor puntuación 354.4987425037214\n",
      "Generación 85, x = -18.828136989721564 Mejor puntuación 392.41855037695547\n",
      "Generación 86, x = -19.07349200390619 Mejor puntuación 392.41855037695547\n",
      "Generación 87, x = -19.318847018090814 Mejor puntuación 392.41855037695547\n",
      "Generación 88, x = -19.502863278729283 Mejor puntuación 387.5732259975766\n",
      "Generación 89, x = -19.656210162594675 Mejor puntuación 401.62593658261665\n",
      "Generación 90, x = -19.833073988394027 Mejor puntuación 394.56830047722025\n",
      "Generación 91, x = -19.848408676780565 Mejor puntuación 394.56830047722025\n",
      "Generación 92, x = -19.8522423488772 Mejor puntuación 394.2637549506922\n",
      "Generación 93, x = -20.204788894757538 Mejor puntuación 422.44643494942784\n",
      "Generación 94, x = -20.202872058709218 Mejor puntuación 422.44643494942784\n",
      "Generación 95, x = -20.289091859130984 Mejor puntuación 415.30956444848715\n",
      "Generación 96, x = -21.288710940573065 Mejor puntuación 415.30956444848715\n",
      "Generación 97, x = -20.37698889109503 Mejor puntuación 453.2092135112753\n",
      "Generación 98, x = -20.60521890909709 Mejor puntuación 434.00264398530584\n",
      "Generación 99, x = -20.83261031132801 Mejor puntuación 434.00264398530584\n",
      "Generación 100, x = -20.832700163017773 Mejor puntuación 434.00264398530584\n",
      "Generación 101, x = -20.832670212454516 Mejor puntuación 434.00139608220076\n",
      "Generación 102, x = -20.832700163017773 Mejor puntuación 434.00139608220076\n",
      "Generación 103, x = -20.832700163017773 Mejor puntuación 447.2421863994289\n",
      "Generación 104, x = -21.321583303551858 Mejor puntuación 474.68597376530397\n",
      "Generación 105, x = -21.309994716860544 Mejor puntuación 474.68597376530397\n",
      "Generación 106, x = -21.58806712941585 Mejor puntuación 466.0446423841651\n",
      "Generación 107, x = -21.58806712941585 Mejor puntuación 491.3064093589565\n",
      "Generación 108, x = -21.579659418843782 Mejor puntuación 508.28729161453936\n",
      "Generación 109, x = -22.138818113536225 Mejor puntuación 493.32802423494655\n",
      "Generación 110, x = -22.17490346533618 Mejor puntuación 493.32802423494655\n",
      "Generación 111, x = -22.210988817136137 Mejor puntuación 493.32802423494655\n",
      "Generación 112, x = -22.201967479186145 Mejor puntuación 493.32802423494655\n",
      "Generación 113, x = -23.190561909111736 Mejor puntuación 493.32802423494655\n",
      "Generación 114, x = -22.700775363123938 Mejor puntuación 537.8021616603442\n",
      "Generación 115, x = -22.222433739510336 Mejor puntuación 515.3252020870148\n",
      "Generación 116, x = -22.623734797834928 Mejor puntuación 515.3252020870148\n",
      "Generación 117, x = -22.700775363123938 Mejor puntuación 516.1219145970459\n",
      "Generación 118, x = -22.705160702380446 Mejor puntuación 515.7234814172286\n",
      "Generación 119, x = -22.705160702380446 Mejor puntuación 542.8863946267024\n",
      "Generación 120, x = -23.151232149104494 Mejor puntuación 542.8863946267024\n",
      "Generación 121, x = -23.22557739022517 Mejor puntuación 542.8863946267024\n",
      "Generación 122, x = -23.299922631345847 Mejor puntuación 542.8863946267024\n",
      "Generación 123, x = -23.23384822168846 Mejor puntuación 556.9227156442813\n",
      "Generación 124, x = -23.440273192527357 Mejor puntuación 564.6813542550169\n",
      "Generación 125, x = -23.61174795695769 Mejor puntuación 564.6813542550169\n",
      "Generación 126, x = -23.690112604809137 Mejor puntuación 596.4967400523159\n",
      "Generación 127, x = -24.423282745206794 Mejor puntuación 596.4967400523159\n",
      "Generación 128, x = -24.23930867090896 Mejor puntuación 596.4967400523159\n",
      "Generación 129, x = -25.05081500164342 Mejor puntuación 596.4967400523159\n",
      "Generación 130, x = -24.399610724319118 Mejor puntuación 632.737516117109\n",
      "Generación 131, x = -25.128409483721597 Mejor puntuación 632.737516117109\n",
      "Generación 132, x = -25.04996795166702 Mejor puntuación 632.737516117109\n",
      "Generación 133, x = -25.062900365346714 Mejor puntuación 632.0870724020257\n",
      "Generación 134, x = -25.102121131374005 Mejor puntuación 632.0870724020257\n",
      "Generación 135, x = -25.290444895678604 Mejor puntuación 631.1013942809775\n",
      "Generación 136, x = -25.102121131374005 Mejor puntuación 659.0188218516626\n",
      "Generación 137, x = -25.442531379193426 Mejor puntuación 650.1643861706444\n",
      "Generación 138, x = -25.443757028131778 Mejor puntuación 649.7203362376385\n",
      "Generación 139, x = -25.477730639368865 Mejor puntuación 649.2764379952752\n",
      "Generación 140, x = -25.477730639368865 Mejor puntuación 649.114758532235\n",
      "Generación 141, x = -25.888964972868617 Mejor puntuación 691.7004835546993\n",
      "Generación 142, x = -26.260418963061323 Mejor puntuación 697.7021857866675\n",
      "Generación 143, x = -26.24437238838809 Mejor puntuación 693.649994111449\n",
      "Generación 144, x = -26.332263343022888 Mejor puntuación 693.649994111449\n",
      "Generación 145, x = -25.662734075280255 Mejor puntuación 693.388092766307\n",
      "Generación 146, x = -26.66461179752134 Mejor puntuación 729.1043746620874\n",
      "Generación 147, x = -26.667098068978028 Mejor puntuación 728.1414911203292\n",
      "Generación 148, x = -27.138586700219058 Mejor puntuación 751.2753202083068\n",
      "Generación 149, x = -26.98209211834962 Mejor puntuación 749.319141472963\n",
      "Generación 150, x = -27.250868788988583 Mejor puntuación 749.319141472963\n",
      "Generación 151, x = -27.31491742530406 Mejor puntuación 796.6915992189676\n",
      "Generación 152, x = -27.7703216328657 Mejor puntuación 796.6915992189676\n",
      "Generación 153, x = -27.7703216328657 Mejor puntuación 810.0530552251989\n",
      "Generación 154, x = -28.11587632220766 Mejor puntuación 790.9156964172795\n",
      "Generación 155, x = -28.121386657366568 Mejor puntuación 790.9156964172795\n",
      "Generación 156, x = -28.12046826817342 Mejor puntuación 847.6802907430282\n",
      "Generación 157, x = -27.720738957129747 Mejor puntuación 818.9995473032848\n",
      "Generación 158, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 159, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 160, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 161, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 162, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 163, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 164, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 165, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 166, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 167, x = -28.618168133255573 Mejor puntuación 818.9995473032848\n",
      "Generación 168, x = -28.618168133255573 Mejor puntuación 863.9613095655693\n",
      "Generación 169, x = -29.148683224677406 Mejor puntuación 858.0021070533613\n",
      "Generación 170, x = -29.291672998539386 Mejor puntuación 858.0021070533613\n",
      "Generación 171, x = -29.291672998539386 Mejor puntuación 858.0021070533613\n",
      "Generación 172, x = -29.291672998539386 Mejor puntuación 858.0021070533613\n",
      "Generación 173, x = -29.68800071383374 Mejor puntuación 858.0021070533613\n",
      "Generación 174, x = -29.291672998539386 Mejor puntuación 881.3773863845927\n",
      "Generación 175, x = -30.007374288071006 Mejor puntuación 900.4425116643849\n",
      "Generación 176, x = -30.37156776001931 Mejor puntuación 922.4321282014444\n",
      "Generación 177, x = -30.162352298747095 Mejor puntuación 922.4321282014444\n",
      "Generación 178, x = -30.157124934552378 Mejor puntuación 920.1303227055602\n",
      "Generación 179, x = -30.56230384965555 Mejor puntuación 953.3648318446878\n",
      "Generación 180, x = -31.089319352343715 Mejor puntuación 966.5457777920134\n",
      "Generación 181, x = -31.089319352343715 Mejor puntuación 966.5457777920134\n",
      "Generación 182, x = -32.12239211020243 Mejor puntuación 1002.7442928683579\n",
      "Generación 183, x = -31.37772865275026 Mejor puntuación 1031.8480748815955\n",
      "Generación 184, x = -31.93622624583939 Mejor puntuación 1031.8480748815955\n",
      "Generación 185, x = -31.93622624583939 Mejor puntuación 1031.8480748815955\n",
      "Generación 186, x = -31.98276771193015 Mejor puntuación 1064.5933685079392\n",
      "Generación 187, x = -33.22336764094598 Mejor puntuación 1064.5933685079392\n",
      "Generación 188, x = -32.41071173541932 Mejor puntuación 1103.7921574054565\n",
      "Generación 189, x = -33.431159128253675 Mejor puntuación 1129.9300133895717\n",
      "Generación 190, x = -33.17583787232595 Mejor puntuación 1117.642400658619\n",
      "Generación 191, x = -33.30349850028981 Mejor puntuación 1110.9410802239934\n",
      "Generación 192, x = -33.292046547416106 Mejor puntuación 1110.9410802239934\n",
      "Generación 193, x = -33.7435218820693 Mejor puntuación 1167.5822797612286\n",
      "Generación 194, x = -34.12545650793557 Mejor puntuación 1164.546781875002\n",
      "Generación 195, x = -33.93278392799266 Mejor puntuación 1164.546781875002\n",
      "Generación 196, x = -34.04189201388448 Mejor puntuación 1159.6620556310916\n",
      "Generación 197, x = -34.04189201388448 Mejor puntuación 1158.850411884972\n",
      "Generación 198, x = -34.432079200929664 Mejor puntuación 1213.005324160445\n",
      "Generación 199, x = -34.8282259691826 Mejor puntuación 1213.005324160445\n",
      "Mejor solución: x = -34.63015258505613, f(x) = 1199.2474680642697\n"
     ]
    }
   ],
   "source": [
    "n_generations = 200\n",
    "\n",
    "for generation in range(n_generations):\n",
    "    scores = np.array([fitness(x) for x in population])\n",
    "    new_population = []\n",
    "    for _ in range(population_size):\n",
    "        parent1 = select_parent_tournament(population, scores)\n",
    "        parent2 = select_parent_tournament(population, scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        child = mutate(child)\n",
    "        new_population.append(child)\n",
    "    population = np.array(new_population)\n",
    "    best_score = np.max(scores)\n",
    "    print(f\"Generación {generation}, x = {child} Mejor puntuación {best_score}\")\n",
    "\n",
    "best_solution = population[np.argmax(scores)]\n",
    "print(f\"Mejor solución: x = {best_solution}, f(x) = {fitness(best_solution)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (MNIST)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicamos la máxima descendencia que queremos \n",
    "# uso 2 para simplemente comprobar que el algoritmo al completo funciona, este valor lo \n",
    "# indicará el usuario desde la interfaz\n",
    "max_desc = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS DEL DATASET DE PRUEBA\n",
    "\n",
    "num_channels = 1\n",
    "px_h = 28\n",
    "px_w = 28\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.Grayscale(num_output_channels=num_channels),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (CIFAR100)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DATOS DEL DATASET DE PRUEBA CIFAR 100\n",
    "num_channels = 3\n",
    "px_h = 32\n",
    "px_w = 32\n",
    "batch_size = 512\n",
    "num_classes = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERACIÓN DE LA RED EN BASE A VECTORES\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprobamos si tenemos acceso a la GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU) está disponible en tu sistema.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA (GPU) está disponible en tu sistema.\")\n",
    "else:\n",
    "    print(\"CUDA (GPU) no está disponible en tu sistema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos un par de arquitecturas de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos una función que sea capaz de crear modelos en base a vectores que representen la arquitectura de la red.\n",
    "De este modo el algorimo evolutivo puede ir adaptando y cambiando la red fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def build_cnn_from_individual(individual):\n",
    "    layers = []\n",
    "    num_layers = individual['num_conv_layers']\n",
    "    fully_connected = individual['fully_connected']\n",
    "    dropout = individual['dropout']\n",
    "    out_channels_previous_layer = num_channels # Imagen de entrada en escala de grises (1 canal para MNIST)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        out_channels = individual['filters'][i]\n",
    "        kernel_size = individual['filter_sizes'][i]\n",
    "        \n",
    "        conv_layer = nn.Conv2d(out_channels_previous_layer, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        layers.append(conv_layer)\n",
    "        layers.append(nn.ReLU())\n",
    "        if i < 2:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        else:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=1))\n",
    "\n",
    "\n",
    "        out_channels_previous_layer = out_channels\n",
    "\n",
    "\n",
    "    # Temporalmente crear un modelo para calcular el tamaño de salida de las capas convolucionales\n",
    "    temp_model = nn.Sequential(*layers)\n",
    "\n",
    "    # Calcular el tamaño de salida usando un tensor dummy\n",
    "    dummy_input = torch.zeros(1, num_channels, px_h, px_w)  # Tamaño de entrada para MNIST\n",
    "    output_size = temp_model(dummy_input).view(-1).shape[0]\n",
    "\n",
    "    # Ahora, sabiendo el tamaño de salida, podemos definir las capas lineales correctamente\n",
    "    layers.append(nn.Flatten())\n",
    "\n",
    "    for i in range(fully_connected):\n",
    "        layers.append(nn.Linear(in_features=output_size, out_features=output_size))\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            dropout-= 1\n",
    "\n",
    "    layers.append(nn.Linear(output_size, num_classes))  # Salida de 10 clases para MNIST\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la población inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    individual = {\n",
    "        'num_conv_layers': random.randint(min_conv_layers, max_conv_layers),\n",
    "        'filters': [],\n",
    "        'filter_sizes': [],\n",
    "        'learning_rate': random.uniform(lr_min, lr_max),\n",
    "        'fully_connected': random.randint(0,2),\n",
    "        'dropout': random.randint(0,2)\n",
    "    }\n",
    "\n",
    "    for _ in range(individual['num_conv_layers']):\n",
    "        individual['filters'].append(random.randint(min_filters, max_filters))\n",
    "        individual['filter_sizes'].append(random.choice(filter_sizes))\n",
    "    \n",
    "    # Agrega más parámetros según sea necesario, como capas completamente conectadas, etc.\n",
    "\n",
    "    return individual\n",
    "\n",
    "def initialize_population(pop_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    return [generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max) for _ in range(pop_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETROS PARA POSIBLES ARQUITECTURAS DE RED\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AJUSTAR SEGÚN VAYA NECESITANDO Y TIEMPO \n",
    "\n",
    "population_size = 5\n",
    "min_conv_layers = 1\n",
    "max_conv_layers = 3\n",
    "min_filters = 16\n",
    "max_filters = 128\n",
    "filter_sizes = [3, 5]\n",
    "lr_min = 0.0001\n",
    "lr_max = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num_conv_layers': 2,\n",
       "  'filters': [98, 100],\n",
       "  'filter_sizes': [5, 5],\n",
       "  'learning_rate': 0.006580664111244137,\n",
       "  'fully_connected': 1,\n",
       "  'dropout': 2},\n",
       " {'num_conv_layers': 2,\n",
       "  'filters': [70, 47],\n",
       "  'filter_sizes': [3, 5],\n",
       "  'learning_rate': 0.001168646634845199,\n",
       "  'fully_connected': 1,\n",
       "  'dropout': 2},\n",
       " {'num_conv_layers': 1,\n",
       "  'filters': [112],\n",
       "  'filter_sizes': [3],\n",
       "  'learning_rate': 0.008707459517366928,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 1,\n",
       "  'filters': [58],\n",
       "  'filter_sizes': [3],\n",
       "  'learning_rate': 0.009266323914872622,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 2,\n",
       "  'filters': [42, 53],\n",
       "  'filter_sizes': [3, 5],\n",
       "  'learning_rate': 0.009590188540084888,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 0}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "population = initialize_population(population_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO Y EVALUACIÓN DE LOS MODELOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def evaluate_individual(individual, train_loader, val_loader, device='cuda', epochs=5):\n",
    "    # Construir el modelo basado en el individuo\n",
    "    model = build_cnn_from_individual(individual).to(device)\n",
    "    \n",
    "    # Definir el optimizador y la función de pérdida\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=individual['learning_rate'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch')\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Actualizar la barra de progreso con la última información de pérdida\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item())})\n",
    "            progress_bar.update()  # Forzar la actualización de la barra de progreso\n",
    "            \n",
    "        progress_bar.close()  # Cerrar la barra de progreso al final de cada época\n",
    "\n",
    "    # Evaluación\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy  # Esta es la \"aptitud\" del individuo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUTACIONES Y CRUCES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def mutate_individual(individual):\n",
    "    \"\"\"\n",
    "    Mutar un individuo cambiando aleatoriamente sus hiperparámetros.\n",
    "    \"\"\"\n",
    "    mutation_rate = 0.3  # Probabilidad de mutar cada característica\n",
    "    lr_range = (0.0001, 0.01)\n",
    "    filter_range = (32, 128)  # Rango para el número de filtros\n",
    "    filter_size_range = (1, 7)  # Rango para el tamaño de filtro\n",
    "    fully_connected_range = (0,2) #Rango para ver cuantas fully conected se añaden\n",
    "    dropout_range = (0,2) # Rango para ver cuantos dropouts se añaden\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['learning_rate'] = random.uniform(*lr_range)\n",
    "\n",
    "    # Asegurarse de que hay suficientes entradas en las listas 'filters' y 'filter_sizes'\n",
    "    for i in range(individual['num_conv_layers']):\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el número de filtros en la capa i\n",
    "            individual['filters'][i] = random.randint(*filter_range)\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el tamaño de filtro en la capa i\n",
    "            individual['filter_sizes'][i] = random.randint(*filter_size_range)\n",
    "\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['fully_connected'] = random.uniform(*fully_connected_range)\n",
    "\n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el cruce entre individuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    \"\"\"\n",
    "    Realiza un cruce uniforme entre dos individuos.\n",
    "    \n",
    "    Args:\n",
    "        parent1 (dict): El primer individuo padre.\n",
    "        parent2 (dict): El segundo individuo padre.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un nuevo individuo hijo.\n",
    "    \"\"\"\n",
    "    child = {}\n",
    "    print(f\"Padre 1: {parent1} --- Padre 2: {parent2}\")\n",
    "    for key in parent1:\n",
    "        if key == \"filters\" or key == \"filter_sizes\":\n",
    "            if random.random() < 0.5:\n",
    "                child[\"filters\"] = parent1[\"filters\"]\n",
    "                child[\"filter_sizes\"] = parent1[\"filter_sizes\"]\n",
    "            else:\n",
    "                child[\"filters\"] = parent2[\"filters\"]\n",
    "                child[\"filter_sizes\"] = parent2[\"filter_sizes\"]\n",
    "\n",
    "        else:\n",
    "            if key != \"num_conv_layers\":\n",
    "                if random.random() < 0.5:\n",
    "                    child[key] = parent1[key]\n",
    "                else:\n",
    "                    child[key] = parent2[key]\n",
    "    child[\"num_conv_layers\"] = len(child[\"filters\"])\n",
    "\n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population, train_loader, val_loader, device):\n",
    "    fitness_scores = []\n",
    "    \n",
    "    for individual in population:\n",
    "        print(individual)\n",
    "        fitness = evaluate_individual(individual, train_loader, val_loader, device)\n",
    "        fitness_scores.append(fitness)\n",
    "    \n",
    "    return fitness_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recopilamos lo que hemos realizado, hemos creado las posibles mutaciones sobre las arquitecturas, los posibles cruces, la evaluación de los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queda realizar:\n",
    "- Selección de reproducción: por torneo en principio para también  puede ser por torneo o ruleta\n",
    "- Creación de la nueva generación usando las funciones de mutación y cruces\n",
    "- Criterios de parada\n",
    "- Registro de análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección por torneo\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection_best4(population):\n",
    "    \"\"\"\n",
    "    Selecciona los 4 mejores individuos de la población mediante un torneo de tamaño fijo.\n",
    "\n",
    "    Args:\n",
    "        population: La lista de individuos con sus puntuaciones de fitness.\n",
    "\n",
    "    Returns:\n",
    "        Lista de los 4 mejores individuos.\n",
    "    \"\"\"\n",
    "    winners = []\n",
    "    for _ in range(2):\n",
    "        candidates = random.sample(population, 2)\n",
    "        winner = max(candidates, key=lambda x: x['fitness'])\n",
    "        winners.append(winner)\n",
    "    return winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITMO EVOLUTIVO\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfitness_scores = evaluate_population(population, train_loader, val_loader, device)\\n\\n# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\\npopulation_with_scores = list(zip(population, fitness_scores))\\npopulation_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\\n\\n# Imprimimimos los resultados\\nfor i, (individual, score) in enumerate(population_with_scores):\\n    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fitness_scores = evaluate_population(population, train_loader, val_loader, device)\n",
    "\n",
    "# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\n",
    "population_with_scores = list(zip(population, fitness_scores))\n",
    "population_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\n",
    "\n",
    "# Imprimimimos los resultados\n",
    "for i, (individual, score) in enumerate(population_with_scores):\n",
    "    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = []\n",
    "\n",
    "def genetic_algorithm(population, train_loader, val_loader, device, max_desc):\n",
    "    desc = 0\n",
    "    while desc < max_desc:\n",
    "        print(\"***************************************\")\n",
    "        print()\n",
    "        print(f\"Generation: {desc}\")\n",
    "        print()\n",
    "        print(\"***************************************\")\n",
    "        puntuaciones_aptitud = evaluate_population(population, train_loader, val_loader, device)\n",
    "\n",
    "        # Ordenamos individuos\n",
    "        # Añadimos las puntuaciones directamente a cada diccionario de la población\n",
    "        for i, puntuacion in enumerate(puntuaciones_aptitud):\n",
    "            population[i]['fitness'] = puntuacion\n",
    "\n",
    "        population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "\n",
    "        # Preservamos el mejor individuo (elitismo)\n",
    "        mejor_individuo = population[0]\n",
    "        top_models.append(mejor_individuo)\n",
    "        # Seleccionamos los 4 mejores (excluyendo el mejor) para el torneo\n",
    "        winners = tournament_selection_best4(population[1:])\n",
    "        print(f\"Los 4 mejores son: \\n {winners}\")\n",
    "\n",
    "        # Realizamos cruce y mutación con descendientes que reemplazan a la población restante\n",
    "        for i in range(1, 2):\n",
    "            descendency = mutate_individual(crossover(winners[i-1], winners[i]))\n",
    "            population[-i] = descendency   # Eliminamos las peores arquitecturas\n",
    "\n",
    "        # Nos aseguramos que mantenemos el mejor de todos\n",
    "        population[0] = mejor_individuo\n",
    "        desc += 1\n",
    "\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTADOS DE LAS ARQUITECTURAS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padre 1: {'num_conv_layers': 2, 'filters': [70, 47], 'filter_sizes': [3, 5], 'learning_rate': 0.001168646634845199, 'fully_connected': 1, 'dropout': 2} --- Padre 2: {'num_conv_layers': 1, 'filters': [112], 'filter_sizes': [3], 'learning_rate': 0.008707459517366928, 'fully_connected': 0, 'dropout': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'filters': [42],\n",
       " 'filter_sizes': [3],\n",
       " 'learning_rate': 0.001168646634845199,\n",
       " 'fully_connected': 1,\n",
       " 'dropout': 1,\n",
       " 'num_conv_layers': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = crossover(population[1], population[2])\n",
    "mutate = mutate_individual(sol)\n",
    "mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n",
      "\n",
      "Generation: 0\n",
      "\n",
      "***************************************\n",
      "{'num_conv_layers': 2, 'filters': [98, 100], 'filter_sizes': [5, 5], 'learning_rate': 0.006580664111244137, 'fully_connected': 1, 'dropout': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  7.95batch/s, training_loss=4.611]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:11<00:00,  8.19batch/s, training_loss=4.616]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:11<00:00,  8.19batch/s, training_loss=4.622]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:11<00:00,  8.26batch/s, training_loss=4.609]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:11<00:00,  8.22batch/s, training_loss=4.611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 2, 'filters': [70, 47], 'filter_sizes': [3, 5], 'learning_rate': 0.001168646634845199, 'fully_connected': 1, 'dropout': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:11<00:00,  8.20batch/s, training_loss=3.251]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  8.12batch/s, training_loss=2.853]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:11<00:00,  8.22batch/s, training_loss=2.581]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  8.13batch/s, training_loss=2.723]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:11<00:00,  8.17batch/s, training_loss=2.505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 1, 'filters': [42], 'filter_sizes': [3], 'learning_rate': 0.008707459517366928, 'fully_connected': 0, 'dropout': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:10<00:00,  9.01batch/s, training_loss=3.306]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:11<00:00,  8.35batch/s, training_loss=2.865]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:11<00:00,  8.28batch/s, training_loss=2.434]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:11<00:00,  8.31batch/s, training_loss=2.075]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:11<00:00,  8.34batch/s, training_loss=1.894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 1, 'filters': [58], 'filter_sizes': [3], 'learning_rate': 0.009266323914872622, 'fully_connected': 2, 'dropout': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:34<00:00,  2.82batch/s, training_loss=170.769]  \n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:34<00:00,  2.80batch/s, training_loss=83.973] \n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:35<00:00,  2.78batch/s, training_loss=32.498]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:35<00:00,  2.79batch/s, training_loss=38.003]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:35<00:00,  2.79batch/s, training_loss=32.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 2, 'filters': [42, 53], 'filter_sizes': [3, 5], 'learning_rate': 0.009590188540084888, 'fully_connected': 0, 'dropout': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:11<00:00,  8.71batch/s, training_loss=4.606]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  8.08batch/s, training_loss=4.606]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  8.12batch/s, training_loss=4.607]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  8.10batch/s, training_loss=4.607]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  8.08batch/s, training_loss=4.607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 4 mejores son: \n",
      " [{'num_conv_layers': 2, 'filters': [42, 53], 'filter_sizes': [3, 5], 'learning_rate': 0.009590188540084888, 'fully_connected': 0, 'dropout': 0, 'fitness': 0.01}, {'num_conv_layers': 1, 'filters': [58], 'filter_sizes': [3], 'learning_rate': 0.009266323914872622, 'fully_connected': 2, 'dropout': 1, 'fitness': 0.0307}]\n",
      "Padre 1: {'num_conv_layers': 2, 'filters': [42, 53], 'filter_sizes': [3, 5], 'learning_rate': 0.009590188540084888, 'fully_connected': 0, 'dropout': 0, 'fitness': 0.01} --- Padre 2: {'num_conv_layers': 1, 'filters': [58], 'filter_sizes': [3], 'learning_rate': 0.009266323914872622, 'fully_connected': 2, 'dropout': 1, 'fitness': 0.0307}\n",
      "***************************************\n",
      "\n",
      "Generation: 1\n",
      "\n",
      "***************************************\n",
      "{'num_conv_layers': 2, 'filters': [70, 47], 'filter_sizes': [3, 5], 'learning_rate': 0.001168646634845199, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.351}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  7.88batch/s, training_loss=3.232]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  8.10batch/s, training_loss=2.738]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  8.05batch/s, training_loss=2.564]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  8.11batch/s, training_loss=2.450]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  8.14batch/s, training_loss=2.428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 1, 'filters': [42], 'filter_sizes': [3], 'learning_rate': 0.008707459517366928, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.3239}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:11<00:00,  8.75batch/s, training_loss=3.315]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:09<00:00, 10.00batch/s, training_loss=2.831]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:11<00:00,  8.69batch/s, training_loss=2.361]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:11<00:00,  8.33batch/s, training_loss=1.935]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:11<00:00,  8.25batch/s, training_loss=1.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 1, 'filters': [58], 'filter_sizes': [3], 'learning_rate': 0.009266323914872622, 'fully_connected': 2, 'dropout': 1, 'fitness': 0.0307}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:34<00:00,  2.81batch/s, training_loss=88.142]   \n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:34<00:00,  2.82batch/s, training_loss=62.534] \n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:34<00:00,  2.81batch/s, training_loss=27.173] \n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:35<00:00,  2.80batch/s, training_loss=24.934] \n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:35<00:00,  2.79batch/s, training_loss=45.601] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 2, 'filters': [98, 100], 'filter_sizes': [5, 5], 'learning_rate': 0.006580664111244137, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  8.07batch/s, training_loss=4.612] \n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  7.96batch/s, training_loss=4.610]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  7.98batch/s, training_loss=4.608]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  8.01batch/s, training_loss=4.612]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  8.03batch/s, training_loss=4.617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filters': [42, 53], 'filter_sizes': [3, 5], 'learning_rate': 0.009266323914872622, 'fully_connected': 2, 'dropout': 1, 'fitness': 0.0307, 'num_conv_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  8.11batch/s, training_loss=4.970] \n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  8.11batch/s, training_loss=4.625]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  8.02batch/s, training_loss=4.619]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  8.11batch/s, training_loss=4.627]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  8.10batch/s, training_loss=4.613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 4 mejores son: \n",
      " [{'num_conv_layers': 1, 'filters': [58], 'filter_sizes': [3], 'learning_rate': 0.009266323914872622, 'fully_connected': 2, 'dropout': 1, 'fitness': 0.0187}, {'num_conv_layers': 1, 'filters': [42], 'filter_sizes': [3], 'learning_rate': 0.008707459517366928, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.3219}]\n",
      "Padre 1: {'num_conv_layers': 1, 'filters': [58], 'filter_sizes': [3], 'learning_rate': 0.009266323914872622, 'fully_connected': 2, 'dropout': 1, 'fitness': 0.0187} --- Padre 2: {'num_conv_layers': 1, 'filters': [42], 'filter_sizes': [3], 'learning_rate': 0.008707459517366928, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.3219}\n"
     ]
    }
   ],
   "source": [
    "population_sol = genetic_algorithm(population, train_loader, val_loader, device, max_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuo {'num_conv_layers': 2, 'filters': [70, 47], 'filter_sizes': [3, 5], 'learning_rate': 0.001168646634845199, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.3593} \n",
      "Individuo {'num_conv_layers': 2, 'filters': [70, 47], 'filter_sizes': [3, 5], 'learning_rate': 0.001168646634845199, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.3593} \n"
     ]
    }
   ],
   "source": [
    "for individual in top_models:\n",
    "    print(f\"Individuo {individual} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
