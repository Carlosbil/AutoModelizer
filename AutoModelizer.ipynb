{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoModelizer\n",
    "---\n",
    "\n",
    "La idea de este proyecto es encontrar el mejor modelo de CNN que se adapte al dataset correspondiente, para ello usando algoritmos evolutivos. Este tipo de soluciones se conocen como neuroevoluciones\n",
    "\n",
    "A continuación un ejemplo básico de como funcionan este tipo de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def fitness(x):\n",
    "    return x ** 2\n",
    "\n",
    "population_size = 10\n",
    "population = np.random.uniform(-10, 10, population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parent_tournament(population, scores, k=3):\n",
    "    selection_ix = np.random.randint(len(population), size=k)\n",
    "    selected = population[selection_ix]\n",
    "    ix = np.argmax(scores[selection_ix])\n",
    "    return selected[ix]\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    child = (p1 + p2) / 2\n",
    "    return child\n",
    "\n",
    "def mutate(x):\n",
    "    mutation_chance = 0.1\n",
    "    if np.random.rand() < mutation_chance:\n",
    "        x += np.random.uniform(-1, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 0, x = 1.0418109381542169 Mejor puntuación 68.21442545374215\n",
      "Generación 1, x = 2.1847606401170916 Mejor puntuación 68.21442545374215\n",
      "Generación 2, x = 7.326325849149429 Mejor puntuación 68.21442545374215\n",
      "Generación 3, x = 7.254033158083836 Mejor puntuación 77.6642058071865\n",
      "Generación 4, x = 7.697926826640756 Mejor puntuación 77.6642058071865\n",
      "Generación 5, x = 9.119355267496095 Mejor puntuación 95.99260821394486\n",
      "Generación 6, x = 8.864105682549386 Mejor puntuación 95.99260821394486\n",
      "Generación 7, x = 9.458468510432438 Mejor puntuación 89.46262656284202\n",
      "Generación 8, x = 9.335362011150682 Mejor puntuación 96.67999325798252\n",
      "Generación 9, x = 9.41883165780883 Mejor puntuación 93.45958761011988\n",
      "Generación 10, x = 9.789850995835593 Mejor puntuación 98.47010242093323\n",
      "Generación 11, x = 9.784371896581275 Mejor puntuación 98.47010242093323\n",
      "Generación 12, x = 9.787111446208435 Mejor puntuación 98.47010242093323\n",
      "Generación 13, x = 9.923210288053621 Mejor puntuación 98.47010242093323\n",
      "Generación 14, x = 9.923210288053621 Mejor puntuación 98.47010242093323\n",
      "Generación 15, x = 10.386164041619582 Mejor puntuación 98.47010242093323\n",
      "Generación 16, x = 10.313157953194018 Mejor puntuación 114.55646987722173\n",
      "Generación 17, x = 10.544634829977 Mejor puntuación 112.91510119697581\n",
      "Generación 18, x = 10.565014062134843 Mejor puntuación 112.05055119485657\n",
      "Generación 19, x = 11.065001902261326 Mejor puntuación 133.53638442725725\n",
      "Generación 20, x = 11.065001902261326 Mejor puntuación 152.84737086100594\n",
      "Generación 21, x = 11.715471773567602 Mejor puntuación 157.04025425712865\n",
      "Generación 22, x = 12.531570302924077 Mejor puntuación 157.04025425712865\n",
      "Generación 23, x = 12.377289291738473 Mejor puntuación 175.56506827657176\n",
      "Generación 24, x = 13.331639946821298 Mejor puntuación 189.68027665418373\n",
      "Generación 25, x = 13.293069694024897 Mejor puntuación 189.68027665418373\n",
      "Generación 26, x = 13.532757989167076 Mejor puntuación 183.6578726061402\n",
      "Generación 27, x = 14.007050150682813 Mejor puntuación 183.6578726061402\n",
      "Generación 28, x = 13.779546633124045 Mejor puntuación 196.1974539237434\n",
      "Generación 29, x = 14.21139173376278 Mejor puntuación 214.42438498837325\n",
      "Generación 30, x = 14.385306037188673 Mejor puntuación 214.42438498837325\n",
      "Generación 31, x = 14.47079285993862 Mejor puntuación 210.66407531193735\n",
      "Generación 32, x = 14.47079285993862 Mejor puntuación 209.40384599525052\n",
      "Generación 33, x = 14.47079285993862 Mejor puntuación 209.40384599525052\n",
      "Generación 34, x = 14.47079285993862 Mejor puntuación 209.40384599525052\n",
      "Generación 35, x = 14.47079285993862 Mejor puntuación 210.98351215547567\n",
      "Generación 36, x = 14.498032180085717 Mejor puntuación 210.192937094801\n",
      "Generación 37, x = 14.91952486318878 Mejor puntuación 235.34681935563424\n",
      "Generación 38, x = 15.285950366011503 Mejor puntuación 245.21009675172607\n",
      "Generación 39, x = 15.289355281029891 Mejor puntuación 237.3740650865716\n",
      "Generación 40, x = 15.347300710519507 Mejor puntuación 237.3740650865716\n",
      "Generación 41, x = 15.362851103835157 Mejor puntuación 249.97189533898202\n",
      "Generación 42, x = 15.579325733859907 Mejor puntuación 242.71539032170952\n",
      "Generación 43, x = 15.528881867493983 Mejor puntuación 271.0174061529995\n",
      "Generación 44, x = 16.37636974474757 Mejor puntuación 271.0174061529995\n",
      "Generación 45, x = 16.389824793420416 Mejor puntuación 278.23313197726463\n",
      "Generación 46, x = 16.461830113582252 Mejor puntuación 274.61341906628917\n",
      "Generación 47, x = 16.48943263124015 Mejor puntuación 297.37652392710146\n",
      "Generación 48, x = 16.672861942783282 Mejor puntuación 297.37652392710146\n",
      "Generación 49, x = 16.970265478352996 Mejor puntuación 311.76252517145974\n",
      "Generación 50, x = 17.52747202695783 Mejor puntuación 311.76252517145974\n",
      "Generación 51, x = 17.656798270679193 Mejor puntuación 311.76252517145974\n",
      "Generación 52, x = 17.62446670974885 Mejor puntuación 311.76252517145974\n",
      "Generación 53, x = 18.298352167564836 Mejor puntuación 341.7002992845689\n",
      "Generación 54, x = 18.29652460610523 Mejor puntuación 343.66661038040763\n",
      "Generación 55, x = 18.397879562302712 Mejor puntuación 342.68274966507585\n",
      "Generación 56, x = 18.464995970559226 Mejor puntuación 342.68274966507585\n",
      "Generación 57, x = 18.474884377808113 Mejor puntuación 342.68274966507585\n",
      "Generación 58, x = 18.46994017418367 Mejor puntuación 341.8188677934789\n",
      "Generación 59, x = 18.92125634591341 Mejor puntuación 375.29656595134264\n",
      "Generación 60, x = 19.12417872078875 Mejor puntuación 375.29656595134264\n",
      "Generación 61, x = 19.282204265470824 Mejor puntuación 373.5368367620201\n",
      "Generación 62, x = 19.316020536062222 Mejor puntuación 373.5368367620201\n",
      "Generación 63, x = 19.316020536062222 Mejor puntuación 373.1086493495775\n",
      "Generación 64, x = 19.316020536062222 Mejor puntuación 411.2997147219778\n",
      "Generación 65, x = 19.798273020075285 Mejor puntuación 411.2997147219778\n",
      "Generación 66, x = 20.039399262081815 Mejor puntuación 401.5775227851252\n",
      "Generación 67, x = 20.039399262081815 Mejor puntuación 401.5775227851252\n",
      "Generación 68, x = 20.0242438181899 Mejor puntuación 438.1171558445855\n",
      "Generación 69, x = 20.254783802292813 Mejor puntuación 438.1171558445855\n",
      "Generación 70, x = 19.84359897407222 Mejor puntuación 456.64329939646666\n",
      "Generación 71, x = 20.678932769884007 Mejor puntuación 445.8615824950998\n",
      "Generación 72, x = 21.11543469822726 Mejor puntuación 445.8615824950998\n",
      "Generación 73, x = 21.11543469822726 Mejor puntuación 445.8615824950998\n",
      "Generación 74, x = 21.513125854958165 Mejor puntuación 480.0839021197231\n",
      "Generación 75, x = 21.11543469822726 Mejor puntuación 462.8145840512695\n",
      "Generación 76, x = 21.513125854958165 Mejor puntuación 462.8145840512695\n",
      "Generación 77, x = 21.513125854958165 Mejor puntuación 462.8145840512695\n",
      "Generación 78, x = 21.808721079138753 Mejor puntuación 488.60079923718916\n",
      "Generación 79, x = 21.761906933102452 Mejor puntuación 484.47038672844104\n",
      "Generación 80, x = 21.7853140061206 Mejor puntuación 488.4662902600125\n",
      "Generación 81, x = 22.782953107125245 Mejor puntuación 522.76966817022\n",
      "Generación 82, x = 22.860772806960426 Mejor puntuación 522.81046513028\n",
      "Generación 83, x = 22.859080788624468 Mejor puntuación 536.8682010757854\n",
      "Generación 84, x = 22.859926797792447 Mejor puntuación 529.7175973984869\n",
      "Generación 85, x = 22.49108046924475 Mejor puntuación 529.7175973984869\n",
      "Generación 86, x = 23.01559465663416 Mejor puntuación 529.7175973984869\n",
      "Generación 87, x = 23.01559465663416 Mejor puntuación 529.7175973984869\n",
      "Generación 88, x = 23.49308229824299 Mejor puntuación 574.5882232413276\n",
      "Generación 89, x = 23.55669458371336 Mejor puntuación 557.918896594408\n",
      "Generación 90, x = 23.49308229824299 Mejor puntuación 592.1219370252581\n",
      "Generación 91, x = 24.253059140772855 Mejor puntuación 592.1219370252581\n",
      "Generación 92, x = 24.248297436774124 Mejor puntuación 588.2108776858257\n",
      "Generación 93, x = 24.25067828877349 Mejor puntuación 619.6505124032176\n",
      "Generación 94, x = 24.41298943730423 Mejor puntuación 619.6505124032176\n",
      "Generación 95, x = 25.41673587726973 Mejor puntuación 646.0104626548903\n",
      "Generación 96, x = 25.41673587726973 Mejor puntuación 646.0104626548903\n",
      "Generación 97, x = 26.24654449776215 Mejor puntuación 646.0104626548903\n",
      "Generación 98, x = 25.82743615811565 Mejor puntuación 688.8810980730087\n",
      "Generación 99, x = 25.902057194872064 Mejor puntuación 681.7064784974851\n",
      "Generación 100, x = 26.109509349995168 Mejor puntuación 681.7064784974851\n",
      "Generación 101, x = 26.109509349995168 Mejor puntuación 681.7064784974851\n",
      "Generación 102, x = 26.109509349995168 Mejor puntuación 681.7064784974851\n",
      "Generación 103, x = 25.59805420725336 Mejor puntuación 681.7064784974851\n",
      "Generación 104, x = 26.109509349995168 Mejor puntuación 681.7064784974851\n",
      "Generación 105, x = 26.109509349995168 Mejor puntuación 681.7064784974851\n",
      "Generación 106, x = 26.173597052555568 Mejor puntuación 685.0571826695455\n",
      "Generación 107, x = 25.525188547745948 Mejor puntuación 732.7108463795661\n",
      "Generación 108, x = 27.068632148292348 Mejor puntuación 732.7108463795661\n",
      "Generación 109, x = 27.068632148292348 Mejor puntuación 732.7108463795661\n",
      "Generación 110, x = 27.068632148292348 Mejor puntuación 732.7108463795661\n",
      "Generación 111, x = 27.068632148292348 Mejor puntuación 738.858765428676\n",
      "Generación 112, x = 27.068632148292348 Mejor puntuación 738.858765428676\n",
      "Generación 113, x = 27.096963265010345 Mejor puntuación 735.7815952954229\n",
      "Generación 114, x = 27.11112882336934 Mejor puntuación 735.7815952954229\n",
      "Generación 115, x = 27.11821160254884 Mejor puntuación 775.4239227499233\n",
      "Generación 116, x = 27.47878173698276 Mejor puntuación 804.6707505233383\n",
      "Generación 117, x = 28.0302699190331 Mejor puntuación 804.6707505233383\n",
      "Generación 118, x = 28.43144858551014 Mejor puntuación 818.5688882920667\n",
      "Generación 119, x = 28.52104575272292 Mejor puntuación 818.5688882920667\n",
      "Generación 120, x = 28.47624716911653 Mejor puntuación 818.5688882920667\n",
      "Generación 121, x = 28.498646460919723 Mejor puntuación 818.5688882920667\n",
      "Generación 122, x = 28.6106429199357 Mejor puntuación 818.5688882920667\n",
      "Generación 123, x = 28.6106429199357 Mejor puntuación 818.5688882920667\n",
      "Generación 124, x = 28.06754898835787 Mejor puntuación 818.5688882920667\n",
      "Generación 125, x = 28.6106429199357 Mejor puntuación 818.5688882920667\n",
      "Generación 126, x = 28.342112073949536 Mejor puntuación 839.9877075340033\n",
      "Generación 127, x = 28.703617546556135 Mejor puntuación 854.4832833103656\n",
      "Generación 128, x = 29.12280756587569 Mejor puntuación 854.4832833103656\n",
      "Generación 129, x = 29.06843833375917 Mejor puntuación 848.1379205190262\n",
      "Generación 130, x = 29.12280756587569 Mejor puntuación 876.3903423344851\n",
      "Generación 131, x = 29.34975680596643 Mejor puntuación 862.2062711903839\n",
      "Generación 132, x = 29.303213726965595 Mejor puntuación 862.2062711903839\n",
      "Generación 133, x = 29.356552959980995 Mejor puntuación 862.2062711903839\n",
      "Generación 134, x = 29.473867445178357 Mejor puntuación 875.2358817645603\n",
      "Generación 135, x = 29.3608005562401 Mejor puntuación 875.2358817645603\n",
      "Generación 136, x = 29.698625787623577 Mejor puntuación 895.5614472361887\n",
      "Generación 137, x = 29.92593268782426 Mejor puntuación 895.5614472361887\n",
      "Generación 138, x = 29.876119548379492 Mejor puntuación 895.5614472361887\n",
      "Generación 139, x = 29.92593268782426 Mejor puntuación 895.5614472361887\n",
      "Generación 140, x = 30.178456340133913 Mejor puntuación 939.3212091439107\n",
      "Generación 141, x = 30.280926763257412 Mejor puntuación 932.6710640556021\n",
      "Generación 142, x = 30.446255238881847 Mejor puntuación 929.3548506364004\n",
      "Generación 143, x = 30.485321888351457 Mejor puntuación 938.797698757805\n",
      "Generación 144, x = 30.60118481347274 Mejor puntuación 938.797698757805\n",
      "Generación 145, x = 30.620495300992957 Mejor puntuación 938.797698757805\n",
      "Generación 146, x = 30.620495300992957 Mejor puntuación 937.6147324781317\n",
      "Generación 147, x = 30.620495300992957 Mejor puntuación 937.6147324781317\n",
      "Generación 148, x = 30.620495300992957 Mejor puntuación 937.6147324781317\n",
      "Generación 149, x = 30.620495300992957 Mejor puntuación 937.6147324781317\n",
      "Generación 150, x = 30.93656351707697 Mejor puntuación 996.5643292134623\n",
      "Generación 151, x = 31.684010594868994 Mejor puntuación 1038.3407559192606\n",
      "Generación 152, x = 32.19500061653181 Mejor puntuación 1038.3407559192606\n",
      "Generación 153, x = 31.80276002598857 Mejor puntuación 1036.5180646984834\n",
      "Generación 154, x = 31.737100968734183 Mejor puntuación 1013.2523048654855\n",
      "Generación 155, x = 31.820728984947287 Mejor puntuación 1013.2523048654855\n",
      "Generación 156, x = 31.802036720798654 Mejor puntuación 1013.2523048654855\n",
      "Generación 157, x = 31.816830504816316 Mejor puntuación 1058.4896846995211\n",
      "Generación 158, x = 32.173685233060155 Mejor puntuación 1035.3968936194228\n",
      "Generación 159, x = 32.17660909315838 Mejor puntuación 1035.3968936194228\n",
      "Generación 160, x = 32.17709640317476 Mejor puntuación 1035.3968936194228\n",
      "Generación 161, x = 32.17734005818294 Mejor puntuación 1035.3968936194228\n",
      "Generación 162, x = 32.102032435147905 Mejor puntuación 1040.5016988891439\n",
      "Generación 163, x = 32.256808566396394 Mejor puntuación 1040.5016988891439\n",
      "Generación 164, x = 32.21707431228967 Mejor puntuación 1040.5016988891439\n",
      "Generación 165, x = 32.42994542803519 Mejor puntuación 1062.9609747872535\n",
      "Generación 166, x = 32.42994542803519 Mejor puntuación 1062.9609747872535\n",
      "Generación 167, x = 32.603082289673985 Mejor puntuación 1062.9609747872535\n",
      "Generación 168, x = 32.581440181969135 Mejor puntuación 1097.7033210460136\n",
      "Generación 169, x = 33.1316060740498 Mejor puntuación 1097.7033210460136\n",
      "Generación 170, x = 32.97265455717506 Mejor puntuación 1097.7033210460136\n",
      "Generación 171, x = 32.91999936951848 Mejor puntuación 1097.7033210460136\n",
      "Generación 172, x = 33.015991496217595 Mejor puntuación 1095.5155569796077\n",
      "Generación 173, x = 33.04076604861021 Mejor puntuación 1093.329975236566\n",
      "Generación 174, x = 33.049024232741075 Mejor puntuación 1124.6032280137456\n",
      "Generación 175, x = 33.17467336995672 Mejor puntuación 1108.3615468895327\n",
      "Generación 176, x = 33.23543339253183 Mejor puntuación 1126.3412130682273\n",
      "Generación 177, x = 33.426535826996854 Mejor puntuación 1126.3412130682273\n",
      "Generación 178, x = 33.49377157897453 Mejor puntuación 1126.3412130682273\n",
      "Generación 179, x = 33.51058051696895 Mejor puntuación 1126.3412130682273\n",
      "Generación 180, x = 33.550145667608945 Mejor puntuación 1125.2132458261115\n",
      "Generación 181, x = 33.534024207382146 Mejor puntuación 1125.6122743177793\n",
      "Generación 182, x = 33.54358409437127 Mejor puntuación 1125.2132458261115\n",
      "Generación 183, x = 33.543891243664525 Mejor puntuación 1189.5154006374391\n",
      "Generación 184, x = 33.54404481831115 Mejor puntuación 1157.140994401636\n",
      "Generación 185, x = 34.01639125448048 Mejor puntuación 1157.120098039059\n",
      "Generación 186, x = 34.01646804180379 Mejor puntuación 1157.1200980390586\n",
      "Generación 187, x = 34.01646804180379 Mejor puntuación 1167.0109097484406\n",
      "Generación 188, x = 34.0890047130314 Mejor puntuación 1162.060242325077\n",
      "Generación 189, x = 34.070870545224494 Mejor puntuación 1162.060242325077\n",
      "Generación 190, x = 34.0890047130314 Mejor puntuación 1162.060242325077\n",
      "Generación 191, x = 34.409760872060396 Mejor puntuación 1162.060242325077\n",
      "Generación 192, x = 34.5185927681009 Mejor puntuación 1221.375342849015\n",
      "Generación 193, x = 34.48241680877358 Mejor puntuación 1202.6310190497586\n",
      "Generación 194, x = 34.56950817311613 Mejor puntuación 1198.5737287292332\n",
      "Generación 195, x = 35.18635784504776 Mejor puntuación 1222.9264134954867\n",
      "Generación 196, x = 35.14379415389851 Mejor puntuación 1238.0797783997539\n",
      "Generación 197, x = 35.06236886539581 Mejor puntuación 1235.0862675315911\n",
      "Generación 198, x = 35.10421200837614 Mejor puntuación 1235.0862675315911\n",
      "Generación 199, x = 35.124003081137325 Mejor puntuación 1235.0862675315911\n",
      "Mejor solución: x = 35.10421200837614, f(x) = 1232.3057007290195\n"
     ]
    }
   ],
   "source": [
    "n_generations = 200\n",
    "\n",
    "for generation in range(n_generations):\n",
    "    scores = np.array([fitness(x) for x in population])\n",
    "    new_population = []\n",
    "    for _ in range(population_size):\n",
    "        parent1 = select_parent_tournament(population, scores)\n",
    "        parent2 = select_parent_tournament(population, scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        child = mutate(child)\n",
    "        new_population.append(child)\n",
    "    population = np.array(new_population)\n",
    "    best_score = np.max(scores)\n",
    "    print(f\"Generación {generation}, x = {child} Mejor puntuación {best_score}\")\n",
    "\n",
    "best_solution = population[np.argmax(scores)]\n",
    "print(f\"Mejor solución: x = {best_solution}, f(x) = {fitness(best_solution)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (MNIST)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicamos la máxima descendencia que queremos \n",
    "# uso 2 para simplemente comprobar que el algoritmo al completo funciona, este valor lo \n",
    "# indicará el usuario desde la interfaz\n",
    "max_desc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS DEL DATASET DE PRUEBA\n",
    "\n",
    "num_channels = 1\n",
    "px_h = 28\n",
    "px_w = 28\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.Grayscale(num_output_channels=num_channels),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (CIFAR100)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# DATOS DEL DATASET DE PRUEBA CIFAR 100\\nnum_channels = 3\\npx_h = 32\\npx_w = 32\\nbatch_size = 128\\nnum_classes = 100\\n\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\n# Preparar los DataLoader para los conjuntos de entrenamiento y validación\\ntransform = transforms.Compose([\\n    transforms.Resize((px_h, px_w)),\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.5,), (0.5,))\\n])\\n\\ntrain_dataset = datasets.CIFAR100(root=\\'./data\\', train=True, download=True, transform=transform)\\nval_dataset = datasets.CIFAR100(root=\\'./data\\', train=False, download=True, transform=transform)\\n\\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\\nval_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# DATOS DEL DATASET DE PRUEBA CIFAR 100\n",
    "num_channels = 3\n",
    "px_h = 32\n",
    "px_w = 32\n",
    "batch_size = 128\n",
    "num_classes = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERACIÓN DE LA RED EN BASE A VECTORES\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprobamos si tenemos acceso a la GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU) está disponible en tu sistema.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA (GPU) está disponible en tu sistema.\")\n",
    "else:\n",
    "    print(\"CUDA (GPU) no está disponible en tu sistema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos una función que sea capaz de crear modelos en base a vectores que representen la arquitectura de la red.\n",
    "De este modo el algorimo evolutivo puede ir adaptando y cambiando la red fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def build_cnn_from_individual(individual):\n",
    "    \"\"\" \n",
    "    Funcion para construir un modelo en base a un diccionario\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    num_layers = individual['num_conv_layers']\n",
    "    fully_connected = int(individual['fully_connected'])\n",
    "    dropout = individual['dropout']\n",
    "    out_channels_previous_layer = num_channels # Imagen de entrada en escala de grises (1 canal para MNIST)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        out_channels = individual['filters'][i]\n",
    "        kernel_size = individual['filter_sizes'][i]\n",
    "        \n",
    "        conv_layer = nn.Conv2d(out_channels_previous_layer, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        layers.append(conv_layer)\n",
    "        if out_channels_previous_layer > 1 or i > 0:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.ReLU())\n",
    "        if i < 2:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        else:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=1))\n",
    "\n",
    "\n",
    "        out_channels_previous_layer = out_channels\n",
    "\n",
    "\n",
    "    # Temporalmente crear un modelo para calcular el tamaño de salida de las capas convolucionales\n",
    "    temp_model = nn.Sequential(*layers)\n",
    "\n",
    "    # Calcular el tamaño de salida usando un tensor dummy\n",
    "    dummy_input = torch.zeros(1, num_channels, px_h, px_w)  # Tamaño de entrada para MNIST\n",
    "    output_size = temp_model(dummy_input).view(-1).shape[0]\n",
    "\n",
    "    # Ahora, sabiendo el tamaño de salida, podemos definir las capas lineales correctamente\n",
    "    layers.append(nn.Flatten())\n",
    "\n",
    "    for i in range(fully_connected):\n",
    "        layers.append(nn.Linear(in_features=output_size, out_features=output_size))\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            dropout-= 1\n",
    "\n",
    "    layers.append(nn.Linear(output_size, num_classes))\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para generar diccionarios para la población inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    \"\"\" \n",
    "    Funcion para generar un diccionario que representa a una arquitectura\n",
    "    \"\"\"\n",
    "    individual = {\n",
    "        'num_conv_layers': random.randint(min_conv_layers, max_conv_layers),\n",
    "        'filters': [],\n",
    "        'filter_sizes': [],\n",
    "        'learning_rate': random.uniform(lr_min, lr_max),\n",
    "        'fully_connected': random.randint(0,2),\n",
    "        'dropout': random.randint(0,2)\n",
    "    }\n",
    "\n",
    "    for _ in range(individual['num_conv_layers']):\n",
    "        individual['filters'].append(random.randint(min_filters, max_filters))\n",
    "        individual['filter_sizes'].append(random.choice(filter_sizes))\n",
    "    \n",
    "    # Agrega más parámetros según sea necesario, como capas completamente conectadas, etc.\n",
    "\n",
    "    return individual\n",
    "\n",
    "def initialize_population(pop_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    return [generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max) for _ in range(pop_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETROS PARA POSIBLES ARQUITECTURAS DE RED\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AJUSTAR SEGÚN VAYA NECESITANDO Y TIEMPO \n",
    "\n",
    "population_size = 5\n",
    "min_conv_layers = 1\n",
    "max_conv_layers = 3\n",
    "min_filters = 16\n",
    "max_filters = 128\n",
    "filter_sizes = [3, 5]\n",
    "lr_min = 0.0001\n",
    "lr_max = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num_conv_layers': 2,\n",
       "  'filters': [110, 34],\n",
       "  'filter_sizes': [5, 3],\n",
       "  'learning_rate': 0.002976203098904704,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 2},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [109, 85, 100],\n",
       "  'filter_sizes': [3, 3, 3],\n",
       "  'learning_rate': 0.0017140537493918137,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 2},\n",
       " {'num_conv_layers': 2,\n",
       "  'filters': [71, 81],\n",
       "  'filter_sizes': [3, 3],\n",
       "  'learning_rate': 0.0006296023309457448,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 0},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [56, 23, 43],\n",
       "  'filter_sizes': [3, 3, 5],\n",
       "  'learning_rate': 0.0028299227244332724,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 0},\n",
       " {'num_conv_layers': 2,\n",
       "  'filters': [83, 39],\n",
       "  'filter_sizes': [3, 5],\n",
       "  'learning_rate': 0.0013931000978306164,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 1}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "population = initialize_population(population_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO Y EVALUACIÓN DE LOS MODELOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def evaluate_individual(individual, train_loader, val_loader, device='cuda', epochs=5):\n",
    "    \"\"\" \n",
    "    Funcion para entrenar y evaluar una arquitectura\n",
    "    \"\"\"\n",
    "    # Construir el modelo basado en el individuo\n",
    "    model = build_cnn_from_individual(individual).to(device)\n",
    "    \n",
    "    # Definir el optimizador y la función de pérdida\n",
    "    # HACER QUE EL OPTIMIZADOR SEA OTRO GEN!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=individual['learning_rate'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch')\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Actualizar la barra de progreso con la última información de pérdida\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item())})\n",
    "            progress_bar.update()  # Forzar la actualización de la barra de progreso\n",
    "            \n",
    "        progress_bar.close()  # Cerrar la barra de progreso al final de cada época\n",
    "\n",
    "    # Evaluación\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy  # Esta es la \"aptitud\" del individuo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUTACIONES Y CRUCES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def mutate_individual(individual):\n",
    "    \"\"\"\n",
    "    Mutar un individuo cambiando aleatoriamente sus hiperparámetros.\n",
    "    \"\"\"\n",
    "    mutation_rate = 0.3  # Probabilidad de mutar cada característica\n",
    "    lr_range = (0.0001, 0.01)\n",
    "    filter_range = (32, 128)  # Rango para el número de filtros\n",
    "    filter_size_range = (1, 7)  # Rango para el tamaño de filtro\n",
    "    fully_connected_range = (0,2) #Rango para ver cuantas fully conected se añaden\n",
    "    dropout_range = (0,2) # Rango para ver cuantos dropouts se añaden\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['learning_rate'] = random.uniform(*lr_range)\n",
    "\n",
    "    # Asegurarse de que hay suficientes entradas en las listas 'filters' y 'filter_sizes'\n",
    "    for i in range(individual['num_conv_layers']):\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el número de filtros en la capa i\n",
    "            individual['filters'][i] = random.randint(*filter_range)\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el tamaño de filtro en la capa i\n",
    "            individual['filter_sizes'][i] = random.randint(*filter_size_range)\n",
    "\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['fully_connected'] = random.uniform(*fully_connected_range)\n",
    "\n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el cruce entre individuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    \"\"\"\n",
    "    Realiza un cruce uniforme entre dos individuos.\n",
    "    \n",
    "    Args:\n",
    "        parent1 (dict): El primer individuo padre.\n",
    "        parent2 (dict): El segundo individuo padre.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un nuevo individuo hijo.\n",
    "    \"\"\"\n",
    "    child = {}\n",
    "    print(f\"Padre 1: {parent1} --- Padre 2: {parent2}\")\n",
    "    for key in parent1:\n",
    "        if key == \"filters\" or key == \"filter_sizes\":\n",
    "            if random.random() < 0.5:\n",
    "                child[\"filters\"] = parent1[\"filters\"]\n",
    "                child[\"filter_sizes\"] = parent1[\"filter_sizes\"]\n",
    "            else:\n",
    "                child[\"filters\"] = parent2[\"filters\"]\n",
    "                child[\"filter_sizes\"] = parent2[\"filter_sizes\"]\n",
    "\n",
    "        else:\n",
    "            if key != \"num_conv_layers\":\n",
    "                if random.random() < 0.5:\n",
    "                    child[key] = parent1[key]\n",
    "                else:\n",
    "                    child[key] = parent2[key]\n",
    "    child[\"num_conv_layers\"] = len(child[\"filters\"])\n",
    "\n",
    "    return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos como evaluamos a la población "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population, train_loader, val_loader, device, epochs):\n",
    "    \"\"\"\n",
    "    Funcion para evaluar a una poblacion de arquitecturas\n",
    "    \"\"\"\n",
    "    fitness_scores = []\n",
    "    \n",
    "    for individual in population:\n",
    "        print(individual)\n",
    "        fitness = evaluate_individual(individual, train_loader, val_loader, device, epochs)\n",
    "        fitness_scores.append(fitness)\n",
    "    \n",
    "    # sacamos los scores de la poblacion\n",
    "    return fitness_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recopilamos lo que hemos realizado, hemos creado las posibles mutaciones sobre las arquitecturas, los posibles cruces, la evaluación de los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queda realizar:\n",
    "- Selección de reproducción: por torneo en principio para también  puede ser por torneo o ruleta\n",
    "- Creación de la nueva generación usando las funciones de mutación y cruces\n",
    "- Criterios de parada\n",
    "- Registro de análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección por torneo\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection_best4(population):\n",
    "    \"\"\"\n",
    "    Selecciona los 4 mejores individuos de la población mediante un torneo de tamaño fijo.\n",
    "\n",
    "    Args:\n",
    "        population: La lista de individuos con sus puntuaciones de fitness.\n",
    "\n",
    "    Returns:\n",
    "        Lista de los 4 mejores individuos.\n",
    "    \"\"\"\n",
    "    winners = []\n",
    "    for _ in range(2):\n",
    "        candidates = random.sample(population, 2)\n",
    "        winner = max(candidates, key=lambda x: x['fitness'])\n",
    "        winners.append(winner)\n",
    "    return winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITMO EVOLUTIVO\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfitness_scores = evaluate_population(population, train_loader, val_loader, device)\\n\\n# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\\npopulation_with_scores = list(zip(population, fitness_scores))\\npopulation_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\\n\\n# Imprimimimos los resultados\\nfor i, (individual, score) in enumerate(population_with_scores):\\n    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fitness_scores = evaluate_population(population, train_loader, val_loader, device)\n",
    "\n",
    "# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\n",
    "population_with_scores = list(zip(population, fitness_scores))\n",
    "population_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\n",
    "\n",
    "# Imprimimimos los resultados\n",
    "for i, (individual, score) in enumerate(population_with_scores):\n",
    "    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = []\n",
    "\n",
    "def genetic_algorithm(population, train_loader, val_loader, device, max_desc, epochs):\n",
    "    \"\"\" \n",
    "    Algoritmo genetico para evolucionar una poblacion de arquitecturas hacia la mejor puntuacion dado un dataset dado\n",
    "    \"\"\"\n",
    "    desc = 0\n",
    "    while desc < max_desc:\n",
    "        print(\"***************************************\")\n",
    "        print()\n",
    "        print(f\"Generation: {desc}\")\n",
    "        print()\n",
    "        print(\"***************************************\")\n",
    "        puntuaciones_aptitud = evaluate_population(population, train_loader, val_loader, device, epochs)\n",
    "\n",
    "        # Ordenamos individuos\n",
    "        # Añadimos las puntuaciones directamente a cada diccionario de la población\n",
    "        for i, puntuacion in enumerate(puntuaciones_aptitud):\n",
    "            population[i]['fitness'] = puntuacion\n",
    "\n",
    "        population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "\n",
    "        # Preservamos el mejor individuo (elitismo)\n",
    "        mejor_individuo = population[0]\n",
    "        top_models.append(mejor_individuo)\n",
    "        # Seleccionamos los 4 mejores (excluyendo el mejor) para el torneo\n",
    "        winners = tournament_selection_best4(population[1:])\n",
    "        print(f\"Los 4 mejores son: \\n {winners}\")\n",
    "\n",
    "        # Realizamos cruce y mutación con descendientes que reemplazan a la población restante\n",
    "        for i in range(1, 2):\n",
    "            descendency = mutate_individual(crossover(winners[i-1], winners[i]))\n",
    "            population[-i] = descendency   # Eliminamos las peores arquitecturas\n",
    "\n",
    "        # Nos aseguramos que mantenemos el mejor de todos\n",
    "        population[0] = mejor_individuo\n",
    "        desc += 1\n",
    "\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTADOS DE LAS ARQUITECTURAS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padre 1: {'num_conv_layers': 3, 'filters': [109, 85, 100], 'filter_sizes': [3, 3, 3], 'learning_rate': 0.0017140537493918137, 'fully_connected': 2, 'dropout': 2} --- Padre 2: {'num_conv_layers': 2, 'filters': [71, 81], 'filter_sizes': [3, 3], 'learning_rate': 0.0006296023309457448, 'fully_connected': 2, 'dropout': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'filters': [104, 56],\n",
       " 'filter_sizes': [3, 1],\n",
       " 'learning_rate': 0.009285076936544713,\n",
       " 'fully_connected': 2,\n",
       " 'dropout': 2,\n",
       " 'num_conv_layers': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = crossover(population[1], population[2])\n",
    "mutate = mutate_individual(sol)\n",
    "mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n",
      "\n",
      "Generation: 0\n",
      "\n",
      "***************************************\n",
      "{'num_conv_layers': 2, 'filters': [110, 34], 'filter_sizes': [5, 3], 'learning_rate': 0.002976203098904704, 'fully_connected': 0, 'dropout': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  85%|████████▌ | 1599/1875 [00:15<00:02, 92.14batch/s, training_loss=0.042] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m population_sol \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_desc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 14\u001b[0m, in \u001b[0;36mgenetic_algorithm\u001b[1;34m(population, train_loader, val_loader, device, max_desc, epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***************************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m puntuaciones_aptitud \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Ordenamos individuos\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Añadimos las puntuaciones directamente a cada diccionario de la población\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, puntuacion \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(puntuaciones_aptitud):\n",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m, in \u001b[0;36mevaluate_population\u001b[1;34m(population, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m individual \u001b[38;5;129;01min\u001b[39;00m population:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(individual)\n\u001b[1;32m----> 9\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_individual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindividual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     fitness_scores\u001b[38;5;241m.\u001b[39mappend(fitness)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# sacamos los scores de la poblacion\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m, in \u001b[0;36mevaluate_individual\u001b[1;34m(individual, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     20\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "population_sol = genetic_algorithm(population, train_loader, val_loader, device, max_desc, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for individual in top_models:\n",
    "    print(f\"Individuo {individual} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
