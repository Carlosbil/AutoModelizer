{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoModelizer\n",
    "---\n",
    "\n",
    "La idea de este proyecto es encontrar el mejor modelo de CNN que se adapte al dataset correspondiente, para ello usando algoritmos evolutivos. Este tipo de soluciones se conocen como neuroevoluciones\n",
    "\n",
    "A continuación un ejemplo básico de como funcionan este tipo de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def fitness(x):\n",
    "    return x ** 2\n",
    "\n",
    "population_size = 10\n",
    "population = np.random.uniform(-10, 10, population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parent_tournament(population, scores, k=3):\n",
    "    selection_ix = np.random.randint(len(population), size=k)\n",
    "    selected = population[selection_ix]\n",
    "    ix = np.argmax(scores[selection_ix])\n",
    "    return selected[ix]\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    child = (p1 + p2) / 2\n",
    "    return child\n",
    "\n",
    "def mutate(x):\n",
    "    mutation_chance = 0.1\n",
    "    if np.random.rand() < mutation_chance:\n",
    "        x += np.random.uniform(-1, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 0, x = 0.5885749889263119 Mejor puntuación 83.1617439721922\n",
      "Generación 1, x = 0.8802927328454446 Mejor puntuación 83.1617439721922\n",
      "Generación 2, x = -4.18031653036261 Mejor puntuación 70.22048717749445\n",
      "Generación 3, x = 0.985332297372925 Mejor puntuación 70.22048717749445\n",
      "Generación 4, x = 8.063307559952024 Mejor puntuación 70.22048717749445\n",
      "Generación 5, x = 8.30065179107639 Mejor puntuación 70.22048717749445\n",
      "Generación 6, x = 8.30065179107639 Mejor puntuación 68.9008201566997\n",
      "Generación 7, x = 8.30065179107639 Mejor puntuación 68.9008201566997\n",
      "Generación 8, x = 7.59562962033025 Mejor puntuación 68.9008201566997\n",
      "Generación 9, x = 8.30065179107639 Mejor puntuación 68.9008201566997\n",
      "Generación 10, x = 8.30065179107639 Mejor puntuación 75.32539405970425\n",
      "Generación 11, x = 9.39909820532981 Mejor puntuación 79.02492252280399\n",
      "Generación 12, x = 9.668023030746955 Mejor puntuación 93.47066932305354\n",
      "Generación 13, x = 9.619919995703928 Mejor puntuación 96.15231697169627\n",
      "Generación 14, x = 9.668023030746955 Mejor puntuación 110.2070506603196\n",
      "Generación 15, x = 9.73687590702496 Mejor puntuación 101.66666339171361\n",
      "Generación 16, x = 9.90132575019583 Mejor puntuación 98.20675937443532\n",
      "Generación 17, x = 9.905629054963207 Mejor puntuación 98.20675937443532\n",
      "Generación 18, x = 9.90132575019583 Mejor puntuación 98.12148697453127\n",
      "Generación 19, x = 10.324396630568467 Mejor puntuación 106.59316578529351\n",
      "Generación 20, x = 10.115012842765836 Mejor puntuación 106.59316578529351\n",
      "Generación 21, x = 10.27205068361781 Mejor puntuación 106.59316578529351\n",
      "Generación 22, x = 10.29822365709314 Mejor puntuación 106.59316578529351\n",
      "Generación 23, x = 10.311310143830802 Mejor puntuación 106.59316578529351\n",
      "Generación 24, x = 10.725631823445744 Mejor puntuación 106.323116882268\n",
      "Generación 25, x = 10.518470983638274 Mejor puntuación 115.03917801211206\n",
      "Generación 26, x = 10.518470983638274 Mejor puntuación 129.8797488725003\n",
      "Generación 27, x = 11.125187288581984 Mejor puntuación 129.8797488725003\n",
      "Generación 28, x = 10.931580221926058 Mejor puntuación 129.8797488725003\n",
      "Generación 29, x = 11.472505410372998 Mejor puntuación 144.32251475266315\n",
      "Generación 30, x = 12.050480774239487 Mejor puntuación 157.04231700683957\n",
      "Generación 31, x = 12.050480774239487 Mejor puntuación 157.04231700683957\n",
      "Generación 32, x = 12.29106668950875 Mejor puntuación 151.07032036595157\n",
      "Generación 33, x = 12.29106668950875 Mejor puntuación 151.07032036595157\n",
      "Generación 34, x = 12.836297992538416 Mejor puntuación 151.07032036595157\n",
      "Generación 35, x = 12.29106668950875 Mejor puntuación 164.77054615324576\n",
      "Generación 36, x = 12.563682341023583 Mejor puntuación 157.8461139661478\n",
      "Generación 37, x = 12.563682341023583 Mejor puntuación 176.62559590332037\n",
      "Generación 38, x = 12.74527582555844 Mejor puntuación 167.10395016023205\n",
      "Generación 39, x = 12.29907018932737 Mejor puntuación 186.17212301048932\n",
      "Generación 40, x = 13.285679941799563 Mejor puntuación 176.50929151593525\n",
      "Generación 41, x = 13.173278098306138 Mejor puntuación 176.50929151593525\n",
      "Generación 42, x = 13.285679941799563 Mejor puntuación 182.47447872782246\n",
      "Generación 43, x = 13.392111599594626 Mejor puntuación 179.47949392271764\n",
      "Generación 44, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 45, x = 13.394553652351973 Mejor puntuación 179.47949392271764\n",
      "Generación 46, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 47, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 48, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 49, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 50, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 51, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 52, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 53, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 54, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 55, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 56, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 57, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 58, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 59, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 60, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 61, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 62, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 63, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 64, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 65, x = 13.396995705109322 Mejor puntuación 179.47949392271764\n",
      "Generación 66, x = 13.396995705109322 Mejor puntuación 185.93956641100397\n",
      "Generación 67, x = 13.45673825736164 Mejor puntuación 206.14491829898353\n",
      "Generación 68, x = 13.975551313761262 Mejor puntuación 202.8800823992468\n",
      "Generación 69, x = 14.05217223926278 Mejor puntuación 199.6227962926904\n",
      "Generación 70, x = 14.109574629037294 Mejor puntuación 203.69720391771693\n",
      "Generación 71, x = 14.195718417300935 Mejor puntuación 230.29492248149413\n",
      "Generación 72, x = 15.133819782300145 Mejor puntuación 230.29492248149413\n",
      "Generación 73, x = 15.077944865394144 Mejor puntuación 256.0549600397683\n",
      "Generación 74, x = 15.008505052212284 Mejor puntuación 256.0549600397683\n",
      "Generación 75, x = 16.184171201523416 Mejor puntuación 267.866413693432\n",
      "Generación 76, x = 16.092944305297245 Mejor puntuación 267.866413693432\n",
      "Generación 77, x = 16.57137054512083 Mejor puntuación 281.4380712753916\n",
      "Generación 78, x = 17.029372976188355 Mejor puntuación 307.4056982024924\n",
      "Generación 79, x = 17.45361250073764 Mejor puntuación 307.4056982024924\n",
      "Generación 80, x = 17.31247579068593 Mejor puntuación 304.62858932590524\n",
      "Generación 81, x = 17.45361250073764 Mejor puntuación 307.3442389344681\n",
      "Generación 82, x = 17.478694067275583 Mejor puntuación 305.9849077746833\n",
      "Generación 83, x = 17.478694067275583 Mejor puntuación 305.9849077746833\n",
      "Generación 84, x = 17.482126624623845 Mejor puntuación 305.74477990624916\n",
      "Generación 85, x = 17.483842903297976 Mejor puntuación 305.74477990624916\n",
      "Generación 86, x = 17.484701042635045 Mejor puntuación 314.30103666606647\n",
      "Generación 87, x = 17.54587465498546 Mejor puntuación 310.0081486882953\n",
      "Generación 88, x = 18.075250531368 Mejor puntuación 310.0081486882953\n",
      "Generación 89, x = 17.841149399351938 Mejor puntuación 326.71468177171914\n",
      "Generación 90, x = 17.841149399351938 Mejor puntuación 318.306611889996\n",
      "Generación 91, x = 17.841149399351938 Mejor puntuación 318.306611889996\n",
      "Generación 92, x = 17.346411371834154 Mejor puntuación 318.306611889996\n",
      "Generación 93, x = 17.841149399351938 Mejor puntuación 318.306611889996\n",
      "Generación 94, x = 17.904040069861725 Mejor puntuación 318.306611889996\n",
      "Generación 95, x = 17.87259473460683 Mejor puntuación 320.5546508232143\n",
      "Generación 96, x = 18.11655567782354 Mejor puntuación 335.95485419940144\n",
      "Generación 97, x = 18.32907128578536 Mejor puntuación 335.95485419940144\n",
      "Generación 98, x = 18.32907128578536 Mejor puntuación 335.95485419940144\n",
      "Generación 99, x = 18.32907128578536 Mejor puntuación 335.95485419940144\n",
      "Generación 100, x = 18.32907128578536 Mejor puntuación 335.95485419940144\n",
      "Generación 101, x = 18.755616051430025 Mejor puntuación 367.9552936121153\n",
      "Generación 102, x = 18.755616051430025 Mejor puntuación 351.7731334686596\n",
      "Generación 103, x = 18.755616051430025 Mejor puntuación 351.7731334686596\n",
      "Generación 104, x = 19.159999908425185 Mejor puntuación 382.76511212064315\n",
      "Generación 105, x = 19.362191836922765 Mejor puntuación 382.76511212064315\n",
      "Generación 106, x = 19.463287801171553 Mejor puntuación 382.76511212064315\n",
      "Generación 107, x = 19.463287801171553 Mejor puntuación 378.8195720312334\n",
      "Generación 108, x = 19.87485991863718 Mejor puntuación 411.53932475541836\n",
      "Generación 109, x = 19.87485991863718 Mejor puntuación 395.01005678545073\n",
      "Generación 110, x = 19.87485991863718 Mejor puntuación 395.01005678545073\n",
      "Generación 111, x = 20.20022296319302 Mejor puntuación 421.29968096149565\n",
      "Generación 112, x = 20.63789644366795 Mejor puntuación 425.9227696195623\n",
      "Generación 113, x = 20.63789644366795 Mejor puntuación 425.9227696195623\n",
      "Generación 114, x = 20.609818834688177 Mejor puntuación 425.9227696195623\n",
      "Generación 115, x = 20.623857639178063 Mejor puntuación 425.9227696195623\n",
      "Generación 116, x = 20.889910193646017 Mejor puntuación 436.3883478985958\n",
      "Generación 117, x = 20.87971247945957 Mejor puntuación 436.3883478985958\n",
      "Generación 118, x = 20.823397055029027 Mejor puntuación 436.3883478985958\n",
      "Generación 119, x = 20.884811336552794 Mejor puntuación 448.3412692345852\n",
      "Generación 120, x = 21.019852152537275 Mejor puntuación 442.2373891568027\n",
      "Generación 121, x = 21.025283937974145 Mejor puntuación 442.2373891568027\n",
      "Generación 122, x = 21.672609109938218 Mejor puntuación 477.51487784659525\n",
      "Generación 123, x = 21.562092920199465 Mejor puntuación 477.51487784659525\n",
      "Generación 124, x = 21.70424419389658 Mejor puntuación 473.6003762552936\n",
      "Generación 125, x = 21.76236145861229 Mejor puntuación 473.6003762552936\n",
      "Generación 126, x = 21.83531672867069 Mejor puntuación 479.97238197029736\n",
      "Generación 127, x = 21.908271998729095 Mejor puntuación 479.97238197029736\n",
      "Generación 128, x = 21.89003318121449 Mejor puntuación 485.3116327827804\n",
      "Generación 129, x = 21.908271998729095 Mejor puntuación 500.37988959985574\n",
      "Generación 130, x = 22.044757195366852 Mejor puntuación 490.12302840903135\n",
      "Generación 131, x = 22.084144931033755 Mejor puntuación 490.12302840903135\n",
      "Generación 132, x = 23.208348684401592 Mejor puntuación 528.3646664181733\n",
      "Generación 133, x = 22.35058784418334 Mejor puntuación 538.6274486567651\n",
      "Generación 134, x = 23.046874841576773 Mejor puntuación 538.6274486567651\n",
      "Generación 135, x = 23.046874841576773 Mejor puntuación 531.1584399633044\n",
      "Generación 136, x = 22.378258911540733 Mejor puntuación 531.1584399633044\n",
      "Generación 137, x = 23.32326597919568 Mejor puntuación 531.1584399633044\n",
      "Generación 138, x = 23.046874841576773 Mejor puntuación 543.9747359363065\n",
      "Generación 139, x = 23.185070410386224 Mejor puntuación 537.5474899345668\n",
      "Generación 140, x = 23.614251823111278 Mejor puntuación 578.0866817661191\n",
      "Generación 141, x = 23.82546294773374 Mejor puntuación 577.761700460681\n",
      "Generación 142, x = 23.931068510044973 Mejor puntuación 577.761700460681\n",
      "Generación 143, x = 23.931068510044973 Mejor puntuación 621.1360115800915\n",
      "Generación 144, x = 24.20535287753529 Mejor puntuación 596.6702419253068\n",
      "Generación 145, x = 24.701572144201943 Mejor puntuación 623.8160524511084\n",
      "Generación 146, x = 24.564203304035967 Mejor puntuación 610.1676663952134\n",
      "Generación 147, x = 24.701572144201943 Mejor puntuación 610.1676663952134\n",
      "Generación 148, x = 24.701572144201943 Mejor puntuación 610.1676663952134\n",
      "Generación 149, x = 24.701572144201943 Mejor puntuación 610.1676663952134\n",
      "Generación 150, x = 24.701572144201943 Mejor puntuación 610.1676663952134\n",
      "Generación 151, x = 24.701572144201943 Mejor puntuación 610.1676663952134\n",
      "Generación 152, x = 23.734873523741545 Mejor puntuación 610.1676663952134\n",
      "Generación 153, x = 24.701572144201943 Mejor puntuación 610.1676663952134\n",
      "Generación 154, x = 25.04818756408224 Mejor puntuación 656.4814655850561\n",
      "Generación 155, x = 25.008611825620147 Mejor puntuación 650.6758494774978\n",
      "Generación 156, x = 25.30665450337387 Mejor puntuación 647.7827108828434\n",
      "Generación 157, x = 25.393308358343944 Mejor puntuación 647.7827108828434\n",
      "Generación 158, x = 25.47854078156025 Mejor puntuación 645.5791109470498\n",
      "Generación 159, x = 25.400778617194547 Mejor puntuación 649.1560403576287\n",
      "Generación 160, x = 25.418538421775647 Mejor puntuación 647.3663404143441\n",
      "Generación 161, x = 25.434608340613316 Mejor puntuación 647.3663404143441\n",
      "Generación 162, x = 24.984789717673056 Mejor puntuación 647.3663404143441\n",
      "Generación 163, x = 25.443394828802703 Mejor puntuación 647.3663404143441\n",
      "Generación 164, x = 25.443394828802703 Mejor puntuación 695.0480900520986\n",
      "Generación 165, x = 25.69762313736858 Mejor puntuación 670.9954450504571\n",
      "Generación 166, x = 25.903579772889636 Mejor puntuación 670.9954450504571\n",
      "Generación 167, x = 25.903579772889636 Mejor puntuación 682.1261439366507\n",
      "Generación 168, x = 26.342146042304567 Mejor puntuación 678.7522446329001\n",
      "Generación 169, x = 26.337145739606996 Mejor puntuación 709.8267140892839\n",
      "Generación 170, x = 26.33964589095578 Mejor puntuación 709.8267140892839\n",
      "Generación 171, x = 26.56886092338928 Mejor puntuación 709.8267140892839\n",
      "Generación 172, x = 26.56886092338928 Mejor puntuación 709.8267140892839\n",
      "Generación 173, x = 26.79270286394516 Mejor puntuación 747.8536456632921\n",
      "Generación 174, x = 26.717638101146882 Mejor puntuación 747.8536456632921\n",
      "Generación 175, x = 27.25426343690738 Mejor puntuación 747.8536456632921\n",
      "Generación 176, x = 26.43293858696408 Mejor puntuación 743.0460189100185\n",
      "Generación 177, x = 27.74390073532331 Mejor puntuación 797.0752046559606\n",
      "Generación 178, x = 28.011931870320907 Mejor puntuación 797.0752046559606\n",
      "Generación 179, x = 28.232520338360878 Mejor puntuación 797.0752046559606\n",
      "Generación 180, x = 28.232520338360878 Mejor puntuación 797.0752046559606\n",
      "Generación 181, x = 28.232520338360878 Mejor puntuación 797.0752046559606\n",
      "Generación 182, x = 28.232520338360878 Mejor puntuación 797.0752046559606\n",
      "Generación 183, x = 28.232520338360878 Mejor puntuación 825.6267441759711\n",
      "Generación 184, x = 28.357820598041993 Mejor puntuación 811.2881737956611\n",
      "Generación 185, x = 28.14728533793185 Mejor puntuación 811.2881737956611\n",
      "Generación 186, x = 28.483120857723108 Mejor puntuación 831.701215222643\n",
      "Generación 187, x = 28.48818938570277 Mejor puntuación 821.462990991703\n",
      "Generación 188, x = 28.661175673578065 Mejor puntuación 821.462990991703\n",
      "Generación 189, x = 28.661175673578065 Mejor puntuación 821.462990991703\n",
      "Generación 190, x = 28.661175673578065 Mejor puntuación 821.462990991703\n",
      "Generación 191, x = 28.661175673578065 Mejor puntuación 821.462990991703\n",
      "Generación 192, x = 28.661175673578065 Mejor puntuación 821.462990991703\n",
      "Generación 193, x = 28.7335572563806 Mejor puntuación 829.7821124067594\n",
      "Generación 194, x = 29.912415491133956 Mejor puntuación 850.0838763643901\n",
      "Generación 195, x = 29.156197906523925 Mejor puntuación 894.7526005142306\n",
      "Generación 196, x = 29.2395921401406 Mejor puntuación 872.2752721804922\n",
      "Generación 197, x = 29.825636342073153 Mejor puntuación 872.2752721804922\n",
      "Generación 198, x = 29.825636342073153 Mejor puntuación 928.1814526153207\n",
      "Generación 199, x = 30.305961971649737 Mejor puntuación 928.1814526153207\n",
      "Mejor solución: x = 30.305961971649737, f(x) = 918.45133102708\n"
     ]
    }
   ],
   "source": [
    "n_generations = 200\n",
    "\n",
    "for generation in range(n_generations):\n",
    "    scores = np.array([fitness(x) for x in population])\n",
    "    new_population = []\n",
    "    for _ in range(population_size):\n",
    "        parent1 = select_parent_tournament(population, scores)\n",
    "        parent2 = select_parent_tournament(population, scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        child = mutate(child)\n",
    "        new_population.append(child)\n",
    "    population = np.array(new_population)\n",
    "    best_score = np.max(scores)\n",
    "    print(f\"Generación {generation}, x = {child} Mejor puntuación {best_score}\")\n",
    "\n",
    "best_solution = population[np.argmax(scores)]\n",
    "print(f\"Mejor solución: x = {best_solution}, f(x) = {fitness(best_solution)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (MNIST)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicamos la máxima descendencia que queremos \n",
    "# uso 2 para simplemente comprobar que el algoritmo al completo funciona, este valor lo \n",
    "# indicará el usuario desde la interfaz\n",
    "max_desc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS DEL DATASET DE PRUEBA\n",
    "\n",
    "num_channels = 1\n",
    "px_h = 28\n",
    "px_w = 28\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.Grayscale(num_output_channels=num_channels),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (CIFAR100)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DATOS DEL DATASET DE PRUEBA CIFAR 100\n",
    "num_channels = 3\n",
    "px_h = 32\n",
    "px_w = 32\n",
    "batch_size = 128\n",
    "num_classes = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERACIÓN DE LA RED EN BASE A VECTORES\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprobamos si tenemos acceso a la GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU) está disponible en tu sistema.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA (GPU) está disponible en tu sistema.\")\n",
    "else:\n",
    "    print(\"CUDA (GPU) no está disponible en tu sistema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos una función que sea capaz de crear modelos en base a vectores que representen la arquitectura de la red.\n",
    "De este modo el algorimo evolutivo puede ir adaptando y cambiando la red fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def build_cnn_from_individual(individual):\n",
    "    \"\"\" \n",
    "    Funcion para construir un modelo en base a un diccionario\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    num_layers = individual['num_conv_layers']\n",
    "    fully_connected = int(individual['fully_connected'])\n",
    "    dropout = individual['dropout']\n",
    "    out_channels_previous_layer = num_channels # Imagen de entrada en escala de grises (1 canal para MNIST)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        out_channels = individual['filters'][i]\n",
    "        kernel_size = individual['filter_sizes'][i]\n",
    "        \n",
    "        conv_layer = nn.Conv2d(out_channels_previous_layer, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        layers.append(conv_layer)\n",
    "        if out_channels_previous_layer > 1 or i > 0:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.ReLU())\n",
    "        if i < 2:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        else:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=1))\n",
    "\n",
    "\n",
    "        out_channels_previous_layer = out_channels\n",
    "\n",
    "\n",
    "    # Temporalmente crear un modelo para calcular el tamaño de salida de las capas convolucionales\n",
    "    temp_model = nn.Sequential(*layers)\n",
    "\n",
    "    # Calcular el tamaño de salida usando un tensor dummy\n",
    "    dummy_input = torch.zeros(1, num_channels, px_h, px_w)  # Tamaño de entrada para MNIST\n",
    "    output_size = temp_model(dummy_input).view(-1).shape[0]\n",
    "\n",
    "    # Ahora, sabiendo el tamaño de salida, podemos definir las capas lineales correctamente\n",
    "    layers.append(nn.Flatten())\n",
    "\n",
    "    for i in range(fully_connected):\n",
    "        layers.append(nn.Linear(in_features=output_size, out_features=output_size))\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            dropout-= 1\n",
    "\n",
    "    layers.append(nn.Linear(output_size, num_classes))\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para generar diccionarios para la población inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    \"\"\" \n",
    "    Funcion para generar un diccionario que representa a una arquitectura\n",
    "    \"\"\"\n",
    "    individual = {\n",
    "        'num_conv_layers': random.randint(min_conv_layers, max_conv_layers),\n",
    "        'filters': [],\n",
    "        'filter_sizes': [],\n",
    "        'learning_rate': random.uniform(lr_min, lr_max),\n",
    "        'fully_connected': random.randint(0,2),\n",
    "        'dropout': random.randint(0,2)\n",
    "    }\n",
    "\n",
    "    for _ in range(individual['num_conv_layers']):\n",
    "        individual['filters'].append(random.randint(min_filters, max_filters))\n",
    "        individual['filter_sizes'].append(random.choice(filter_sizes))\n",
    "    \n",
    "    # Agrega más parámetros según sea necesario, como capas completamente conectadas, etc.\n",
    "\n",
    "    return individual\n",
    "\n",
    "def initialize_population(pop_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    return [generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max) for _ in range(pop_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETROS PARA POSIBLES ARQUITECTURAS DE RED\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AJUSTAR SEGÚN VAYA NECESITANDO Y TIEMPO \n",
    "\n",
    "population_size = 5\n",
    "min_conv_layers = 1\n",
    "max_conv_layers = 3\n",
    "min_filters = 16\n",
    "max_filters = 128\n",
    "filter_sizes = [3, 5]\n",
    "lr_min = 0.0001\n",
    "lr_max = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num_conv_layers': 2,\n",
       "  'filters': [61, 73],\n",
       "  'filter_sizes': [5, 5],\n",
       "  'learning_rate': 0.007183141440140548,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 0},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [43, 113, 104],\n",
       "  'filter_sizes': [3, 5, 3],\n",
       "  'learning_rate': 0.006330265646269987,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [58, 44, 114],\n",
       "  'filter_sizes': [5, 3, 3],\n",
       "  'learning_rate': 0.007689148251452704,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [19, 117, 98],\n",
       "  'filter_sizes': [5, 3, 5],\n",
       "  'learning_rate': 0.005342586552922331,\n",
       "  'fully_connected': 1,\n",
       "  'dropout': 2},\n",
       " {'num_conv_layers': 2,\n",
       "  'filters': [68, 114],\n",
       "  'filter_sizes': [5, 5],\n",
       "  'learning_rate': 0.009602168837477255,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 2}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "population = initialize_population(population_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO Y EVALUACIÓN DE LOS MODELOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def evaluate_individual(individual, train_loader, val_loader, device='cuda', epochs=5):\n",
    "    \"\"\" \n",
    "    Funcion para entrenar y evaluar una arquitectura\n",
    "    \"\"\"\n",
    "    # Construir el modelo basado en el individuo\n",
    "    model = build_cnn_from_individual(individual).to(device)\n",
    "    \n",
    "    # Definir el optimizador y la función de pérdida\n",
    "    # HACER QUE EL OPTIMIZADOR SEA OTRO GEN!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=individual['learning_rate'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch')\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Actualizar la barra de progreso con la última información de pérdida\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item())})\n",
    "            progress_bar.update()  # Forzar la actualización de la barra de progreso\n",
    "            \n",
    "        progress_bar.close()  # Cerrar la barra de progreso al final de cada época\n",
    "\n",
    "    # Evaluación\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy  # Esta es la \"aptitud\" del individuo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUTACIONES Y CRUCES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def mutate_individual(individual):\n",
    "    \"\"\"\n",
    "    Mutar un individuo cambiando aleatoriamente sus hiperparámetros.\n",
    "    \"\"\"\n",
    "    mutation_rate = 0.3  # Probabilidad de mutar cada característica\n",
    "    lr_range = (0.0001, 0.01)\n",
    "    filter_range = (32, 128)  # Rango para el número de filtros\n",
    "    filter_size_range = (1, 7)  # Rango para el tamaño de filtro\n",
    "    fully_connected_range = (0,2) #Rango para ver cuantas fully conected se añaden\n",
    "    dropout_range = (0,2) # Rango para ver cuantos dropouts se añaden\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['learning_rate'] = random.uniform(*lr_range)\n",
    "\n",
    "    # Asegurarse de que hay suficientes entradas en las listas 'filters' y 'filter_sizes'\n",
    "    for i in range(individual['num_conv_layers']):\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el número de filtros en la capa i\n",
    "            individual['filters'][i] = random.randint(*filter_range)\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el tamaño de filtro en la capa i\n",
    "            individual['filter_sizes'][i] = random.randint(*filter_size_range)\n",
    "\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['fully_connected'] = random.uniform(*fully_connected_range)\n",
    "\n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el cruce entre individuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    \"\"\"\n",
    "    Realiza un cruce uniforme entre dos individuos.\n",
    "    \n",
    "    Args:\n",
    "        parent1 (dict): El primer individuo padre.\n",
    "        parent2 (dict): El segundo individuo padre.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un nuevo individuo hijo.\n",
    "    \"\"\"\n",
    "    child = {}\n",
    "    print(f\"Padre 1: {parent1} --- Padre 2: {parent2}\")\n",
    "    for key in parent1:\n",
    "        if key == \"filters\" or key == \"filter_sizes\":\n",
    "            if random.random() < 0.5:\n",
    "                child[\"filters\"] = parent1[\"filters\"]\n",
    "                child[\"filter_sizes\"] = parent1[\"filter_sizes\"]\n",
    "            else:\n",
    "                child[\"filters\"] = parent2[\"filters\"]\n",
    "                child[\"filter_sizes\"] = parent2[\"filter_sizes\"]\n",
    "\n",
    "        else:\n",
    "            if key != \"num_conv_layers\":\n",
    "                if random.random() < 0.5:\n",
    "                    child[key] = parent1[key]\n",
    "                else:\n",
    "                    child[key] = parent2[key]\n",
    "    child[\"num_conv_layers\"] = len(child[\"filters\"])\n",
    "\n",
    "    return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos como evaluamos a la población "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population, train_loader, val_loader, device, epochs):\n",
    "    \"\"\"\n",
    "    Funcion para evaluar a una poblacion de arquitecturas\n",
    "    \"\"\"\n",
    "    fitness_scores = []\n",
    "    \n",
    "    for individual in population:\n",
    "        print(individual)\n",
    "        fitness = evaluate_individual(individual, train_loader, val_loader, device, epochs)\n",
    "        fitness_scores.append(fitness)\n",
    "    \n",
    "    # sacamos los scores de la poblacion\n",
    "    return fitness_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recopilamos lo que hemos realizado, hemos creado las posibles mutaciones sobre las arquitecturas, los posibles cruces, la evaluación de los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queda realizar:\n",
    "- Selección de reproducción: por torneo en principio para también  puede ser por torneo o ruleta\n",
    "- Creación de la nueva generación usando las funciones de mutación y cruces\n",
    "- Criterios de parada\n",
    "- Registro de análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección por torneo\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection_best4(population):\n",
    "    \"\"\"\n",
    "    Selecciona los 4 mejores individuos de la población mediante un torneo de tamaño fijo.\n",
    "\n",
    "    Args:\n",
    "        population: La lista de individuos con sus puntuaciones de fitness.\n",
    "\n",
    "    Returns:\n",
    "        Lista de los 4 mejores individuos.\n",
    "    \"\"\"\n",
    "    winners = []\n",
    "    for _ in range(2):\n",
    "        candidates = random.sample(population, 2)\n",
    "        winner = max(candidates, key=lambda x: x['fitness'])\n",
    "        winners.append(winner)\n",
    "    return winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITMO EVOLUTIVO\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfitness_scores = evaluate_population(population, train_loader, val_loader, device)\\n\\n# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\\npopulation_with_scores = list(zip(population, fitness_scores))\\npopulation_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\\n\\n# Imprimimimos los resultados\\nfor i, (individual, score) in enumerate(population_with_scores):\\n    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fitness_scores = evaluate_population(population, train_loader, val_loader, device)\n",
    "\n",
    "# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\n",
    "population_with_scores = list(zip(population, fitness_scores))\n",
    "population_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\n",
    "\n",
    "# Imprimimimos los resultados\n",
    "for i, (individual, score) in enumerate(population_with_scores):\n",
    "    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = []\n",
    "\n",
    "def genetic_algorithm(population, train_loader, val_loader, device, max_desc, epochs):\n",
    "    \"\"\" \n",
    "    Algoritmo genetico para evolucionar una poblacion de arquitecturas hacia la mejor puntuacion dado un dataset dado\n",
    "    \"\"\"\n",
    "    desc = 0\n",
    "    while desc < max_desc:\n",
    "        print(\"***************************************\")\n",
    "        print()\n",
    "        print(f\"Generation: {desc}\")\n",
    "        print()\n",
    "        print(\"***************************************\")\n",
    "        puntuaciones_aptitud = evaluate_population(population, train_loader, val_loader, device, epochs)\n",
    "\n",
    "        # Ordenamos individuos\n",
    "        # Añadimos las puntuaciones directamente a cada diccionario de la población\n",
    "        for i, puntuacion in enumerate(puntuaciones_aptitud):\n",
    "            population[i]['fitness'] = puntuacion\n",
    "\n",
    "        population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "\n",
    "        # Preservamos el mejor individuo (elitismo)\n",
    "        mejor_individuo = population[0]\n",
    "        top_models.append(mejor_individuo)\n",
    "        # Seleccionamos los 4 mejores (excluyendo el mejor) para el torneo\n",
    "        winners = tournament_selection_best4(population[1:])\n",
    "        print(f\"Los 4 mejores son: \\n {winners}\")\n",
    "\n",
    "        # Realizamos cruce y mutación con descendientes que reemplazan a la población restante\n",
    "        for i in range(1, 2):\n",
    "            descendency = mutate_individual(crossover(winners[i-1], winners[i]))\n",
    "            population[-i] = descendency   # Eliminamos las peores arquitecturas\n",
    "\n",
    "        # Nos aseguramos que mantenemos el mejor de todos\n",
    "        population[0] = mejor_individuo\n",
    "        desc += 1\n",
    "\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTADOS DE LAS ARQUITECTURAS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padre 1: {'num_conv_layers': 3, 'filters': [43, 113, 104], 'filter_sizes': [3, 5, 3], 'learning_rate': 0.006330265646269987, 'fully_connected': 0, 'dropout': 1} --- Padre 2: {'num_conv_layers': 3, 'filters': [58, 44, 114], 'filter_sizes': [5, 3, 3], 'learning_rate': 0.007689148251452704, 'fully_connected': 0, 'dropout': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'filters': [63, 44, 114],\n",
       " 'filter_sizes': [5, 3, 3],\n",
       " 'learning_rate': 0.007689148251452704,\n",
       " 'fully_connected': 0,\n",
       " 'dropout': 1,\n",
       " 'num_conv_layers': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = crossover(population[1], population[2])\n",
    "mutate = mutate_individual(sol)\n",
    "mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n",
      "\n",
      "Generation: 0\n",
      "\n",
      "***************************************\n",
      "{'num_conv_layers': 2, 'filters': [61, 73], 'filter_sizes': [5, 5], 'learning_rate': 0.007183141440140548, 'fully_connected': 2, 'dropout': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/391 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:14<00:00, 26.97batch/s, training_loss=4.511]  \n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:14<00:00, 27.46batch/s, training_loss=4.023]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:14<00:00, 27.52batch/s, training_loss=3.772]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:14<00:00, 27.30batch/s, training_loss=3.131]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:14<00:00, 26.83batch/s, training_loss=3.451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [43, 113, 104], 'filter_sizes': [3, 5, 3], 'learning_rate': 0.006330265646269987, 'fully_connected': 0, 'dropout': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:13<00:00, 28.30batch/s, training_loss=3.055]\n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:13<00:00, 28.23batch/s, training_loss=2.405]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:13<00:00, 28.04batch/s, training_loss=2.294]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:14<00:00, 27.65batch/s, training_loss=2.015]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:13<00:00, 28.09batch/s, training_loss=1.523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [63, 44, 114], 'filter_sizes': [5, 3, 3], 'learning_rate': 0.007689148251452704, 'fully_connected': 0, 'dropout': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:13<00:00, 28.12batch/s, training_loss=3.400]\n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:14<00:00, 26.80batch/s, training_loss=2.904]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:15<00:00, 24.82batch/s, training_loss=3.082]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:14<00:00, 27.77batch/s, training_loss=3.024]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:13<00:00, 27.98batch/s, training_loss=2.175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [19, 117, 98], 'filter_sizes': [5, 3, 5], 'learning_rate': 0.005342586552922331, 'fully_connected': 1, 'dropout': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:14<00:00, 27.54batch/s, training_loss=3.902]\n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:13<00:00, 29.69batch/s, training_loss=3.670]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:14<00:00, 27.69batch/s, training_loss=3.017]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:13<00:00, 28.24batch/s, training_loss=2.946]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:14<00:00, 27.69batch/s, training_loss=2.840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 2, 'filters': [68, 114], 'filter_sizes': [5, 5], 'learning_rate': 0.009602168837477255, 'fully_connected': 2, 'dropout': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:17<00:00, 22.52batch/s, training_loss=5.610]  \n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:16<00:00, 23.13batch/s, training_loss=5.187]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:16<00:00, 23.28batch/s, training_loss=4.937]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:17<00:00, 22.78batch/s, training_loss=4.750]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:17<00:00, 21.92batch/s, training_loss=4.610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 4 mejores son: \n",
      " [{'num_conv_layers': 3, 'filters': [63, 44, 114], 'filter_sizes': [5, 3, 3], 'learning_rate': 0.007689148251452704, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.3646}, {'num_conv_layers': 3, 'filters': [19, 117, 98], 'filter_sizes': [5, 3, 5], 'learning_rate': 0.005342586552922331, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.3065}]\n",
      "Padre 1: {'num_conv_layers': 3, 'filters': [63, 44, 114], 'filter_sizes': [5, 3, 3], 'learning_rate': 0.007689148251452704, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.3646} --- Padre 2: {'num_conv_layers': 3, 'filters': [19, 117, 98], 'filter_sizes': [5, 3, 5], 'learning_rate': 0.005342586552922331, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.3065}\n",
      "***************************************\n",
      "\n",
      "Generation: 1\n",
      "\n",
      "***************************************\n",
      "{'num_conv_layers': 3, 'filters': [43, 113, 104], 'filter_sizes': [3, 5, 3], 'learning_rate': 0.006330265646269987, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.4358}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:13<00:00, 28.45batch/s, training_loss=3.290]\n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:13<00:00, 28.33batch/s, training_loss=2.768]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:14<00:00, 27.87batch/s, training_loss=2.099]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:14<00:00, 27.77batch/s, training_loss=1.820]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:13<00:00, 28.65batch/s, training_loss=2.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [63, 44, 114], 'filter_sizes': [5, 3, 3], 'learning_rate': 0.007689148251452704, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.3646}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:13<00:00, 28.84batch/s, training_loss=3.493]\n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:13<00:00, 29.94batch/s, training_loss=2.916]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:12<00:00, 31.54batch/s, training_loss=2.565]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:13<00:00, 30.03batch/s, training_loss=2.055]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:12<00:00, 30.21batch/s, training_loss=1.760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [19, 79, 71], 'filter_sizes': [7, 3, 5], 'learning_rate': 0.005342586552922331, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.3065}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:13<00:00, 28.79batch/s, training_loss=3.645]\n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:13<00:00, 28.43batch/s, training_loss=3.423]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:13<00:00, 29.48batch/s, training_loss=2.956]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:14<00:00, 27.31batch/s, training_loss=2.812]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:18<00:00, 21.38batch/s, training_loss=2.676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 2, 'filters': [61, 73], 'filter_sizes': [5, 5], 'learning_rate': 0.007183141440140548, 'fully_connected': 2, 'dropout': 0, 'fitness': 0.2286}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:14<00:00, 27.04batch/s, training_loss=4.653]  \n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:14<00:00, 27.60batch/s, training_loss=4.245]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:14<00:00, 27.35batch/s, training_loss=3.827]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:14<00:00, 27.48batch/s, training_loss=3.284]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:13<00:00, 27.99batch/s, training_loss=3.401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filters': [19, 79, 71], 'filter_sizes': [7, 3, 5], 'learning_rate': 0.007689148251452704, 'fully_connected': 0.10240066604609788, 'dropout': 2, 'fitness': 0.3646, 'num_conv_layers': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:12<00:00, 30.19batch/s, training_loss=3.026]\n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:12<00:00, 31.97batch/s, training_loss=2.814]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:12<00:00, 32.18batch/s, training_loss=2.437]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:11<00:00, 33.72batch/s, training_loss=2.152]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:12<00:00, 31.56batch/s, training_loss=2.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 4 mejores son: \n",
      " [{'filters': [19, 79, 71], 'filter_sizes': [7, 3, 5], 'learning_rate': 0.007689148251452704, 'fully_connected': 0.10240066604609788, 'dropout': 2, 'fitness': 0.4096, 'num_conv_layers': 3}, {'num_conv_layers': 3, 'filters': [19, 79, 71], 'filter_sizes': [7, 3, 5], 'learning_rate': 0.005342586552922331, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.3361}]\n",
      "Padre 1: {'filters': [19, 79, 71], 'filter_sizes': [7, 3, 5], 'learning_rate': 0.007689148251452704, 'fully_connected': 0.10240066604609788, 'dropout': 2, 'fitness': 0.4096, 'num_conv_layers': 3} --- Padre 2: {'num_conv_layers': 3, 'filters': [19, 79, 71], 'filter_sizes': [7, 3, 5], 'learning_rate': 0.005342586552922331, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.3361}\n"
     ]
    }
   ],
   "source": [
    "population_sol = genetic_algorithm(population, train_loader, val_loader, device, max_desc, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuo {'num_conv_layers': 3, 'filters': [43, 113, 104], 'filter_sizes': [3, 5, 3], 'learning_rate': 0.006330265646269987, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.4294} \n",
      "Individuo {'num_conv_layers': 3, 'filters': [43, 113, 104], 'filter_sizes': [3, 5, 3], 'learning_rate': 0.006330265646269987, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.4294} \n"
     ]
    }
   ],
   "source": [
    "for individual in top_models:\n",
    "    print(f\"Individuo {individual} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
