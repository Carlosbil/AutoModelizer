{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoModelizer\n",
    "---\n",
    "\n",
    "La idea de este proyecto es encontrar el mejor modelo de CNN que se adapte al dataset correspondiente, para ello usando algoritmos evolutivos. Este tipo de soluciones se conocen como neuroevoluciones\n",
    "\n",
    "A continuación un ejemplo básico de como funcionan este tipo de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def fitness(x):\n",
    "    return x ** 2\n",
    "\n",
    "population_size = 10\n",
    "population = np.random.uniform(-10, 10, population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parent_tournament(population, scores, k=3):\n",
    "    selection_ix = np.random.randint(len(population), size=k)\n",
    "    selected = population[selection_ix]\n",
    "    ix = np.argmax(scores[selection_ix])\n",
    "    return selected[ix]\n",
    "\n",
    "def crossover_test(p1, p2):\n",
    "    child = (p1 + p2) / 2\n",
    "    return child\n",
    "\n",
    "def mutate(x):\n",
    "    mutation_chance = 0.1\n",
    "    if np.random.rand() < mutation_chance:\n",
    "        x += np.random.uniform(-1, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 0, x = -2.545145224286 Mejor puntuación 77.5139441787222\n",
      "Generación 1, x = -7.099297315995722 Mejor puntuación 50.40002238090406\n",
      "Generación 2, x = -7.255826324782765 Mejor puntuación 52.64701565541057\n",
      "Generación 3, x = -7.255826324782765 Mejor puntuación 61.51468546295035\n",
      "Generación 4, x = -7.510345823049895 Mejor puntuación 56.99461920862995\n",
      "Generación 5, x = -7.549478075246656 Mejor puntuación 56.99461920862995\n",
      "Generación 6, x = -7.539695012197465 Mejor puntuación 56.99461920862995\n",
      "Generación 7, x = -7.539695012197465 Mejor puntuación 56.847000876955335\n",
      "Generación 8, x = -7.93508753838905 Mejor puntuación 69.39689810637539\n",
      "Generación 9, x = -7.737391275293257 Mejor puntuación 65.72387141659577\n",
      "Generación 10, x = -7.965193292455915 Mejor puntuación 65.72387141659577\n",
      "Generación 11, x = -8.03610967249899 Mejor puntuación 65.72387141659577\n",
      "Generación 12, x = -7.707081023309344 Mejor puntuación 65.72387141659577\n",
      "Generación 13, x = -8.096279895407502 Mejor puntuación 65.72387141659577\n",
      "Generación 14, x = -9.0327311230416 Mejor puntuación 81.59023154116437\n",
      "Generación 15, x = -9.032053851914235 Mejor puntuación 81.59023154116437\n",
      "Generación 16, x = -8.915336084023656 Mejor puntuación 81.57799678387876\n",
      "Generación 17, x = -9.307861833887802 Mejor puntuación 94.09751927500898\n",
      "Generación 18, x = -9.338833484035291 Mejor puntuación 87.72609053516582\n",
      "Generación 19, x = -9.366220717833091 Mejor puntuación 87.72609053516582\n",
      "Generación 20, x = -9.366220717833091 Mejor puntuación 87.72609053516582\n",
      "Generación 21, x = -9.366220717833091 Mejor puntuación 87.72609053516582\n",
      "Generación 22, x = -9.366220717833091 Mejor puntuación 87.72609053516582\n",
      "Generación 23, x = -9.366220717833091 Mejor puntuación 87.72609053516582\n",
      "Generación 24, x = -9.366220717833091 Mejor puntuación 87.72609053516582\n",
      "Generación 25, x = -9.366220717833091 Mejor puntuación 87.72609053516582\n",
      "Generación 26, x = -9.366220717833091 Mejor puntuación 94.2837411662986\n",
      "Generación 27, x = -10.818831151022739 Mejor puntuación 103.18806211308781\n",
      "Generación 28, x = -9.60717376271918 Mejor puntuación 117.04710747434\n",
      "Generación 29, x = -9.935790049727494 Mejor puntuación 106.78078781592438\n",
      "Generación 30, x = -10.255972557447933 Mejor puntuación 106.78078781592438\n",
      "Generación 31, x = -10.759091657329066 Mejor puntuación 125.96599929308577\n",
      "Generación 32, x = -10.759091657329066 Mejor puntuación 115.7580532908079\n",
      "Generación 33, x = -10.759091657329066 Mejor puntuación 115.7580532908079\n",
      "Generación 34, x = -10.759091657329066 Mejor puntuación 115.7580532908079\n",
      "Generación 35, x = -10.759091657329066 Mejor puntuación 115.7580532908079\n",
      "Generación 36, x = -10.759091657329066 Mejor puntuación 115.7580532908079\n",
      "Generación 37, x = -10.759091657329066 Mejor puntuación 115.7580532908079\n",
      "Generación 38, x = -10.759091657329066 Mejor puntuación 115.7580532908079\n",
      "Generación 39, x = -10.759091657329066 Mejor puntuación 115.7580532908079\n",
      "Generación 40, x = -10.759091657329066 Mejor puntuación 115.7580532908079\n",
      "Generación 41, x = -10.97997323971722 Mejor puntuación 125.45914874588121\n",
      "Generación 42, x = -10.869532448523142 Mejor puntuación 120.55981234490625\n",
      "Generación 43, x = -10.97997323971722 Mejor puntuación 120.55981234490625\n",
      "Generación 44, x = -10.97997323971722 Mejor puntuación 120.55981234490625\n",
      "Generación 45, x = -11.082674239198035 Mejor puntuación 134.78168636376705\n",
      "Generación 46, x = -11.320437626891337 Mejor puntuación 134.78168636376705\n",
      "Generación 47, x = -11.33327525182644 Mejor puntuación 145.06686559071045\n",
      "Generación 48, x = -11.678907668909705 Mejor puntuación 139.87700904589497\n",
      "Generación 49, x = -11.678907668909707 Mejor puntuación 155.22508918432706\n",
      "Generación 50, x = -12.45893611767582 Mejor puntuación 155.22508918432706\n",
      "Generación 51, x = -12.826990391279736 Mejor puntuación 155.22508918432706\n",
      "Generación 52, x = -12.32193412346409 Mejor puntuación 164.53168249798267\n",
      "Generación 53, x = -12.563746541122168 Mejor puntuación 158.84732537727007\n",
      "Generación 54, x = -12.580493300390437 Mejor puntuación 158.84732537727007\n",
      "Generación 55, x = -12.560629766282204 Mejor puntuación 158.84732537727007\n",
      "Generación 56, x = -13.196138673224432 Mejor puntuación 174.13807588296947\n",
      "Generación 57, x = -12.8969303052967 Mejor puntuación 174.13807588296947\n",
      "Generación 58, x = -13.046534489260566 Mejor puntuación 170.24952657518057\n",
      "Generación 59, x = -13.4987000698201 Mejor puntuación 194.6266523949424\n",
      "Generación 60, x = -13.499058999757153 Mejor puntuación 194.6266523949424\n",
      "Generación 61, x = -13.94683561488665 Mejor puntuación 194.6266523949424\n",
      "Generación 62, x = -14.297879751096659 Mejor puntuación 214.4729159308902\n",
      "Generación 63, x = -14.294437187752356 Mejor puntuación 214.33029519184328\n",
      "Generación 64, x = -14.64002374287157 Mejor puntuación 214.33029519184328\n",
      "Generación 65, x = -14.64002374287157 Mejor puntuación 214.33029519184328\n",
      "Generación 66, x = -15.401656773822493 Mejor puntuación 214.33029519184328\n",
      "Generación 67, x = -15.201499684293168 Mejor puntuación 237.2110313786323\n",
      "Generación 68, x = -15.010941514790133 Mejor puntuación 231.0855926515653\n",
      "Generación 69, x = -15.010941514790133 Mejor puntuación 231.0855926515653\n",
      "Generación 70, x = -15.128803027784919 Mejor puntuación 229.56448123714242\n",
      "Generación 71, x = -15.151385456028185 Mejor puntuación 229.56448123714242\n",
      "Generación 72, x = -15.299605884790342 Mejor puntuación 238.63533781368497\n",
      "Generación 73, x = -15.225495670409263 Mejor puntuación 234.07794022991126\n",
      "Generación 74, x = -15.262550777599802 Mejor puntuación 234.07794022991126\n",
      "Generación 75, x = -16.00066116995514 Mejor puntuación 256.02115787571023\n",
      "Generación 76, x = -14.717070769956075 Mejor puntuación 256.02115787571023\n",
      "Generación 77, x = -16.687854338262593 Mejor puntuación 278.48448241506964\n",
      "Generación 78, x = -16.030004836607866 Mejor puntuación 278.48448241506964\n",
      "Generación 79, x = -16.472240090862933 Mejor puntuación 278.48448241506964\n",
      "Generación 80, x = -16.58004721456276 Mejor puntuación 278.48448241506964\n",
      "Generación 81, x = -16.510145860618586 Mejor puntuación 302.0466277675642\n",
      "Generación 82, x = -17.182733304579664 Mejor puntuación 302.0466277675642\n",
      "Generación 83, x = -16.513308134341752 Mejor puntuación 302.0466277675642\n",
      "Generación 84, x = -17.379488708462173 Mejor puntuación 302.0466277675642\n",
      "Generación 85, x = -17.379488708462173 Mejor puntuación 302.0466277675642\n",
      "Generación 86, x = -17.379488708462173 Mejor puntuación 302.0466277675642\n",
      "Generación 87, x = -17.379488708462173 Mejor puntuación 302.0466277675642\n",
      "Generación 88, x = -17.682055321000483 Mejor puntuación 323.4466260923248\n",
      "Generación 89, x = -17.682055321000483 Mejor puntuación 312.6550803749215\n",
      "Generación 90, x = -17.682055321000483 Mejor puntuación 347.25995541668203\n",
      "Generación 91, x = -18.15848379692345 Mejor puntuación 329.73053380313144\n",
      "Generación 92, x = -18.72823727257151 Mejor puntuación 362.19656719117313\n",
      "Generación 93, x = -18.66160522563807 Mejor puntuación 362.19656719117313\n",
      "Generación 94, x = -18.66160522563807 Mejor puntuación 356.44873287064723\n",
      "Generación 95, x = -18.966510796994914 Mejor puntuación 367.19351222031685\n",
      "Generación 96, x = -19.064402409950688 Mejor puntuación 367.19351222031685\n",
      "Generación 97, x = -19.091682996312013 Mejor puntuación 367.19351222031685\n",
      "Generación 98, x = -19.162294022906465 Mejor puntuación 399.6919836022757\n",
      "Generación 99, x = -19.694071242246064 Mejor puntuación 399.6919836022757\n",
      "Generación 100, x = -18.95718506593662 Mejor puntuación 399.6919836022757\n",
      "Generación 101, x = -19.694071242246064 Mejor puntuación 410.0484855893489\n",
      "Generación 102, x = -20.335952043676357 Mejor puntuación 425.4106219527627\n",
      "Generación 103, x = -20.335952043676357 Mejor puntuación 441.49966306152515\n",
      "Generación 104, x = -20.386760704620166 Mejor puntuación 429.5144903008908\n",
      "Generación 105, x = -20.978988378387164 Mejor puntuación 456.09741117694136\n",
      "Generación 106, x = -21.93549056610957 Mejor puntuación 456.09741117694136\n",
      "Generación 107, x = -21.265011642566577 Mejor puntuación 481.165746375882\n",
      "Generación 108, x = -21.623107501301853 Mejor puntuación 468.5477530850189\n",
      "Generación 109, x = -21.62237334501347 Mejor puntuación 472.0963058471659\n",
      "Generación 110, x = -21.631398493793952 Mejor puntuación 470.3203561084354\n",
      "Generación 111, x = -21.661991592912628 Mejor puntuación 469.82480298898514\n",
      "Generación 112, x = -21.668716993610552 Mejor puntuación 469.56121554950147\n",
      "Generación 113, x = -21.669361216923342 Mejor puntuación 469.56121554950147\n",
      "Generación 114, x = -21.669361216923342 Mejor puntuación 469.56121554950147\n",
      "Generación 115, x = -22.072416538445147 Mejor puntuación 505.14683532816616\n",
      "Generación 116, x = -22.072416538445147 Mejor puntuación 495.6403501337509\n",
      "Generación 117, x = -22.120057806146065 Mejor puntuación 495.6403501337509\n",
      "Generación 118, x = -22.2153403415479 Mejor puntuación 493.52134649080557\n",
      "Generación 119, x = -22.167699073846983 Mejor puntuación 516.05042740795\n",
      "Generación 120, x = -22.418400566827813 Mejor puntuación 516.05042740795\n",
      "Generación 121, x = -22.50477542337469 Mejor puntuación 547.6868188698172\n",
      "Generación 122, x = -22.805883613233384 Mejor puntuación 532.124273625725\n",
      "Generación 123, x = -23.34254433916668 Mejor puntuación 557.9665663680856\n",
      "Generación 124, x = -23.392831217820536 Mejor puntuación 549.5797860852451\n",
      "Generación 125, x = -22.478661693394773 Mejor puntuación 547.224552385439\n",
      "Generación 126, x = -23.579724860677707 Mejor puntuación 564.8761968182076\n",
      "Generación 127, x = -24.053531738798803 Mejor puntuación 592.4326398588245\n",
      "Generación 128, x = -25.293369670822408 Mejor puntuación 592.4326398588245\n",
      "Generación 129, x = -25.293369670822408 Mejor puntuación 639.7545493048789\n",
      "Generación 130, x = -24.72974135915442 Mejor puntuación 639.7545493048789\n",
      "Generación 131, x = -24.867882167084236 Mejor puntuación 625.3011850269306\n",
      "Generación 132, x = -24.99786743530221 Mejor puntuación 645.9313478084281\n",
      "Generación 133, x = -25.10423433045939 Mejor puntuación 645.9313478084281\n",
      "Generación 134, x = -25.41517947621909 Mejor puntuación 670.1564093559673\n",
      "Generación 135, x = -25.672248645352113 Mejor puntuación 660.1414450320145\n",
      "Generación 136, x = -25.672248645352113 Mejor puntuación 659.0643505087834\n",
      "Generación 137, x = -26.060518556781744 Mejor puntuación 699.538411436191\n",
      "Generación 138, x = -26.628811830346137 Mejor puntuación 699.538411436191\n",
      "Generación 139, x = -26.44173267142135 Mejor puntuación 709.0936194959824\n",
      "Generación 140, x = -26.39672683088766 Mejor puntuación 709.0936194959824\n",
      "Generación 141, x = -26.4659995408857 Mejor puntuación 704.1206734285208\n",
      "Generación 142, x = -26.489384435751298 Mejor puntuación 704.1206734285208\n",
      "Generación 143, x = -26.50670261325081 Mejor puntuación 703.5236789081553\n",
      "Generación 144, x = -26.51839506068361 Mejor puntuación 703.5236789081553\n",
      "Generación 145, x = -27.426037225031585 Mejor puntuación 752.1875178688182\n",
      "Generación 146, x = -27.253288439850675 Mejor puntuación 752.1875178688182\n",
      "Generación 147, x = -27.339662832441128 Mejor puntuación 752.1875178688182\n",
      "Generación 148, x = -27.47560208871618 Mejor puntuación 747.4571637915628\n",
      "Generación 149, x = -27.93233683861738 Mejor puntuación 754.9087101374649\n",
      "Generación 150, x = -27.669984649598018 Mejor puntuación 780.2154412659817\n",
      "Generación 151, x = -27.93233683861738 Mejor puntuación 780.2154412659817\n",
      "Generación 152, x = -27.93233683861738 Mejor puntuación 780.2154412659817\n",
      "Generación 153, x = -27.996257371172103 Mejor puntuación 791.0587103293997\n",
      "Generación 154, x = -28.021134362870903 Mejor puntuación 786.5787529006527\n",
      "Generación 155, x = -28.029051394799524 Mejor puntuación 786.103165586424\n",
      "Generación 156, x = -28.031171389770797 Mejor puntuación 786.103165586424\n",
      "Generación 157, x = -28.036471377198975 Mejor puntuación 786.103165586424\n",
      "Generación 158, x = -28.036471377198975 Mejor puntuación 786.0437272844974\n",
      "Generación 159, x = -28.036471377198975 Mejor puntuación 816.9898758942397\n",
      "Generación 160, x = -28.309753066875313 Mejor puntuación 801.4421187074562\n",
      "Generación 161, x = -28.309753066875313 Mejor puntuación 801.4421187074562\n",
      "Generación 162, x = -28.309753066875313 Mejor puntuación 829.7552439476643\n",
      "Generación 163, x = -28.8054724652741 Mejor puntuación 829.7552439476643\n",
      "Generación 164, x = -28.74350754047425 Mejor puntuación 829.7552439476643\n",
      "Generación 165, x = -28.74350754047425 Mejor puntuación 851.6024928139365\n",
      "Generación 166, x = -28.962868299411518 Mejor puntuación 851.6024928139365\n",
      "Generación 167, x = -29.12738886861447 Mejor puntuación 892.0749456706236\n",
      "Generación 168, x = -29.35357771953928 Mejor puntuación 931.7077054729004\n",
      "Generación 169, x = -30.024406918744475 Mejor puntuación 901.4650108223511\n",
      "Generación 170, x = -30.024406918744475 Mejor puntuación 901.4650108223511\n",
      "Generación 171, x = -30.024406918744475 Mejor puntuación 901.4650108223511\n",
      "Generación 172, x = -30.024406918744475 Mejor puntuación 901.4650108223511\n",
      "Generación 173, x = -30.21883816304063 Mejor puntuación 924.9669560432474\n",
      "Generación 174, x = -30.121622540892552 Mejor puntuación 913.1781799240408\n",
      "Generación 175, x = -30.41845288916455 Mejor puntuación 943.4286243559502\n",
      "Generación 176, x = -30.628303111419033 Mejor puntuación 966.3627647851002\n",
      "Generación 177, x = -30.423570637229833 Mejor puntuación 966.3627647851002\n",
      "Generación 178, x = -30.888367308295 Mejor puntuación 956.0089949233762\n",
      "Generación 179, x = -30.810952911965888 Mejor puntuación 957.1540051179493\n",
      "Generación 180, x = -30.919395125444744 Mejor puntuación 956.5814143609163\n",
      "Generación 181, x = -30.9286503805277 Mejor puntuación 956.5814143609163\n",
      "Generación 182, x = -30.9286503805277 Mejor puntuación 956.5814143609163\n",
      "Generación 183, x = -30.9286503805277 Mejor puntuación 956.5814143609163\n",
      "Generación 184, x = -30.9286503805277 Mejor puntuación 956.5814143609163\n",
      "Generación 185, x = -30.9286503805277 Mejor puntuación 956.5814143609163\n",
      "Generación 186, x = -30.9286503805277 Mejor puntuación 993.1551989646867\n",
      "Generación 187, x = -31.79336706046186 Mejor puntuación 989.5147069870296\n",
      "Generación 188, x = -31.444362217171914 Mejor puntuación 1010.8181890412612\n",
      "Generación 189, x = -31.677819908708997 Mejor puntuación 1003.4842741686001\n",
      "Generación 190, x = -31.948930890912898 Mejor puntuación 1038.1310983053997\n",
      "Generación 191, x = -31.93571588224194 Mejor puntuación 1020.7341850723284\n",
      "Generación 192, x = -31.94562713874516 Mejor puntuación 1020.7341850723284\n",
      "Generación 193, x = -31.948930890912898 Mejor puntuación 1020.7341850723284\n",
      "Generación 194, x = -31.64906494309319 Mejor puntuación 1020.7341850723284\n",
      "Generación 195, x = -31.948930890912898 Mejor puntuación 1020.7341850723284\n",
      "Generación 196, x = -31.948930890912898 Mejor puntuación 1020.7341850723284\n",
      "Generación 197, x = -31.948930890912898 Mejor puntuación 1020.7341850723284\n",
      "Generación 198, x = -32.20171034210917 Mejor puntuación 1053.2939077437675\n",
      "Generación 199, x = -32.20171034210917 Mejor puntuación 1036.950148957101\n",
      "Mejor solución: x = -32.20171034210917, f(x) = 1036.950148957101\n"
     ]
    }
   ],
   "source": [
    "n_generations = 200\n",
    "\n",
    "for generation in range(n_generations):\n",
    "    scores = np.array([fitness(x) for x in population])\n",
    "    new_population = []\n",
    "    for _ in range(population_size):\n",
    "        parent1 = select_parent_tournament(population, scores)\n",
    "        parent2 = select_parent_tournament(population, scores)\n",
    "        child = crossover_test(parent1, parent2)\n",
    "        child = mutate(child)\n",
    "        new_population.append(child)\n",
    "    population = np.array(new_population)\n",
    "    best_score = np.max(scores)\n",
    "    print(f\"Generación {generation}, x = {child} Mejor puntuación {best_score}\")\n",
    "\n",
    "best_solution = population[np.argmax(scores)]\n",
    "print(f\"Mejor solución: x = {best_solution}, f(x) = {fitness(best_solution)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (MNIST)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicamos la máxima descendencia que queremos \n",
    "# uso 2 para simplemente comprobar que el algoritmo al completo funciona, este valor lo \n",
    "# indicará el usuario desde la interfaz\n",
    "max_desc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS DEL DATASET DE PRUEBA\n",
    "\n",
    "num_channels = 1\n",
    "px_h = 28\n",
    "px_w = 28\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.Grayscale(num_output_channels=num_channels),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (CIFAR100)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DATOS DEL DATASET DE PRUEBA CIFAR 100\n",
    "num_channels = 3\n",
    "px_h = 32\n",
    "px_w = 32\n",
    "batch_size = 128\n",
    "num_classes = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERACIÓN DE LA RED EN BASE A VECTORES\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprobamos si tenemos acceso a la GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU) está disponible en tu sistema.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA (GPU) está disponible en tu sistema.\")\n",
    "else:\n",
    "    print(\"CUDA (GPU) no está disponible en tu sistema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos una función que sea capaz de crear modelos en base a vectores que representen la arquitectura de la red.\n",
    "De este modo el algorimo evolutivo puede ir adaptando y cambiando la red fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "filter_range = [8,16,32,64,128]\n",
    "kernel_size_range = [1,3,5,7,11] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def build_cnn_from_individual(individual):\n",
    "    \"\"\" \n",
    "    Funcion para construir un modelo en base a un diccionario\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    num_layers = individual['num_conv_layers']\n",
    "    fully_connected = int(individual['fully_connected'])\n",
    "    dropout = individual['dropout']\n",
    "    out_channels_previous_layer = num_channels # Imagen de entrada en escala de grises (1 canal para MNIST)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        out_channels = individual['filters'][i]\n",
    "        kernel_size = individual['kernel_sizes'][i]\n",
    "        \n",
    "        conv_layer = nn.Conv2d(out_channels_previous_layer, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        layers.append(conv_layer)\n",
    "        if out_channels_previous_layer > 1 or i > 0:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.ReLU())\n",
    "        if i < 1:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        else:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=1))\n",
    "\n",
    "\n",
    "        out_channels_previous_layer = out_channels\n",
    "\n",
    "\n",
    "    # Temporalmente crear un modelo para calcular el tamaño de salida de las capas convolucionales\n",
    "    temp_model = nn.Sequential(*layers)\n",
    "\n",
    "    # Calcular el tamaño de salida usando un tensor dummy\n",
    "    dummy_input = torch.zeros(1, num_channels, px_h, px_w)\n",
    "    output_size = temp_model(dummy_input).view(-1).shape[0]\n",
    "\n",
    "    # Ahora, sabiendo el tamaño de salida, podemos definir las capas lineales correctamente\n",
    "    layers.append(nn.Flatten())\n",
    "\n",
    "    for i in range(fully_connected):\n",
    "        layers.append(nn.Linear(in_features=output_size, out_features=output_size))\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            dropout-= 1\n",
    "\n",
    "    layers.append(nn.Linear(output_size, num_classes))\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para generar diccionarios para la población inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, kernel_sizes):\n",
    "    \"\"\" \n",
    "    Funcion para generar un diccionario que representa a una arquitectura\n",
    "    \"\"\"\n",
    "    individual = {\n",
    "        'num_conv_layers': random.randint(min_conv_layers, max_conv_layers),\n",
    "        'filters': [],\n",
    "        'kernel_sizes': [],\n",
    "        'learning_rate': random.choice(learning_rates),\n",
    "        'fully_connected': random.randint(0,2),\n",
    "        'dropout': random.randint(0,2)\n",
    "    }\n",
    "\n",
    "    for _ in range(individual['num_conv_layers']):\n",
    "        individual['filters'].append(random.choice(filter_range))\n",
    "        individual['kernel_sizes'].append(random.choice(kernel_size_range))\n",
    "    \n",
    "    # Agrega más parámetros según sea necesario, como capas completamente conectadas, etc.\n",
    "\n",
    "    return individual\n",
    "\n",
    "def initialize_population(pop_size, min_conv_layers, max_conv_layers, min_filters, max_filters, kernel_sizes):\n",
    "    return [generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, kernel_sizes) for _ in range(pop_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETROS PARA POSIBLES ARQUITECTURAS DE RED\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AJUSTAR SEGÚN VAYA NECESITANDO Y TIEMPO \n",
    "\n",
    "population_size = 10\n",
    "min_conv_layers = 1\n",
    "max_conv_layers = 3\n",
    "min_filters = 16\n",
    "max_filters = 128\n",
    "kernel_sizes = [3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num_conv_layers': 2,\n",
       "  'filters': [8, 32],\n",
       "  'kernel_sizes': [3, 5],\n",
       "  'learning_rate': 0.01,\n",
       "  'fully_connected': 1,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 2,\n",
       "  'filters': [8, 8],\n",
       "  'kernel_sizes': [1, 1],\n",
       "  'learning_rate': 0.1,\n",
       "  'fully_connected': 1,\n",
       "  'dropout': 0},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [32, 128, 64],\n",
       "  'kernel_sizes': [3, 1, 5],\n",
       "  'learning_rate': 0.1,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 0},\n",
       " {'num_conv_layers': 1,\n",
       "  'filters': [128],\n",
       "  'kernel_sizes': [3],\n",
       "  'learning_rate': 0.001,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [8, 32, 8],\n",
       "  'kernel_sizes': [11, 5, 3],\n",
       "  'learning_rate': 0.001,\n",
       "  'fully_connected': 1,\n",
       "  'dropout': 1}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "population = initialize_population(population_size, min_conv_layers, max_conv_layers, min_filters, max_filters, kernel_sizes)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO Y EVALUACIÓN DE LOS MODELOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def evaluate_individual(individual, train_loader, val_loader, device='cuda', epochs=5):\n",
    "    \"\"\" \n",
    "    Funcion para entrenar y evaluar una arquitectura\n",
    "    \"\"\"\n",
    "    # Construir el modelo basado en el individuo\n",
    "    model = build_cnn_from_individual(individual).to(device)\n",
    "    \n",
    "    # Definir el optimizador y la función de pérdida\n",
    "    # HACER QUE EL OPTIMIZADOR SEA OTRO GEN!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=individual['learning_rate'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch')\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Actualizar la barra de progreso con la última información de pérdida\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item())})\n",
    "            progress_bar.update()  # Forzar la actualización de la barra de progreso\n",
    "            \n",
    "        progress_bar.close()  # Cerrar la barra de progreso al final de cada época\n",
    "\n",
    "    # Evaluación\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy  # Esta es la \"aptitud\" del individuo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUTACIONES Y CRUCES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def mutate_individual(individual):\n",
    "    \"\"\"\n",
    "    Mutar un individuo cambiando aleatoriamente sus hiperparámetros.\n",
    "    \"\"\"\n",
    "    mutation_rate = 0.3  # Probabilidad de mutar cada característica\n",
    "    fully_connected_range = (0,5) #Rango para ver cuantas fully conected se añaden\n",
    "\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['learning_rate'] = random.choice(learning_rates)\n",
    "\n",
    "\n",
    "    # Asegurarse de que hay suficientes entradas en las listas 'filters' y 'kernel_sizes'\n",
    "    for i in range(individual['num_conv_layers']):\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el número de filtros en la capa i\n",
    "            individual['filters'][i] = random.choice(filter_range)\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el tamaño de filtro en la capa i\n",
    "            individual['kernel_sizes'][i] = random.choice(kernel_size_range)\n",
    "\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        num_fully = random.randint(*fully_connected_range)\n",
    "        individual['fully_connected'] = num_fully\n",
    "        individual['dropout'] = random.randint(0, num_fully)\n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el cruce entre individuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    \"\"\"\n",
    "    Realiza un cruce uniforme entre dos individuos.\n",
    "    \n",
    "    Args:\n",
    "        parent1 (dict): El primer individuo padre.\n",
    "        parent2 (dict): El segundo individuo padre.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un nuevo individuo hijo.\n",
    "    \"\"\"\n",
    "    child = {}\n",
    "    for key in parent1:\n",
    "        if key == \"filters\" or key == \"kernel_sizes\":\n",
    "            if random.random() < 0.5:\n",
    "                child[\"filters\"] = parent1[\"filters\"]\n",
    "                child[\"kernel_sizes\"] = parent1[\"kernel_sizes\"]\n",
    "            else:\n",
    "                child[\"filters\"] = parent2[\"filters\"]\n",
    "                child[\"kernel_sizes\"] = parent2[\"kernel_sizes\"]\n",
    "\n",
    "        else:\n",
    "            if key != \"num_conv_layers\":\n",
    "                if random.random() < 0.5:\n",
    "                    child[key] = parent1[key]\n",
    "                else:\n",
    "                    child[key] = parent2[key]\n",
    "    child[\"num_conv_layers\"] = len(child[\"filters\"])\n",
    "\n",
    "    return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos como evaluamos a la población "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population, train_loader, val_loader, device, epochs):\n",
    "    \"\"\"\n",
    "    Funcion para evaluar a una poblacion de arquitecturas\n",
    "    \"\"\"\n",
    "    fitness_scores = []\n",
    "    \n",
    "    for individual in population:\n",
    "        print(individual)\n",
    "        fitness = evaluate_individual(individual, train_loader, val_loader, device, epochs)\n",
    "        fitness_scores.append(fitness)\n",
    "    \n",
    "    # sacamos los scores de la poblacion\n",
    "    return fitness_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recopilamos lo que hemos realizado, hemos creado las posibles mutaciones sobre las arquitecturas, los posibles cruces, la evaluación de los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queda realizar:\n",
    "- Selección de reproducción: por torneo en principio para también  puede ser por torneo o ruleta\n",
    "- Creación de la nueva generación usando las funciones de mutación y cruces\n",
    "- Criterios de parada\n",
    "- Registro de análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección por torneo\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection_best4(population):\n",
    "    \"\"\"\n",
    "    Selecciona los 4 mejores individuos de la población mediante un torneo de tamaño fijo.\n",
    "\n",
    "    Args:\n",
    "        population: La lista de individuos con sus puntuaciones de fitness.\n",
    "\n",
    "    Returns:\n",
    "        Lista de los 4 mejores individuos.\n",
    "    \"\"\"\n",
    "    winners = []\n",
    "    for _ in range(2):\n",
    "        candidates = random.sample(population, 2)\n",
    "        winner = max(candidates, key=lambda x: x['fitness'])\n",
    "        winners.append(winner)\n",
    "    return winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITMO EVOLUTIVO\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfitness_scores = evaluate_population(population, train_loader, val_loader, device)\\n\\n# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\\npopulation_with_scores = list(zip(population, fitness_scores))\\npopulation_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\\n\\n# Imprimimimos los resultados\\nfor i, (individual, score) in enumerate(population_with_scores):\\n    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fitness_scores = evaluate_population(population, train_loader, val_loader, device)\n",
    "\n",
    "# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\n",
    "population_with_scores = list(zip(population, fitness_scores))\n",
    "population_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\n",
    "\n",
    "# Imprimimimos los resultados\n",
    "for i, (individual, score) in enumerate(population_with_scores):\n",
    "    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = []\n",
    "\n",
    "def genetic_algorithm(population, train_loader, val_loader, device, max_desc, epochs):\n",
    "    \"\"\" \n",
    "    Algoritmo genetico para evolucionar una poblacion de arquitecturas hacia la mejor puntuacion dado un dataset dado\n",
    "    \"\"\"\n",
    "    desc = 0\n",
    "    while desc < max_desc:\n",
    "        print(\"***************************************\")\n",
    "        print()\n",
    "        print(f\"Generation: {desc}\")\n",
    "        print()\n",
    "        print(\"***************************************\")\n",
    "        puntuaciones_aptitud = evaluate_population(population, train_loader, val_loader, device, epochs)\n",
    "\n",
    "        # Ordenamos individuos\n",
    "        # Añadimos las puntuaciones directamente a cada diccionario de la población\n",
    "        for i, puntuacion in enumerate(puntuaciones_aptitud):\n",
    "            population[i]['fitness'] = puntuacion\n",
    "\n",
    "        population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "\n",
    "        # Preservamos el mejor individuo (elitismo)\n",
    "        mejor_individuo = population[0]\n",
    "        top_models.append(mejor_individuo)\n",
    "        # Seleccionamos los 4 mejores (excluyendo el mejor) para el torneo\n",
    "        winners = tournament_selection_best4(population[1:])\n",
    "        print(f\"Los 4 mejores son: \\n {winners}\")\n",
    "\n",
    "        # Realizamos cruce y mutación con descendientes que reemplazan a la población restante\n",
    "        for i in range(1, 5):\n",
    "            descendency = mutate_individual(crossover(winners[i-1], winners[i]))\n",
    "            population[-i] = descendency   # Eliminamos las peores arquitecturas\n",
    "        \n",
    "        # Nos aseguramos que mantenemos el mejor de todos\n",
    "        population[0] = mejor_individuo\n",
    "        desc += 1\n",
    "\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTADOS DE LAS ARQUITECTURAS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n",
      "\n",
      "Generation: 0\n",
      "\n",
      "***************************************\n",
      "{'num_conv_layers': 2, 'filters': [8, 32], 'kernel_sizes': [3, 5], 'learning_rate': 0.01, 'fully_connected': 1, 'dropout': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:14<00:00, 27.58batch/s, training_loss=4.664]  \n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:13<00:00, 28.31batch/s, training_loss=4.494]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:14<00:00, 27.67batch/s, training_loss=4.563]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:13<00:00, 28.10batch/s, training_loss=4.666]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:13<00:00, 28.07batch/s, training_loss=4.542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 2, 'filters': [8, 8], 'kernel_sizes': [1, 1], 'learning_rate': 0.1, 'fully_connected': 1, 'dropout': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:12<00:00, 30.69batch/s, training_loss=17.351] \n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:13<00:00, 28.97batch/s, training_loss=19.076]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:13<00:00, 29.27batch/s, training_loss=10.369]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:12<00:00, 32.08batch/s, training_loss=13.610]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:13<00:00, 28.82batch/s, training_loss=163.930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [32, 128, 64], 'kernel_sizes': [3, 1, 5], 'learning_rate': 0.1, 'fully_connected': 0, 'dropout': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:13<00:00, 29.58batch/s, training_loss=4.658]\n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:13<00:00, 29.06batch/s, training_loss=4.653]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:13<00:00, 28.77batch/s, training_loss=4.625]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:13<00:00, 28.45batch/s, training_loss=4.625]\n",
      "Epoch 5/5: 100%|██████████| 391/391 [00:13<00:00, 28.57batch/s, training_loss=4.614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 1, 'filters': [128], 'kernel_sizes': [3], 'learning_rate': 0.001, 'fully_connected': 0, 'dropout': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [00:13<00:00, 28.88batch/s, training_loss=5.501]\n",
      "Epoch 2/5: 100%|██████████| 391/391 [00:13<00:00, 28.57batch/s, training_loss=3.884]\n",
      "Epoch 3/5: 100%|██████████| 391/391 [00:13<00:00, 28.37batch/s, training_loss=2.785]\n",
      "Epoch 4/5: 100%|██████████| 391/391 [00:13<00:00, 28.46batch/s, training_loss=2.170]\n",
      "Epoch 5/5:   9%|▊         | 34/391 [00:01<00:13, 26.62batch/s, training_loss=1.392]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m population_sol \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_desc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m, in \u001b[0;36mgenetic_algorithm\u001b[1;34m(population, train_loader, val_loader, device, max_desc, epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***************************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m puntuaciones_aptitud \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Ordenamos individuos\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Añadimos las puntuaciones directamente a cada diccionario de la población\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, puntuacion \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(puntuaciones_aptitud):\n",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m, in \u001b[0;36mevaluate_population\u001b[1;34m(population, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m individual \u001b[38;5;129;01min\u001b[39;00m population:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(individual)\n\u001b[1;32m----> 9\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_individual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindividual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     fitness_scores\u001b[38;5;241m.\u001b[39mappend(fitness)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# sacamos los scores de la poblacion\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m, in \u001b[0;36mevaluate_individual\u001b[1;34m(individual, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     20\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:922\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    920\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "population_sol = genetic_algorithm(population, train_loader, val_loader, device, max_desc, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for individual in top_models:\n",
    "    print(f\"Individuo {individual} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = build_cnn_from_individual(top_models[len(top_models)-1])\n",
    "model = model.to(device)\n",
    "summary(model, (num_channels, px_h, px_w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
