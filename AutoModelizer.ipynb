{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoModelizer\n",
    "---\n",
    "\n",
    "La idea de este proyecto es encontrar el mejor modelo de CNN que se adapte al dataset correspondiente, para ello usando algoritmos evolutivos. Este tipo de soluciones se conocen como neuroevoluciones\n",
    "\n",
    "A continuación un ejemplo básico de como funcionan este tipo de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def fitness(x):\n",
    "    return x ** 2\n",
    "\n",
    "population_size = 10\n",
    "population = np.random.uniform(-10, 10, population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parent_tournament(population, scores, k=3):\n",
    "    selection_ix = np.random.randint(len(population), size=k)\n",
    "    selected = population[selection_ix]\n",
    "    ix = np.argmax(scores[selection_ix])\n",
    "    return selected[ix]\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    child = (p1 + p2) / 2\n",
    "    return child\n",
    "\n",
    "def mutate(x):\n",
    "    mutation_chance = 0.1\n",
    "    if np.random.rand() < mutation_chance:\n",
    "        x += np.random.uniform(-1, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 0, x = 8.34090860079414 Mejor puntuación 99.81213686538679\n",
      "Generación 1, x = 0.14746655130976105 Mejor puntuación 99.81213686538679\n",
      "Generación 2, x = 9.704857390070945 Mejor puntuación 99.81213686538679\n",
      "Generación 3, x = 9.990602427550943 Mejor puntuación 99.81213686538679\n",
      "Generación 4, x = 9.822157114981025 Mejor puntuación 99.81213686538679\n",
      "Generación 5, x = 9.954026837436736 Mejor puntuación 99.81213686538679\n",
      "Generación 6, x = 9.937025233023444 Mejor puntuación 99.81213686538679\n",
      "Generación 7, x = 9.972743362708442 Mejor puntuación 99.81213686538679\n",
      "Generación 8, x = 10.181970606267667 Mejor puntuación 107.79149541460497\n",
      "Generación 9, x = 10.186435372478293 Mejor puntuación 107.79149541460497\n",
      "Generación 10, x = 10.382268317405641 Mejor puntuación 107.79149541460497\n",
      "Generación 11, x = 9.922530368031909 Mejor puntuación 114.49845133273078\n",
      "Generación 12, x = 10.596384147337352 Mejor puntuación 114.49845133273078\n",
      "Generación 13, x = 10.556618322662747 Mejor puntuación 112.28335699794233\n",
      "Generación 14, x = 10.556618322662747 Mejor puntuación 111.70075692400991\n",
      "Generación 15, x = 10.555094748912383 Mejor puntuación 111.79907512736433\n",
      "Generación 16, x = 10.566593193727154 Mejor puntuación 111.74991061938016\n",
      "Generación 17, x = 10.57118302837389 Mejor puntuación 111.74991061938016\n",
      "Generación 18, x = 10.570322832573368 Mejor puntuación 111.74991061938016\n",
      "Generación 19, x = 10.570752930473628 Mejor puntuación 111.74991061938016\n",
      "Generación 20, x = 11.174767797871262 Mejor puntuación 123.0704317465274\n",
      "Generación 21, x = 10.839254609206504 Mejor puntuación 124.87543533634053\n",
      "Generación 22, x = 11.007011203538884 Mejor puntuación 124.87543533634053\n",
      "Generación 23, x = 11.023871605496918 Mejor puntuación 121.5257451744812\n",
      "Generación 24, x = 11.023871605496918 Mejor puntuación 121.5257451744812\n",
      "Generación 25, x = 11.171453733578888 Mejor puntuación 129.5048828887394\n",
      "Generación 26, x = 11.523556632934177 Mejor puntuación 140.3079778193184\n",
      "Generación 27, x = 11.61394562726679 Mejor puntuación 140.3079778193184\n",
      "Generación 28, x = 11.845166854853435 Mejor puntuación 140.3079778193184\n",
      "Generación 29, x = 12.903762415824467 Mejor puntuación 150.24354803427858\n",
      "Generación 30, x = 12.47751979365924 Mejor puntuación 166.50708448404407\n",
      "Generación 31, x = 12.776987701692821 Mejor puntuación 166.50708448404407\n",
      "Generación 32, x = 12.414132436593418 Mejor puntuación 163.2514147292096\n",
      "Generación 33, x = 12.789253524391746 Mejor puntuación 163.87889759393678\n",
      "Generación 34, x = 12.789253524391746 Mejor puntuación 163.56500571116672\n",
      "Generación 35, x = 12.786187068717016 Mejor puntuación 163.56500571116672\n",
      "Generación 36, x = 13.10775711123208 Mejor puntuación 180.3468278023704\n",
      "Generación 37, x = 13.678967049054712 Mejor puntuación 194.00609141053715\n",
      "Generación 38, x = 13.598574538425947 Mejor puntuación 194.00609141053715\n",
      "Generación 39, x = 13.866196970535388 Mejor puntuación 194.00609141053715\n",
      "Generación 40, x = 13.81608918446217 Mejor puntuación 192.3377227824845\n",
      "Generación 41, x = 13.867392299032808 Mejor puntuación 207.87404779446936\n",
      "Generación 42, x = 14.11882804920749 Mejor puntuación 206.50448166383376\n",
      "Generación 43, x = 14.30693872678782 Mejor puntuación 206.50448166383376\n",
      "Generación 44, x = 14.30693872678782 Mejor puntuación 204.68849573206109\n",
      "Generación 45, x = 14.30693872678782 Mejor puntuación 204.68849573206109\n",
      "Generación 46, x = 14.30693872678782 Mejor puntuación 204.68849573206109\n",
      "Generación 47, x = 13.745658650075844 Mejor puntuación 204.68849573206109\n",
      "Generación 48, x = 14.30693872678782 Mejor puntuación 204.68849573206109\n",
      "Generación 49, x = 14.30693872678782 Mejor puntuación 224.03490408071187\n",
      "Generación 50, x = 14.472152936383274 Mejor puntuación 214.25251696617747\n",
      "Generación 51, x = 14.554760041181002 Mejor puntuación 214.25251696617747\n",
      "Generación 52, x = 14.596063593579865 Mejor puntuación 214.25251696617747\n",
      "Generación 53, x = 15.045801540542817 Mejor puntuación 238.83340833794958\n",
      "Generación 54, x = 14.781265011695622 Mejor puntuación 232.77639917914658\n",
      "Generación 55, x = 15.049297909636135 Mejor puntuación 232.77639917914658\n",
      "Generación 56, x = 15.257011476011499 Mejor puntuación 232.77639917914658\n",
      "Generación 57, x = 15.257011476011499 Mejor puntuación 232.77639917914658\n",
      "Generación 58, x = 15.257011476011499 Mejor puntuación 232.77639917914658\n",
      "Generación 59, x = 15.257011476011499 Mejor puntuación 235.07918250906195\n",
      "Generación 60, x = 15.3322921479165 Mejor puntuación 235.07918250906195\n",
      "Generación 61, x = 15.522971456715805 Mejor puntuación 235.07918250906195\n",
      "Generación 62, x = 15.3322921479165 Mejor puntuación 240.9626428460136\n",
      "Generación 63, x = 15.3322921479165 Mejor puntuación 255.55040749808273\n",
      "Generación 64, x = 16.871715490798856 Mejor puntuación 284.6547836024621\n",
      "Generación 65, x = 16.871715490798856 Mejor puntuación 286.21077222557545\n",
      "Generación 66, x = 16.79553118568994 Mejor puntuación 307.37272861268\n",
      "Generación 67, x = 16.998706619109 Mejor puntuación 295.904746149087\n",
      "Generación 68, x = 17.088312126141155 Mejor puntuación 322.9406901908829\n",
      "Generación 69, x = 17.987895838936744 Mejor puntuación 317.4873125583478\n",
      "Generación 70, x = 17.663802275491133 Mejor puntuación 323.5643967124378\n",
      "Generación 71, x = 17.860604204322318 Mejor puntuación 320.51865323084047\n",
      "Generación 72, x = 17.88373832619883 Mejor puntuación 320.51865323084047\n",
      "Generación 73, x = 17.903034749193793 Mejor puntuación 320.51865323084047\n",
      "Generación 74, x = 17.903034749193793 Mejor puntuación 355.0763871016709\n",
      "Generación 75, x = 18.717937764624686 Mejor puntuación 355.0763871016709\n",
      "Generación 76, x = 18.725916184787003 Mejor puntuación 365.0209408867688\n",
      "Generación 77, x = 18.97449594516156 Mejor puntuación 360.0314963729525\n",
      "Generación 78, x = 18.82306282525117 Mejor puntuación 360.0314963729525\n",
      "Generación 79, x = 18.97449594516156 Mejor puntuación 360.0314963729525\n",
      "Generación 80, x = 18.97449594516156 Mejor puntuación 360.0314963729525\n",
      "Generación 81, x = 19.948908709541524 Mejor puntuación 360.0314963729525\n",
      "Generación 82, x = 19.948908709541524 Mejor puntuación 397.95895870162167\n",
      "Generación 83, x = 19.705305518446533 Mejor puntuación 397.95895870162167\n",
      "Generación 84, x = 19.705305518446533 Mejor puntuación 388.2990655753194\n",
      "Generación 85, x = 19.644404720672785 Mejor puntuación 388.2990655753194\n",
      "Generación 86, x = 20.04603973104611 Mejor puntuación 415.62055182931084\n",
      "Generación 87, x = 20.382507563650268 Mejor puntuación 415.4466145822604\n",
      "Generación 88, x = 20.56758340822349 Mejor puntuación 415.4466145822604\n",
      "Generación 89, x = 20.39092852778584 Mejor puntuación 423.02548725423026\n",
      "Generación 90, x = 20.43298700686136 Mejor puntuación 419.2274876511843\n",
      "Generación 91, x = 20.44350162663024 Mejor puntuación 418.3667806079592\n",
      "Generación 92, x = 20.437191696228854 Mejor puntuación 443.83875740678815\n",
      "Generación 93, x = 20.75549133374266 Mejor puntuación 431.0086842438645\n",
      "Generación 94, x = 20.948446326594528 Mejor puntuación 452.3060477421965\n",
      "Generación 95, x = 21.014118344289788 Mejor puntuación 441.5931697878166\n",
      "Generación 96, x = 20.997700339865972 Mejor puntuación 441.5931697878166\n",
      "Generación 97, x = 21.013132598686454 Mejor puntuación 441.5931697878166\n",
      "Generación 98, x = 21.013296889620342 Mejor puntuación 441.5655507866596\n",
      "Generación 99, x = 21.01346118055423 Mejor puntuación 441.5655507866596\n",
      "Generación 100, x = 21.013379035087286 Mejor puntuación 441.5655507866596\n",
      "Generación 101, x = 21.013399571454023 Mejor puntuación 441.5638246277657\n",
      "Generación 102, x = 21.013399571454023 Mejor puntuación 441.56296154958414\n",
      "Generación 103, x = 21.21166131352325 Mejor puntuación 461.68247376066057\n",
      "Generación 104, x = 21.230879965084014 Mejor puntuación 461.68247376066057\n",
      "Generación 105, x = 21.427622900537838 Mejor puntuación 461.68247376066057\n",
      "Generación 106, x = 22.13314902734197 Mejor puntuación 489.87628586652886\n",
      "Generación 107, x = 21.95676749564094 Mejor puntuación 489.87628586652886\n",
      "Generación 108, x = 22.112361570488094 Mejor puntuación 521.3983583537746\n",
      "Generación 109, x = 22.483648989579585 Mejor puntuación 505.5144718866231\n",
      "Generación 110, x = 22.483648989579585 Mejor puntuación 505.5144718866231\n",
      "Generación 111, x = 23.308314696206132 Mejor puntuación 543.2775339773788\n",
      "Generación 112, x = 23.308314696206132 Mejor puntuación 543.2775339773788\n",
      "Generación 113, x = 23.205231482877814 Mejor puntuación 543.2775339773788\n",
      "Generación 114, x = 23.307332187221988 Mejor puntuación 543.2775339773788\n",
      "Generación 115, x = 23.306349678237847 Mejor puntuación 543.2775339773788\n",
      "Generación 116, x = 23.749244790777105 Mejor puntuación 585.1883282892086\n",
      "Generación 117, x = 23.749244790777105 Mejor puntuación 585.1883282892086\n",
      "Generación 118, x = 24.080310802574388 Mejor puntuación 585.1883282892086\n",
      "Generación 119, x = 24.080310802574388 Mejor puntuación 579.8613683485808\n",
      "Generación 120, x = 24.080310802574388 Mejor puntuación 579.8613683485808\n",
      "Generación 121, x = 24.080310802574388 Mejor puntuación 579.8613683485808\n",
      "Generación 122, x = 24.100691052177858 Mejor puntuación 581.8260807456186\n",
      "Generación 123, x = 24.100691052177858 Mejor puntuación 580.8433091925259\n",
      "Generación 124, x = 24.09559598977699 Mejor puntuación 580.8433091925259\n",
      "Generación 125, x = 24.100691052177858 Mejor puntuación 580.8433091925259\n",
      "Generación 126, x = 24.100691052177858 Mejor puntuación 623.0630089134213\n",
      "Generación 127, x = 24.100691052177858 Mejor puntuación 601.7680271828006\n",
      "Generación 128, x = 24.42339320118264 Mejor puntuación 601.7680271828006\n",
      "Generación 129, x = 24.672642812653798 Mejor puntuación 621.1007219996568\n",
      "Generación 130, x = 24.921892424124955 Mejor puntuación 621.1007219996568\n",
      "Generación 131, x = 24.921892424124955 Mejor puntuación 621.1007219996568\n",
      "Generación 132, x = 24.89073622269106 Mejor puntuación 621.1007219996568\n",
      "Generación 133, x = 24.921892424124955 Mejor puntuación 621.1007219996568\n",
      "Generación 134, x = 24.921892424124955 Mejor puntuación 634.2772943188087\n",
      "Generación 135, x = 25.119119909186033 Mejor puntuación 634.2772943188087\n",
      "Generación 136, x = 25.184862404206395 Mejor puntuación 634.2772943188087\n",
      "Generación 137, x = 25.184862404206395 Mejor puntuación 634.2772943188087\n",
      "Generación 138, x = 25.57823821825382 Mejor puntuación 634.2772943188087\n",
      "Generación 139, x = 25.381550311230107 Mejor puntuación 654.2462703497404\n",
      "Generación 140, x = 24.919312020730594 Mejor puntuación 644.2230962015052\n",
      "Generación 141, x = 25.381550311230107 Mejor puntuación 644.2230962015052\n",
      "Generación 142, x = 25.381550311230107 Mejor puntuación 659.0338975180879\n",
      "Generación 143, x = 25.671655527411705 Mejor puntuación 659.0338975180879\n",
      "Generación 144, x = 25.635392375389003 Mejor puntuación 659.0338975180879\n",
      "Generación 145, x = 26.04180410216437 Mejor puntuación 678.175560895505\n",
      "Generación 146, x = 26.04180410216437 Mejor puntuación 678.175560895505\n",
      "Generación 147, x = 25.889399704623607 Mejor puntuación 697.5696540444931\n",
      "Generación 148, x = 26.293708258265568 Mejor puntuación 697.5696540444931\n",
      "Generación 149, x = 26.247490776761456 Mejor puntuación 697.5696540444931\n",
      "Generación 150, x = 26.532329028403403 Mejor puntuación 712.8543070384499\n",
      "Generación 151, x = 26.532329028403403 Mejor puntuación 712.8543070384499\n",
      "Generación 152, x = 26.906013999615535 Mejor puntuación 759.6697234025204\n",
      "Generación 153, x = 27.464240998927366 Mejor puntuación 759.6697234025204\n",
      "Generación 154, x = 27.335268678712648 Mejor puntuación 759.6697234025204\n",
      "Generación 155, x = 27.464240998927366 Mejor puntuación 756.9747341030568\n",
      "Generación 156, x = 27.513173828241932 Mejor puntuación 756.9747341030568\n",
      "Generación 157, x = 27.513173828241932 Mejor puntuación 756.9747341030568\n",
      "Generación 158, x = 27.79102131824025 Mejor puntuación 787.8613961741081\n",
      "Generación 159, x = 27.79102131824025 Mejor puntuación 811.2557374411928\n",
      "Generación 160, x = 28.314745964040313 Mejor puntuación 811.2557374411928\n",
      "Generación 161, x = 28.767359734245154 Mejor puntuación 854.1035794725482\n",
      "Generación 162, x = 28.725408361266183 Mejor puntuación 827.7070456319202\n",
      "Generación 163, x = 28.767994364559293 Mejor puntuación 827.6340142446722\n",
      "Generación 164, x = 28.767677049402224 Mejor puntuación 827.6340142446722\n",
      "Generación 165, x = 29.096819047257753 Mejor puntuación 865.8685089223114\n",
      "Generación 166, x = 29.096819047257753 Mejor puntuación 846.63411155574\n",
      "Generación 167, x = 29.096898376047022 Mejor puntuación 846.6294951060079\n",
      "Generación 168, x = 29.096898376047022 Mejor puntuación 846.6294951060079\n",
      "Generación 169, x = 29.096898376047022 Mejor puntuación 846.6294951060079\n",
      "Generación 170, x = 29.096898376047022 Mejor puntuación 846.6294951060079\n",
      "Generación 171, x = 29.096898376047022 Mejor puntuación 887.0410079957167\n",
      "Generación 172, x = 29.440066024315303 Mejor puntuación 874.8511645863234\n",
      "Generación 173, x = 29.940527125067145 Mejor puntuación 896.4351645268815\n",
      "Generación 174, x = 29.724750826323543 Mejor puntuación 920.5819854509457\n",
      "Generación 175, x = 30.14081056528652 Mejor puntuación 908.4684615324876\n",
      "Generación 176, x = 30.26789656960478 Mejor puntuación 923.8549656690853\n",
      "Generación 177, x = 29.42853810395782 Mejor puntuación 965.1859116770147\n",
      "Generación 178, x = 30.899326651651368 Mejor puntuación 965.1859116770147\n",
      "Generación 179, x = 30.98338399793942 Mejor puntuación 965.1859116770147\n",
      "Generación 180, x = 30.98338399793942 Mejor puntuación 1010.4315248182082\n",
      "Generación 181, x = 31.611803999904822 Mejor puntuación 1013.6756409110022\n",
      "Generación 182, x = 31.611803999904822 Mejor puntuación 999.3061521283985\n",
      "Generación 183, x = 31.611803999904822 Mejor puntuación 999.3061521283985\n",
      "Generación 184, x = 31.611803999904822 Mejor puntuación 999.3061521283985\n",
      "Generación 185, x = 31.611803999904822 Mejor puntuación 999.3061521283985\n",
      "Generación 186, x = 31.611803999904822 Mejor puntuación 999.3061521283985\n",
      "Generación 187, x = 31.611803999904822 Mejor puntuación 999.3061521283985\n",
      "Generación 188, x = 31.611803999904822 Mejor puntuación 999.3061521283985\n",
      "Generación 189, x = 31.611803999904822 Mejor puntuación 999.3061521283985\n",
      "Generación 190, x = 31.611803999904822 Mejor puntuación 999.3061521283985\n",
      "Generación 191, x = 31.611803999904822 Mejor puntuación 1029.824842905316\n",
      "Generación 192, x = 31.731574027209962 Mejor puntuación 1072.9584701486672\n",
      "Generación 193, x = 31.352726906158217 Mejor puntuación 1067.0034888853331\n",
      "Generación 194, x = 31.716638436453515 Mejor puntuación 1055.2334421471307\n",
      "Generación 195, x = 32.40924876124868 Mejor puntuación 1053.2890125453712\n",
      "Generación 196, x = 32.43944312345354 Mejor puntuación 1052.3174701597773\n",
      "Generación 197, x = 32.43944312345354 Mejor puntuación 1052.3174701597773\n",
      "Generación 198, x = 33.383613996345225 Mejor puntuación 1114.4656834569769\n",
      "Generación 199, x = 32.91152855989938 Mejor puntuación 1114.4656834569769\n",
      "Mejor solución: x = 32.91152855989938, f(x) = 1083.1687121490727\n"
     ]
    }
   ],
   "source": [
    "n_generations = 200\n",
    "\n",
    "for generation in range(n_generations):\n",
    "    scores = np.array([fitness(x) for x in population])\n",
    "    new_population = []\n",
    "    for _ in range(population_size):\n",
    "        parent1 = select_parent_tournament(population, scores)\n",
    "        parent2 = select_parent_tournament(population, scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        child = mutate(child)\n",
    "        new_population.append(child)\n",
    "    population = np.array(new_population)\n",
    "    best_score = np.max(scores)\n",
    "    print(f\"Generación {generation}, x = {child} Mejor puntuación {best_score}\")\n",
    "\n",
    "best_solution = population[np.argmax(scores)]\n",
    "print(f\"Mejor solución: x = {best_solution}, f(x) = {fitness(best_solution)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (MNIST)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_desc = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS DEL DATASET DE PRUEBA\n",
    "\n",
    "num_channels = 1\n",
    "px_h = 28\n",
    "px_w = 28\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.Grayscale(num_output_channels=num_channels),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (CIFAR100)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DATOS DEL DATASET DE PRUEBA CIFAR 100\n",
    "num_channels = 3\n",
    "px_h = 32\n",
    "px_w = 32\n",
    "batch_size = 512\n",
    "num_classes = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERACIÓN DE LA RED EN BASE A VECTORES\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprobamos si tenemos acceso a la GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU) está disponible en tu sistema.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA (GPU) está disponible en tu sistema.\")\n",
    "else:\n",
    "    print(\"CUDA (GPU) no está disponible en tu sistema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos un par de arquitecturas de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos una función que sea capaz de crear modelos en base a vectores que representen la arquitectura de la red.\n",
    "De este modo el algorimo evolutivo puede ir adaptando y cambiando la red fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def build_cnn_from_individual(individual):\n",
    "    layers = []\n",
    "    num_layers = individual['num_conv_layers']\n",
    "    fully_connected = individual['fully_connected']\n",
    "    dropout = individual['dropout']\n",
    "    out_channels_previous_layer = num_channels # Imagen de entrada en escala de grises (1 canal para MNIST)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        out_channels = individual['filters'][i]\n",
    "        kernel_size = individual['filter_sizes'][i]\n",
    "        \n",
    "        conv_layer = nn.Conv2d(out_channels_previous_layer, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        layers.append(conv_layer)\n",
    "        layers.append(nn.ReLU())\n",
    "        if i < 2:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        else:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=1))\n",
    "\n",
    "\n",
    "        out_channels_previous_layer = out_channels\n",
    "\n",
    "\n",
    "    # Temporalmente crear un modelo para calcular el tamaño de salida de las capas convolucionales\n",
    "    temp_model = nn.Sequential(*layers)\n",
    "\n",
    "    # Calcular el tamaño de salida usando un tensor dummy\n",
    "    dummy_input = torch.zeros(1, num_channels, px_h, px_w)  # Tamaño de entrada para MNIST\n",
    "    output_size = temp_model(dummy_input).view(-1).shape[0]\n",
    "\n",
    "    # Ahora, sabiendo el tamaño de salida, podemos definir las capas lineales correctamente\n",
    "    layers.append(nn.Flatten())\n",
    "\n",
    "    for i in range(fully_connected):\n",
    "        layers.append(nn.Linear(in_features=output_size, out_features=output_size))\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            dropout-= 1\n",
    "\n",
    "    layers.append(nn.Linear(output_size, num_classes))  # Salida de 10 clases para MNIST\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la población inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    individual = {\n",
    "        'num_conv_layers': random.randint(min_conv_layers, max_conv_layers),\n",
    "        'filters': [],\n",
    "        'filter_sizes': [],\n",
    "        'learning_rate': random.uniform(lr_min, lr_max),\n",
    "        'fully_connected': random.randint(0,2),\n",
    "        'dropout': random.randint(0,2)\n",
    "    }\n",
    "\n",
    "    for _ in range(individual['num_conv_layers']):\n",
    "        individual['filters'].append(random.randint(min_filters, max_filters))\n",
    "        individual['filter_sizes'].append(random.choice(filter_sizes))\n",
    "    \n",
    "    # Agrega más parámetros según sea necesario, como capas completamente conectadas, etc.\n",
    "\n",
    "    return individual\n",
    "\n",
    "def initialize_population(pop_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    return [generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max) for _ in range(pop_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETROS PARA POSIBLES ARQUITECTURAS DE RED\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AJUSTAR SEGÚN VAYA NECESITANDO Y TIEMPO \n",
    "\n",
    "population_size = 5\n",
    "min_conv_layers = 1\n",
    "max_conv_layers = 3\n",
    "min_filters = 16\n",
    "max_filters = 128\n",
    "filter_sizes = [3, 5]\n",
    "lr_min = 0.0001\n",
    "lr_max = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num_conv_layers': 2,\n",
       "  'filters': [63, 18],\n",
       "  'filter_sizes': [5, 5],\n",
       "  'learning_rate': 0.009192248307730508,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 2},\n",
       " {'num_conv_layers': 2,\n",
       "  'filters': [46, 38],\n",
       "  'filter_sizes': [5, 3],\n",
       "  'learning_rate': 0.007818060254341576,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 1,\n",
       "  'filters': [21],\n",
       "  'filter_sizes': [5],\n",
       "  'learning_rate': 0.00181214363417219,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 0},\n",
       " {'num_conv_layers': 1,\n",
       "  'filters': [45],\n",
       "  'filter_sizes': [5],\n",
       "  'learning_rate': 0.002171320076555757,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 2,\n",
       "  'filters': [125, 40],\n",
       "  'filter_sizes': [3, 5],\n",
       "  'learning_rate': 0.008391561444924577,\n",
       "  'fully_connected': 2,\n",
       "  'dropout': 1}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "population = initialize_population(population_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO Y EVALUACIÓN DE LOS MODELOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def evaluate_individual(individual, train_loader, val_loader, device='cuda', epochs=5):\n",
    "    # Construir el modelo basado en el individuo\n",
    "    model = build_cnn_from_individual(individual).to(device)\n",
    "    \n",
    "    # Definir el optimizador y la función de pérdida\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=individual['learning_rate'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch')\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Actualizar la barra de progreso con la última información de pérdida\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item())})\n",
    "            progress_bar.update()  # Forzar la actualización de la barra de progreso\n",
    "            \n",
    "        progress_bar.close()  # Cerrar la barra de progreso al final de cada época\n",
    "\n",
    "    # Evaluación\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy  # Esta es la \"aptitud\" del individuo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUTACIONES Y CRUCES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def mutate_individual(individual):\n",
    "    \"\"\"\n",
    "    Mutar un individuo cambiando aleatoriamente sus hiperparámetros.\n",
    "    \"\"\"\n",
    "    mutation_rate = 0.3  # Probabilidad de mutar cada característica\n",
    "    lr_range = (0.0001, 0.01)\n",
    "    filter_range = (32, 128)  # Rango para el número de filtros\n",
    "    filter_size_range = (1, 7)  # Rango para el tamaño de filtro\n",
    "    fully_connected_range = (0,2) #Rango para ver cuantas fully conected se añaden\n",
    "    dropout_range = (0,2) # Rango para ver cuantos dropouts se añaden\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['learning_rate'] = random.uniform(*lr_range)\n",
    "\n",
    "    # Asegurarse de que hay suficientes entradas en las listas 'filters' y 'filter_sizes'\n",
    "    for i in range(individual['num_conv_layers']):\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el número de filtros en la capa i\n",
    "            individual['filters'][i] = random.randint(*filter_range)\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el tamaño de filtro en la capa i\n",
    "            individual['filter_sizes'][i] = random.randint(*filter_size_range)\n",
    "\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['fully_connected'] = random.uniform(*fully_connected_range)\n",
    "\n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el cruce entre individuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    \"\"\"\n",
    "    Realiza un cruce uniforme entre dos individuos.\n",
    "    \n",
    "    Args:\n",
    "        parent1 (dict): El primer individuo padre.\n",
    "        parent2 (dict): El segundo individuo padre.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un nuevo individuo hijo.\n",
    "    \"\"\"\n",
    "    child = {}\n",
    "    print(f\"Padre 1: {parent1} --- Padre 2: {parent2}\")\n",
    "    for key in parent1:\n",
    "        if key != \"num_conv_layers\" and key != \"filter_sizes\":\n",
    "            if random.random() < 0.5:\n",
    "                child[key] = parent1[key]\n",
    "            else:\n",
    "                child[key] = parent2[key]\n",
    "    child[\"num_conv_layers\"] = len(child[\"filters\"])        \n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population, train_loader, val_loader, device):\n",
    "    fitness_scores = []\n",
    "    \n",
    "    for individual in population:\n",
    "        print(individual)\n",
    "        fitness = evaluate_individual(individual, train_loader, val_loader, device)\n",
    "        fitness_scores.append(fitness)\n",
    "    \n",
    "    return fitness_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recopilamos lo que hemos realizado, hemos creado las posibles mutaciones sobre las arquitecturas, los posibles cruces, la evaluación de los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queda realizar:\n",
    "- Selección de reproducción: por torneo en principio para también  puede ser por torneo o ruleta\n",
    "- Creación de la nueva generación usando las funciones de mutación y cruces\n",
    "- Criterios de parada\n",
    "- Registro de análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección por torneo\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection_best4(population):\n",
    "    \"\"\"\n",
    "    Selecciona los 4 mejores individuos de la población mediante un torneo de tamaño fijo.\n",
    "\n",
    "    Args:\n",
    "        population: La lista de individuos con sus puntuaciones de fitness.\n",
    "\n",
    "    Returns:\n",
    "        Lista de los 4 mejores individuos.\n",
    "    \"\"\"\n",
    "    winners = []\n",
    "    for _ in range(2):\n",
    "        candidates = random.sample(population, 2)\n",
    "        winner = max(candidates, key=lambda x: x['fitness'])\n",
    "        winners.append(winner)\n",
    "    return winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITMO EVOLUTIVO\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfitness_scores = evaluate_population(population, train_loader, val_loader, device)\\n\\n# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\\npopulation_with_scores = list(zip(population, fitness_scores))\\npopulation_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\\n\\n# Imprimimimos los resultados\\nfor i, (individual, score) in enumerate(population_with_scores):\\n    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fitness_scores = evaluate_population(population, train_loader, val_loader, device)\n",
    "\n",
    "# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\n",
    "population_with_scores = list(zip(population, fitness_scores))\n",
    "population_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\n",
    "\n",
    "# Imprimimimos los resultados\n",
    "for i, (individual, score) in enumerate(population_with_scores):\n",
    "    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = []\n",
    "\n",
    "def genetic_algorithm(population, train_loader, val_loader, device, max_desc):\n",
    "    desc = 0\n",
    "    while desc < max_desc:\n",
    "        print(\"***************************************\")\n",
    "        print()\n",
    "        print(f\"Generation: {desc}\")\n",
    "        print()\n",
    "        print(\"***************************************\")\n",
    "        puntuaciones_aptitud = evaluate_population(population, train_loader, val_loader, device)\n",
    "\n",
    "        # Ordenamos individuos\n",
    "        # Añadimos las puntuaciones directamente a cada diccionario de la población\n",
    "        for i, puntuacion in enumerate(puntuaciones_aptitud):\n",
    "            population[i]['fitness'] = puntuacion\n",
    "\n",
    "        population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "\n",
    "        # Preservamos el mejor individuo (elitismo)\n",
    "        mejor_individuo = population[0]\n",
    "        top_models.append(mejor_individuo)\n",
    "        # Seleccionamos los 4 mejores (excluyendo el mejor) para el torneo\n",
    "        winners = tournament_selection_best4(population[1:])\n",
    "        print(f\"Los 4 mejores son: \\n {winners}\")\n",
    "\n",
    "        # Realizamos cruce y mutación con descendientes que reemplazan a la población restante\n",
    "        for i in range(1, 2):\n",
    "            descendency = mutate_individual(crossover(winners[i-1], winners[i]))\n",
    "            population[-i] = descendency   # Eliminamos las peores arquitecturas\n",
    "\n",
    "        # Nos aseguramos que mantenemos el mejor de todos\n",
    "        population[0] = mejor_individuo\n",
    "        desc += 1\n",
    "\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTADOS DE LAS ARQUITECTURAS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padre 1: {'num_conv_layers': 2, 'filters': [46, 38], 'filter_sizes': [5, 3], 'learning_rate': 0.007818060254341576, 'fully_connected': 2, 'dropout': 1} --- Padre 2: {'num_conv_layers': 1, 'filters': [21], 'filter_sizes': [5], 'learning_rate': 0.00181214363417219, 'fully_connected': 2, 'dropout': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'filters': [21],\n",
       " 'learning_rate': 0.00181214363417219,\n",
       " 'fully_connected': 0.023579609792001133,\n",
       " 'dropout': 1,\n",
       " 'num_conv_layers': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = crossover(population[1], population[2])\n",
    "mutate = mutate_individual(sol)\n",
    "mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n",
      "\n",
      "Generation: 0\n",
      "\n",
      "***************************************\n",
      "{'num_conv_layers': 2, 'filters': [63, 18], 'filter_sizes': [5, 5], 'learning_rate': 0.009192248307730508, 'fully_connected': 2, 'dropout': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 196/196 [00:10<00:00, 17.90batch/s, training_loss=4.699]\n",
      "Epoch 2/5:  92%|█████████▏| 180/196 [00:12<00:01, 14.58batch/s, training_loss=4.628]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m population_sol \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_desc\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 11\u001b[0m, in \u001b[0;36mgenetic_algorithm\u001b[1;34m(population, train_loader, val_loader, device, max_desc)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***************************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m puntuaciones_aptitud \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Ordenamos individuos\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Añadimos las puntuaciones directamente a cada diccionario de la población\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, puntuacion \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(puntuaciones_aptitud):\n",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m, in \u001b[0;36mevaluate_population\u001b[1;34m(population, train_loader, val_loader, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m individual \u001b[38;5;129;01min\u001b[39;00m population:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(individual)\n\u001b[1;32m----> 6\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_individual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindividual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     fitness_scores\u001b[38;5;241m.\u001b[39mappend(fitness)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fitness_scores\n",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m, in \u001b[0;36mevaluate_individual\u001b[1;34m(individual, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     16\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "population_sol = genetic_algorithm(population, train_loader, val_loader, device, max_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for individual in top_models:\n",
    "    print(f\"Individuo {individual} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
