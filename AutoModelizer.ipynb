{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoModelizer\n",
    "---\n",
    "\n",
    "La idea de este proyecto es encontrar el mejor modelo de CNN que se adapte al dataset correspondiente, para ello usando algoritmos evolutivos. Este tipo de soluciones se conocen como neuroevoluciones\n",
    "\n",
    "A continuación un ejemplo básico de como funcionan este tipo de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def fitness(x):\n",
    "    return x ** 2\n",
    "\n",
    "population_size = 10\n",
    "population = np.random.uniform(-10, 10, population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parent_tournament(population, scores, k=3):\n",
    "    selection_ix = np.random.randint(len(population), size=k)\n",
    "    selected = population[selection_ix]\n",
    "    ix = np.argmax(scores[selection_ix])\n",
    "    return selected[ix]\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    child = (p1 + p2) / 2\n",
    "    return child\n",
    "\n",
    "def mutate(x):\n",
    "    mutation_chance = 0.1\n",
    "    if np.random.rand() < mutation_chance:\n",
    "        x += np.random.uniform(-1, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 0, x = -7.267381947032456 Mejor puntuación 71.29153604937518\n",
      "Generación 1, x = 0.5880247928924716 Mejor puntuación 71.29153604937518\n",
      "Generación 2, x = 0.5575263953202936 Mejor puntuación 71.29153604937518\n",
      "Generación 3, x = 4.499651800315965 Mejor puntuación 71.29153604937518\n",
      "Generación 4, x = 5.486704901569119 Mejor puntuación 41.880851542108665\n",
      "Generación 5, x = 6.471541666566682 Mejor puntuación 41.880851542108665\n",
      "Generación 6, x = 6.471541666566682 Mejor puntuación 41.880851542108665\n",
      "Generación 7, x = 6.471541666566682 Mejor puntuación 41.880851542108665\n",
      "Generación 8, x = 7.198182203917787 Mejor puntuación 42.36029421715407\n",
      "Generación 9, x = 6.834861935242234 Mejor puntuación 51.81382704079873\n",
      "Generación 10, x = 6.839479057015678 Mejor puntuación 46.84165250451587\n",
      "Generación 11, x = 6.844096178789123 Mejor puntuación 46.84165250451587\n",
      "Generación 12, x = 6.8417876179024 Mejor puntuación 46.84165250451587\n",
      "Generación 13, x = 6.844096178789123 Mejor puntuación 46.84165250451587\n",
      "Generación 14, x = 7.607495290695976 Mejor puntuación 57.87398459796145\n",
      "Generación 15, x = 7.416501227663843 Mejor puntuación 57.87398459796145\n",
      "Generación 16, x = 7.321220623730905 Mejor puntuación 62.76507329827311\n",
      "Generación 17, x = 7.669543316309339 Mejor puntuación 58.82189468074525\n",
      "Generación 18, x = 7.669543316309339 Mejor puntuación 58.82189468074525\n",
      "Generación 19, x = 7.669543316309339 Mejor puntuación 58.82189468074525\n",
      "Generación 20, x = 7.785658506767878 Mejor puntuación 62.43802756217924\n",
      "Generación 21, x = 7.727600911538609 Mejor puntuación 60.616478384007024\n",
      "Generación 22, x = 7.756629709153243 Mejor puntuación 60.616478384007024\n",
      "Generación 23, x = 7.785658506767878 Mejor puntuación 60.616478384007024\n",
      "Generación 24, x = 7.785658506767878 Mejor puntuación 67.29618053133534\n",
      "Generación 25, x = 8.596672592849668 Mejor puntuación 80.81866625951473\n",
      "Generación 26, x = 8.793296425822945 Mejor puntuación 80.81866625951473\n",
      "Generación 27, x = 8.767186024564491 Mejor puntuación 80.81866625951473\n",
      "Generación 28, x = 9.331633688937737 Mejor puntuación 80.81866625951473\n",
      "Generación 29, x = 8.842452384066263 Mejor puntuación 87.07938730451772\n",
      "Generación 30, x = 9.129671394430707 Mejor puntuación 83.35089977028633\n",
      "Generación 31, x = 9.26350164972153 Mejor puntuación 90.62330262157992\n",
      "Generación 32, x = 9.745261831315965 Mejor puntuación 94.97012816090378\n",
      "Generación 33, x = 9.624821785917355 Mejor puntuación 94.97012816090378\n",
      "Generación 34, x = 9.656419650417744 Mejor puntuación 95.90619127307036\n",
      "Generación 35, x = 9.666909000572893 Mejor puntuación 95.90619127307036\n",
      "Generación 36, x = 9.708996215228431 Mejor puntuación 110.46059283661617\n",
      "Generación 37, x = 9.972383844918266 Mejor puntuación 103.05492257008326\n",
      "Generación 38, x = 10.508994754369304 Mejor puntuación 118.07848516954004\n",
      "Generación 39, x = 10.464191454274614 Mejor puntuación 118.07848516954004\n",
      "Generación 40, x = 10.021882934122216 Mejor puntuación 118.07848516954004\n",
      "Generación 41, x = 11.209252314800931 Mejor puntuación 133.4512954995484\n",
      "Generación 42, x = 11.209252314800931 Mejor puntuación 128.7644862970223\n",
      "Generación 43, x = 11.278348178636223 Mejor puntuación 128.7644862970223\n",
      "Generación 44, x = 11.330170076512692 Mejor puntuación 144.61205327537442\n",
      "Generación 45, x = 11.686459610624105 Mejor puntuación 136.5733382307485\n",
      "Generación 46, x = 11.918886080010655 Mejor puntuación 136.5733382307485\n",
      "Generación 47, x = 11.80267284531738 Mejor puntuación 142.05984538827175\n",
      "Generación 48, x = 11.80267284531738 Mejor puntuación 139.30308629359226\n",
      "Generación 49, x = 12.10600643910822 Mejor puntuación 153.99172005211125\n",
      "Generación 50, x = 12.392268883982762 Mejor puntuación 162.576283771067\n",
      "Generación 51, x = 12.571404706283456 Mejor puntuación 162.576283771067\n",
      "Generación 52, x = 12.490837945098965 Mejor puntuación 162.576283771067\n",
      "Generación 53, x = 12.961197679498152 Mejor puntuación 175.62667804141688\n",
      "Generación 54, x = 12.956697104515221 Mejor puntuación 167.9926452870283\n",
      "Generación 55, x = 12.961197679498152 Mejor puntuación 167.9926452870283\n",
      "Generación 56, x = 12.960635107625286 Mejor puntuación 167.9926452870283\n",
      "Generación 57, x = 12.961197679498152 Mejor puntuación 167.9926452870283\n",
      "Generación 58, x = 12.961197679498152 Mejor puntuación 167.9926452870283\n",
      "Generación 59, x = 12.961197679498152 Mejor puntuación 167.9926452870283\n",
      "Generación 60, x = 12.961197679498152 Mejor puntuación 167.9926452870283\n",
      "Generación 61, x = 12.961197679498152 Mejor puntuación 167.9926452870283\n",
      "Generación 62, x = 12.961197679498152 Mejor puntuación 177.86911148007036\n",
      "Generación 63, x = 13.148977793439215 Mejor puntuación 172.8956170123576\n",
      "Generación 64, x = 13.148977793439215 Mejor puntuación 191.70824045618826\n",
      "Generación 65, x = 13.845874492287884 Mejor puntuación 199.10011990913964\n",
      "Generación 66, x = 13.978079340906095 Mejor puntuación 199.10011990913964\n",
      "Generación 67, x = 14.110284189524307 Mejor puntuación 199.10011990913964\n",
      "Generación 68, x = 14.110284189524307 Mejor puntuación 199.10011990913964\n",
      "Generación 69, x = 14.110284189524307 Mejor puntuación 199.10011990913964\n",
      "Generación 70, x = 14.110284189524307 Mejor puntuación 199.10011990913964\n",
      "Generación 71, x = 14.110284189524307 Mejor puntuación 219.52943138233226\n",
      "Generación 72, x = 14.674575123627637 Mejor puntuación 219.52943138233226\n",
      "Generación 73, x = 14.728245439248077 Mejor puntuación 219.52943138233226\n",
      "Generación 74, x = 14.77238552851406 Mejor puntuación 229.45078745785068\n",
      "Generación 75, x = 15.981709623432456 Mejor puntuación 224.46270138476703\n",
      "Generación 76, x = 15.481894482295456 Mejor puntuación 255.41504248771358\n",
      "Generación 77, x = 15.481894482295456 Mejor puntuación 239.68905676093047\n",
      "Generación 78, x = 15.672186797007297 Mejor puntuación 257.0482548345101\n",
      "Generación 79, x = 15.672186797007297 Mejor puntuación 248.2928023711207\n",
      "Generación 80, x = 15.71474814362227 Mejor puntuación 248.2928023711207\n",
      "Generación 81, x = 16.161592328400186 Mejor puntuación 259.47932323863716\n",
      "Generación 82, x = 15.995135091945789 Mejor puntuación 261.19706658940373\n",
      "Generación 83, x = 16.030095598041953 Mejor puntuación 261.11489270339735\n",
      "Generación 84, x = 16.023441795024517 Mejor puntuación 258.47290264287466\n",
      "Generación 85, x = 16.026557126237343 Mejor puntuación 258.47290264287466\n",
      "Generación 86, x = 16.050267138016114 Mejor puntuación 265.60449874414337\n",
      "Generación 87, x = 16.125457287770782 Mejor puntuación 262.0265693705591\n",
      "Generación 88, x = 16.532455729265138 Mejor puntuación 285.0823902446067\n",
      "Generación 89, x = 16.535808897139088 Mejor puntuación 273.4329758827042\n",
      "Generación 90, x = 16.520411978943827 Mejor puntuación 273.4329758827042\n",
      "Generación 91, x = 16.535808897139088 Mejor puntuación 273.4329758827042\n",
      "Generación 92, x = 16.535808897139088 Mejor puntuación 288.96103117111784\n",
      "Generación 93, x = 16.76733135823701 Mejor puntuación 299.7504117965315\n",
      "Generación 94, x = 17.040316471955933 Mejor puntuación 299.77982804601726\n",
      "Generación 95, x = 17.497040707796216 Mejor puntuación 307.27679831184844\n",
      "Generación 96, x = 17.405595900034015 Mejor puntuación 307.27679831184844\n",
      "Generación 97, x = 17.858617438831978 Mejor puntuación 330.80051876702794\n",
      "Generación 98, x = 17.858617438831978 Mejor puntuación 318.93021682655365\n",
      "Generación 99, x = 17.856600448986143 Mejor puntuación 318.93021682655365\n",
      "Generación 100, x = 17.85760894390906 Mejor puntuación 318.93021682655365\n",
      "Generación 101, x = 17.09190631201495 Mejor puntuación 344.65910214788295\n",
      "Generación 102, x = 18.211302817603226 Mejor puntuación 335.01802717463715\n",
      "Generación 103, x = 18.25740024679205 Mejor puntuación 333.33266377156235\n",
      "Generación 104, x = 18.25740024679205 Mejor puntuación 354.7522375732121\n",
      "Generación 105, x = 18.546133924241296 Mejor puntuación 343.95908353589385\n",
      "Generación 106, x = 18.546133924241296 Mejor puntuación 343.95908353589385\n",
      "Generación 107, x = 18.546133924241296 Mejor puntuación 343.95908353589385\n",
      "Generación 108, x = 18.546133924241296 Mejor puntuación 343.95908353589385\n",
      "Generación 109, x = 19.285066074408206 Mejor puntuación 343.95908353589385\n",
      "Generación 110, x = 18.546133924241296 Mejor puntuación 371.91377349429035\n",
      "Generación 111, x = 18.969952740777806 Mejor puntuación 361.92419908123907\n",
      "Generación 112, x = 18.969952740777806 Mejor puntuación 359.8591069873434\n",
      "Generación 113, x = 19.383201638590343 Mejor puntuación 391.8994538402457\n",
      "Generación 114, x = 19.383201638590343 Mejor puntuación 375.7085057622514\n",
      "Generación 115, x = 19.383201638590343 Mejor puntuación 375.7085057622514\n",
      "Generación 116, x = 19.383201638590343 Mejor puntuación 375.7085057622514\n",
      "Generación 117, x = 19.383201638590343 Mejor puntuación 375.7085057622514\n",
      "Generación 118, x = 19.383201638590343 Mejor puntuación 375.7085057622514\n",
      "Generación 119, x = 19.383201638590343 Mejor puntuación 407.50900912862977\n",
      "Generación 120, x = 19.78502701074064 Mejor puntuación 399.6870575603668\n",
      "Generación 121, x = 19.83681398510739 Mejor puntuación 399.6870575603668\n",
      "Generación 122, x = 20.1228282567616 Mejor puntuación 416.26887687668307\n",
      "Generación 123, x = 20.055958044476558 Mejor puntuación 416.26887687668307\n",
      "Generación 124, x = 20.229313210430075 Mejor puntuación 411.56635604411207\n",
      "Generación 125, x = 20.229313210430075 Mejor puntuación 409.9558636293932\n",
      "Generación 126, x = 20.242853426604174 Mejor puntuación 409.9558636293932\n",
      "Generación 127, x = 20.24511012929986 Mejor puntuación 445.6657504837557\n",
      "Generación 128, x = 20.462096025659992 Mejor puntuación 427.62442913761953\n",
      "Generación 129, x = 20.930709552764206 Mejor puntuación 448.73921206643763\n",
      "Generación 130, x = 20.804331561718243 Mejor puntuación 438.0946023821748\n",
      "Generación 131, x = 20.930709552764206 Mejor puntuación 438.0946023821748\n",
      "Generación 132, x = 21.33511638315767 Mejor puntuación 438.0946023821748\n",
      "Generación 133, x = 20.930709552764206 Mejor puntuación 467.2965372202684\n",
      "Generación 134, x = 21.304496267067158 Mejor puntuación 461.2219935326096\n",
      "Generación 135, x = 21.440838770419447 Mejor puntuación 461.2219935326096\n",
      "Generación 136, x = 21.440838770419447 Mejor puntuación 461.2219935326096\n",
      "Generación 137, x = 22.25244088585921 Mejor puntuación 472.1684943431384\n",
      "Generación 138, x = 21.476079566173375 Mejor puntuación 495.1711253786587\n",
      "Generación 139, x = 22.05835055593775 Mejor puntuación 495.1711253786587\n",
      "Generación 140, x = 22.090020413513336 Mejor puntuación 501.9350273402234\n",
      "Generación 141, x = 22.29030729430137 Mejor puntuación 498.5473408998879\n",
      "Generación 142, x = 22.309240498522453 Mejor puntuación 498.5473408998879\n",
      "Generación 143, x = 22.31870710063299 Mejor puntuación 498.5473408998879\n",
      "Generación 144, x = 22.734251035954088 Mejor puntuación 535.9130072120777\n",
      "Generación 145, x = 23.144379036879343 Mejor puntuación 535.9130072120777\n",
      "Generación 146, x = 23.630043416968775 Mejor puntuación 535.66228100274\n",
      "Generación 147, x = 23.312884183197028 Mejor puntuación 558.3789518878293\n",
      "Generación 148, x = 23.630043416968775 Mejor puntuación 558.3789518878293\n",
      "Generación 149, x = 23.630043416968775 Mejor puntuación 558.3789518878293\n",
      "Generación 150, x = 23.59375488436047 Mejor puntuación 558.3789518878293\n",
      "Generación 151, x = 23.630043416968775 Mejor puntuación 558.3789518878293\n",
      "Generación 152, x = 23.630043416968775 Mejor puntuación 558.3789518878293\n",
      "Generación 153, x = 23.861749845788513 Mejor puntuación 558.3789518878293\n",
      "Generación 154, x = 23.630043416968775 Mejor puntuación 569.3831057029881\n",
      "Generación 155, x = 23.70031344072492 Mejor puntuación 599.7736174013692\n",
      "Generación 156, x = 24.02180258203133 Mejor puntuación 590.3786399392658\n",
      "Generación 157, x = 24.1180863039009 Mejor puntuación 586.0222974145709\n",
      "Generación 158, x = 24.39669837818021 Mejor puntuación 604.44677770214\n",
      "Generación 159, x = 24.37424559958232 Mejor puntuación 595.198891755901\n",
      "Generación 160, x = 24.603461713138337 Mejor puntuación 615.5472669371933\n",
      "Generación 161, x = 24.7068433806174 Mejor puntuación 615.5472669371933\n",
      "Generación 162, x = 24.989853267940145 Mejor puntuación 633.5027983638926\n",
      "Generación 163, x = 24.964007851070377 Mejor puntuación 641.5411727324577\n",
      "Generación 164, x = 24.418288340007678 Mejor puntuación 641.5411727324577\n",
      "Generación 165, x = 25.361396410017875 Mejor puntuación 649.1708904404683\n",
      "Generación 166, x = 25.40374763482842 Mejor puntuación 687.5146118997711\n",
      "Generación 167, x = 25.933530934887806 Mejor puntuación 678.8598010611418\n",
      "Generación 168, x = 25.858147862191473 Mejor puntuación 672.5480267507828\n",
      "Generación 169, x = 25.809146683294767 Mejor puntuación 668.6438108629575\n",
      "Generación 170, x = 25.48773699768179 Mejor puntuación 701.9409394136422\n",
      "Generación 171, x = 26.064354244696755 Mejor puntuación 691.4302443873914\n",
      "Generación 172, x = 26.235609580484983 Mejor puntuación 698.5379007272508\n",
      "Generación 173, x = 26.303012766235817 Mejor puntuación 698.5379007272508\n",
      "Generación 174, x = 26.34958938075623 Mejor puntuación 698.5379007272508\n",
      "Generación 175, x = 26.42986758815206 Mejor puntuación 698.5379007272508\n",
      "Generación 176, x = 26.42986758815206 Mejor puntuación 698.5379007272508\n",
      "Generación 177, x = 26.42986758815206 Mejor puntuación 698.5379007272508\n",
      "Generación 178, x = 26.640979330446175 Mejor puntuación 721.0347949787388\n",
      "Generación 179, x = 26.935942494056302 Mejor puntuación 741.5222229367296\n",
      "Generación 180, x = 26.127718460250286 Mejor puntuación 731.242633835296\n",
      "Generación 181, x = 26.98872042962983 Mejor puntuación 728.3910304287185\n",
      "Generación 182, x = 28.343314538846283 Mejor puntuación 780.3631858111733\n",
      "Generación 183, x = 27.14213706178331 Mejor puntuación 815.6626066568476\n",
      "Generación 184, x = 28.343314538846283 Mejor puntuación 809.4913255476474\n",
      "Generación 185, x = 28.343314538846283 Mejor puntuación 809.4913255476474\n",
      "Generación 186, x = 28.424499413852235 Mejor puntuación 809.4913255476474\n",
      "Generación 187, x = 28.431264820102733 Mejor puntuación 808.7215631549798\n",
      "Generación 188, x = 28.84415717889359 Mejor puntuación 855.9749476505218\n",
      "Generación 189, x = 28.847539882018836 Mejor puntuación 832.1805572446673\n",
      "Generación 190, x = 28.847539882018836 Mejor puntuación 832.1805572446673\n",
      "Generación 191, x = 29.015178399616886 Mejor puntuación 851.636803223686\n",
      "Generación 192, x = 29.015178399616886 Mejor puntuación 841.8805775615944\n",
      "Generación 193, x = 29.015178399616886 Mejor puntuación 841.8805775615944\n",
      "Generación 194, x = 29.015178399616886 Mejor puntuación 841.8805775615944\n",
      "Generación 195, x = 29.381081420217676 Mejor puntuación 863.2479454214604\n",
      "Generación 196, x = 29.289605665067477 Mejor puntuación 863.2479454214604\n",
      "Generación 197, x = 29.289605665067477 Mejor puntuación 863.2479454214604\n",
      "Generación 198, x = 29.289605665067477 Mejor puntuación 860.5623807648615\n",
      "Generación 199, x = 29.335343542642576 Mejor puntuación 860.5623807648615\n",
      "Mejor solución: x = 29.3239090732488, f(x) = 859.8916433361633\n"
     ]
    }
   ],
   "source": [
    "n_generations = 200\n",
    "\n",
    "for generation in range(n_generations):\n",
    "    scores = np.array([fitness(x) for x in population])\n",
    "    new_population = []\n",
    "    for _ in range(population_size):\n",
    "        parent1 = select_parent_tournament(population, scores)\n",
    "        parent2 = select_parent_tournament(population, scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        child = mutate(child)\n",
    "        new_population.append(child)\n",
    "    population = np.array(new_population)\n",
    "    best_score = np.max(scores)\n",
    "    print(f\"Generación {generation}, x = {child} Mejor puntuación {best_score}\")\n",
    "\n",
    "best_solution = population[np.argmax(scores)]\n",
    "print(f\"Mejor solución: x = {best_solution}, f(x) = {fitness(best_solution)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (MNIST)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicamos la máxima descendencia que queremos \n",
    "# uso 2 para simplemente comprobar que el algoritmo al completo funciona, este valor lo \n",
    "# indicará el usuario desde la interfaz\n",
    "max_desc = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS DEL DATASET DE PRUEBA\n",
    "\n",
    "num_channels = 1\n",
    "px_h = 28\n",
    "px_w = 28\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.Grayscale(num_output_channels=num_channels),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset de prueba (CIFAR100)\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DATOS DEL DATASET DE PRUEBA CIFAR 100\n",
    "num_channels = 3\n",
    "px_h = 32\n",
    "px_w = 32\n",
    "batch_size = 512\n",
    "num_classes = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparar los DataLoader para los conjuntos de entrenamiento y validación\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((px_h, px_w)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERACIÓN DE LA RED EN BASE A VECTORES\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprobamos si tenemos acceso a la GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU) está disponible en tu sistema.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA (GPU) está disponible en tu sistema.\")\n",
    "else:\n",
    "    print(\"CUDA (GPU) no está disponible en tu sistema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos una función que sea capaz de crear modelos en base a vectores que representen la arquitectura de la red.\n",
    "De este modo el algorimo evolutivo puede ir adaptando y cambiando la red fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def build_cnn_from_individual(individual):\n",
    "    \"\"\" \n",
    "    Funcion para construir un modelo en base a un diccionario\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    num_layers = individual['num_conv_layers']\n",
    "    fully_connected = int(individual['fully_connected'])\n",
    "    dropout = individual['dropout']\n",
    "    out_channels_previous_layer = num_channels # Imagen de entrada en escala de grises (1 canal para MNIST)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        out_channels = individual['filters'][i]\n",
    "        kernel_size = individual['filter_sizes'][i]\n",
    "        \n",
    "        conv_layer = nn.Conv2d(out_channels_previous_layer, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        layers.append(conv_layer)\n",
    "        layers.append(nn.ReLU())\n",
    "        if i < 2:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        else:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=1))\n",
    "\n",
    "\n",
    "        out_channels_previous_layer = out_channels\n",
    "\n",
    "\n",
    "    # Temporalmente crear un modelo para calcular el tamaño de salida de las capas convolucionales\n",
    "    temp_model = nn.Sequential(*layers)\n",
    "\n",
    "    # Calcular el tamaño de salida usando un tensor dummy\n",
    "    dummy_input = torch.zeros(1, num_channels, px_h, px_w)  # Tamaño de entrada para MNIST\n",
    "    output_size = temp_model(dummy_input).view(-1).shape[0]\n",
    "\n",
    "    # Ahora, sabiendo el tamaño de salida, podemos definir las capas lineales correctamente\n",
    "    layers.append(nn.Flatten())\n",
    "\n",
    "    for i in range(fully_connected):\n",
    "        layers.append(nn.Linear(in_features=output_size, out_features=output_size))\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            dropout-= 1\n",
    "\n",
    "    layers.append(nn.Linear(output_size, num_classes))  # Salida de 10 clases para MNIST\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para generar diccionarios para la población inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    \"\"\" \n",
    "    Funcion para generar un diccionario que representa a una arquitectura\n",
    "    \"\"\"\n",
    "    individual = {\n",
    "        'num_conv_layers': random.randint(min_conv_layers, max_conv_layers),\n",
    "        'filters': [],\n",
    "        'filter_sizes': [],\n",
    "        'learning_rate': random.uniform(lr_min, lr_max),\n",
    "        'fully_connected': random.randint(0,2),\n",
    "        'dropout': random.randint(0,2)\n",
    "    }\n",
    "\n",
    "    for _ in range(individual['num_conv_layers']):\n",
    "        individual['filters'].append(random.randint(min_filters, max_filters))\n",
    "        individual['filter_sizes'].append(random.choice(filter_sizes))\n",
    "    \n",
    "    # Agrega más parámetros según sea necesario, como capas completamente conectadas, etc.\n",
    "\n",
    "    return individual\n",
    "\n",
    "def initialize_population(pop_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max):\n",
    "    return [generate_individual(min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max) for _ in range(pop_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETROS PARA POSIBLES ARQUITECTURAS DE RED\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AJUSTAR SEGÚN VAYA NECESITANDO Y TIEMPO \n",
    "\n",
    "population_size = 5\n",
    "min_conv_layers = 1\n",
    "max_conv_layers = 3\n",
    "min_filters = 16\n",
    "max_filters = 128\n",
    "filter_sizes = [3, 5]\n",
    "lr_min = 0.0001\n",
    "lr_max = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num_conv_layers': 3,\n",
       "  'filters': [38, 44, 51],\n",
       "  'filter_sizes': [5, 3, 3],\n",
       "  'learning_rate': 0.008804088726204438,\n",
       "  'fully_connected': 1,\n",
       "  'dropout': 2},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [22, 33, 23],\n",
       "  'filter_sizes': [3, 3, 5],\n",
       "  'learning_rate': 0.006266445364796719,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [82, 102, 90],\n",
       "  'filter_sizes': [5, 5, 5],\n",
       "  'learning_rate': 0.001575109008157176,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 2},\n",
       " {'num_conv_layers': 2,\n",
       "  'filters': [67, 16],\n",
       "  'filter_sizes': [3, 5],\n",
       "  'learning_rate': 0.009162266907092887,\n",
       "  'fully_connected': 1,\n",
       "  'dropout': 1},\n",
       " {'num_conv_layers': 3,\n",
       "  'filters': [53, 32, 76],\n",
       "  'filter_sizes': [5, 3, 5],\n",
       "  'learning_rate': 0.0023590770845924934,\n",
       "  'fully_connected': 0,\n",
       "  'dropout': 1}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "population = initialize_population(population_size, min_conv_layers, max_conv_layers, min_filters, max_filters, filter_sizes, lr_min, lr_max)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO Y EVALUACIÓN DE LOS MODELOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def evaluate_individual(individual, train_loader, val_loader, device='cuda', epochs=5):\n",
    "    \"\"\" \n",
    "    Funcion para entrenar y evaluar una arquitectura\n",
    "    \"\"\"\n",
    "    # Construir el modelo basado en el individuo\n",
    "    model = build_cnn_from_individual(individual).to(device)\n",
    "    \n",
    "    # Definir el optimizador y la función de pérdida\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=individual['learning_rate'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch')\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Actualizar la barra de progreso con la última información de pérdida\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item())})\n",
    "            progress_bar.update()  # Forzar la actualización de la barra de progreso\n",
    "            \n",
    "        progress_bar.close()  # Cerrar la barra de progreso al final de cada época\n",
    "\n",
    "    # Evaluación\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy  # Esta es la \"aptitud\" del individuo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUTACIONES Y CRUCES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def mutate_individual(individual):\n",
    "    \"\"\"\n",
    "    Mutar un individuo cambiando aleatoriamente sus hiperparámetros.\n",
    "    \"\"\"\n",
    "    mutation_rate = 0.3  # Probabilidad de mutar cada característica\n",
    "    lr_range = (0.0001, 0.01)\n",
    "    filter_range = (32, 128)  # Rango para el número de filtros\n",
    "    filter_size_range = (1, 7)  # Rango para el tamaño de filtro\n",
    "    fully_connected_range = (0,2) #Rango para ver cuantas fully conected se añaden\n",
    "    dropout_range = (0,2) # Rango para ver cuantos dropouts se añaden\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['learning_rate'] = random.uniform(*lr_range)\n",
    "\n",
    "    # Asegurarse de que hay suficientes entradas en las listas 'filters' y 'filter_sizes'\n",
    "    for i in range(individual['num_conv_layers']):\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el número de filtros en la capa i\n",
    "            individual['filters'][i] = random.randint(*filter_range)\n",
    "        if random.random() < mutation_rate:\n",
    "            # Mutar el tamaño de filtro en la capa i\n",
    "            individual['filter_sizes'][i] = random.randint(*filter_size_range)\n",
    "\n",
    "    if random.random() < mutation_rate:\n",
    "        # Mutar la tasa de aprendizaje\n",
    "        individual['fully_connected'] = random.uniform(*fully_connected_range)\n",
    "\n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el cruce entre individuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    \"\"\"\n",
    "    Realiza un cruce uniforme entre dos individuos.\n",
    "    \n",
    "    Args:\n",
    "        parent1 (dict): El primer individuo padre.\n",
    "        parent2 (dict): El segundo individuo padre.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un nuevo individuo hijo.\n",
    "    \"\"\"\n",
    "    child = {}\n",
    "    print(f\"Padre 1: {parent1} --- Padre 2: {parent2}\")\n",
    "    for key in parent1:\n",
    "        if key == \"filters\" or key == \"filter_sizes\":\n",
    "            if random.random() < 0.5:\n",
    "                child[\"filters\"] = parent1[\"filters\"]\n",
    "                child[\"filter_sizes\"] = parent1[\"filter_sizes\"]\n",
    "            else:\n",
    "                child[\"filters\"] = parent2[\"filters\"]\n",
    "                child[\"filter_sizes\"] = parent2[\"filter_sizes\"]\n",
    "\n",
    "        else:\n",
    "            if key != \"num_conv_layers\":\n",
    "                if random.random() < 0.5:\n",
    "                    child[key] = parent1[key]\n",
    "                else:\n",
    "                    child[key] = parent2[key]\n",
    "    child[\"num_conv_layers\"] = len(child[\"filters\"])\n",
    "\n",
    "    return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos como evaluamos a la población "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population, train_loader, val_loader, device):\n",
    "    \"\"\"\n",
    "    Funcion para evaluar a una poblacion de arquitecturas\n",
    "    \"\"\"\n",
    "    fitness_scores = []\n",
    "    \n",
    "    for individual in population:\n",
    "        print(individual)\n",
    "        fitness = evaluate_individual(individual, train_loader, val_loader, device)\n",
    "        fitness_scores.append(fitness)\n",
    "    \n",
    "    # sacamos los scores de la poblacion\n",
    "    return fitness_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recopilamos lo que hemos realizado, hemos creado las posibles mutaciones sobre las arquitecturas, los posibles cruces, la evaluación de los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queda realizar:\n",
    "- Selección de reproducción: por torneo en principio para también  puede ser por torneo o ruleta\n",
    "- Creación de la nueva generación usando las funciones de mutación y cruces\n",
    "- Criterios de parada\n",
    "- Registro de análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección por torneo\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection_best4(population):\n",
    "    \"\"\"\n",
    "    Selecciona los 4 mejores individuos de la población mediante un torneo de tamaño fijo.\n",
    "\n",
    "    Args:\n",
    "        population: La lista de individuos con sus puntuaciones de fitness.\n",
    "\n",
    "    Returns:\n",
    "        Lista de los 4 mejores individuos.\n",
    "    \"\"\"\n",
    "    winners = []\n",
    "    for _ in range(2):\n",
    "        candidates = random.sample(population, 2)\n",
    "        winner = max(candidates, key=lambda x: x['fitness'])\n",
    "        winners.append(winner)\n",
    "    return winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITMO EVOLUTIVO\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfitness_scores = evaluate_population(population, train_loader, val_loader, device)\\n\\n# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\\npopulation_with_scores = list(zip(population, fitness_scores))\\npopulation_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\\n\\n# Imprimimimos los resultados\\nfor i, (individual, score) in enumerate(population_with_scores):\\n    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fitness_scores = evaluate_population(population, train_loader, val_loader, device)\n",
    "\n",
    "# Almacenamos- los individuos y sus puntuaciones en una lista de tuplas y ordenarlos\n",
    "population_with_scores = list(zip(population, fitness_scores))\n",
    "population_with_scores.sort(key=lambda x: x[1], reverse=True)  # Ordena de mayor a menor aptitud\n",
    "\n",
    "# Imprimimimos los resultados\n",
    "for i, (individual, score) in enumerate(population_with_scores):\n",
    "    print(f\"Descendecia: {i} Individuo {individual}: Pérdida: {score}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = []\n",
    "\n",
    "def genetic_algorithm(population, train_loader, val_loader, device, max_desc):\n",
    "    \"\"\" \n",
    "    Algoritmo genetico para evolucionar una poblacion de arquitecturas hacia la mejor puntuacion dado un dataset dado\n",
    "    \"\"\"\n",
    "    desc = 0\n",
    "    while desc < max_desc:\n",
    "        print(\"***************************************\")\n",
    "        print()\n",
    "        print(f\"Generation: {desc}\")\n",
    "        print()\n",
    "        print(\"***************************************\")\n",
    "        puntuaciones_aptitud = evaluate_population(population, train_loader, val_loader, device)\n",
    "\n",
    "        # Ordenamos individuos\n",
    "        # Añadimos las puntuaciones directamente a cada diccionario de la población\n",
    "        for i, puntuacion in enumerate(puntuaciones_aptitud):\n",
    "            population[i]['fitness'] = puntuacion\n",
    "\n",
    "        population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "\n",
    "        # Preservamos el mejor individuo (elitismo)\n",
    "        mejor_individuo = population[0]\n",
    "        top_models.append(mejor_individuo)\n",
    "        # Seleccionamos los 4 mejores (excluyendo el mejor) para el torneo\n",
    "        winners = tournament_selection_best4(population[1:])\n",
    "        print(f\"Los 4 mejores son: \\n {winners}\")\n",
    "\n",
    "        # Realizamos cruce y mutación con descendientes que reemplazan a la población restante\n",
    "        for i in range(1, 2):\n",
    "            descendency = mutate_individual(crossover(winners[i-1], winners[i]))\n",
    "            population[-i] = descendency   # Eliminamos las peores arquitecturas\n",
    "\n",
    "        # Nos aseguramos que mantenemos el mejor de todos\n",
    "        population[0] = mejor_individuo\n",
    "        desc += 1\n",
    "\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTADOS DE LAS ARQUITECTURAS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padre 1: {'num_conv_layers': 3, 'filters': [22, 33, 23], 'filter_sizes': [3, 3, 5], 'learning_rate': 0.006266445364796719, 'fully_connected': 0, 'dropout': 1} --- Padre 2: {'num_conv_layers': 3, 'filters': [82, 102, 90], 'filter_sizes': [5, 5, 5], 'learning_rate': 0.001575109008157176, 'fully_connected': 0, 'dropout': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'filters': [82, 102, 90],\n",
       " 'filter_sizes': [6, 5, 5],\n",
       " 'learning_rate': 0.007185554079114625,\n",
       " 'fully_connected': 0,\n",
       " 'dropout': 2,\n",
       " 'num_conv_layers': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = crossover(population[1], population[2])\n",
    "mutate = mutate_individual(sol)\n",
    "mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n",
      "\n",
      "Generation: 0\n",
      "\n",
      "***************************************\n",
      "{'num_conv_layers': 3, 'filters': [38, 44, 51], 'filter_sizes': [5, 3, 3], 'learning_rate': 0.008804088726204438, 'fully_connected': 1, 'dropout': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:11<00:00,  8.67batch/s, training_loss=4.613]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  8.00batch/s, training_loss=4.607]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  7.99batch/s, training_loss=4.606]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  7.92batch/s, training_loss=4.615]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  8.05batch/s, training_loss=4.621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [22, 33, 23], 'filter_sizes': [3, 3, 5], 'learning_rate': 0.006266445364796719, 'fully_connected': 0, 'dropout': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  7.98batch/s, training_loss=3.658]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  7.86batch/s, training_loss=3.346]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:11<00:00,  8.19batch/s, training_loss=3.065]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  7.92batch/s, training_loss=2.859]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:11<00:00,  8.19batch/s, training_loss=2.659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [82, 102, 90], 'filter_sizes': [6, 5, 5], 'learning_rate': 0.001575109008157176, 'fully_connected': 0, 'dropout': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  7.54batch/s, training_loss=3.325]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  7.69batch/s, training_loss=2.932]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  7.65batch/s, training_loss=2.569]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  7.77batch/s, training_loss=2.502]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  7.69batch/s, training_loss=2.414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 2, 'filters': [67, 16], 'filter_sizes': [3, 5], 'learning_rate': 0.009162266907092887, 'fully_connected': 1, 'dropout': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  7.81batch/s, training_loss=4.609]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  7.78batch/s, training_loss=4.609]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  7.73batch/s, training_loss=4.613]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  7.76batch/s, training_loss=4.616]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  7.81batch/s, training_loss=4.600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [53, 32, 76], 'filter_sizes': [5, 3, 5], 'learning_rate': 0.0023590770845924934, 'fully_connected': 0, 'dropout': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  7.85batch/s, training_loss=3.505]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  7.91batch/s, training_loss=2.956]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  7.89batch/s, training_loss=2.727]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  7.94batch/s, training_loss=2.439]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  8.11batch/s, training_loss=2.293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 4 mejores son: \n",
      " [{'num_conv_layers': 2, 'filters': [67, 16], 'filter_sizes': [3, 5], 'learning_rate': 0.009162266907092887, 'fully_connected': 1, 'dropout': 1, 'fitness': 0.01}, {'num_conv_layers': 3, 'filters': [53, 32, 76], 'filter_sizes': [5, 3, 5], 'learning_rate': 0.0023590770845924934, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.3504}]\n",
      "Padre 1: {'num_conv_layers': 2, 'filters': [67, 16], 'filter_sizes': [3, 5], 'learning_rate': 0.009162266907092887, 'fully_connected': 1, 'dropout': 1, 'fitness': 0.01} --- Padre 2: {'num_conv_layers': 3, 'filters': [53, 32, 76], 'filter_sizes': [5, 3, 5], 'learning_rate': 0.0023590770845924934, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.3504}\n",
      "***************************************\n",
      "\n",
      "Generation: 1\n",
      "\n",
      "***************************************\n",
      "{'num_conv_layers': 3, 'filters': [82, 102, 90], 'filter_sizes': [6, 5, 5], 'learning_rate': 0.001575109008157176, 'fully_connected': 0, 'dropout': 2, 'fitness': 0.3708}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:13<00:00,  7.52batch/s, training_loss=3.432]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  7.65batch/s, training_loss=2.794]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  7.74batch/s, training_loss=2.646]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  7.84batch/s, training_loss=2.371]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  7.71batch/s, training_loss=2.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [53, 46, 76], 'filter_sizes': [7, 3, 2], 'learning_rate': 0.0023590770845924934, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.3504}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  7.94batch/s, training_loss=3.265]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  7.94batch/s, training_loss=2.782]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  7.97batch/s, training_loss=2.512]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  7.96batch/s, training_loss=2.104]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  7.99batch/s, training_loss=1.865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [22, 33, 23], 'filter_sizes': [3, 3, 5], 'learning_rate': 0.006266445364796719, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.2849}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  8.14batch/s, training_loss=3.783]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  8.07batch/s, training_loss=3.247]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  8.04batch/s, training_loss=3.249]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:10<00:00,  9.21batch/s, training_loss=2.908]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  8.15batch/s, training_loss=3.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_conv_layers': 3, 'filters': [38, 44, 51], 'filter_sizes': [5, 3, 3], 'learning_rate': 0.008804088726204438, 'fully_connected': 1, 'dropout': 2, 'fitness': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  7.85batch/s, training_loss=4.623]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  7.70batch/s, training_loss=4.618]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  7.91batch/s, training_loss=4.626]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  7.96batch/s, training_loss=4.622]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  8.08batch/s, training_loss=4.590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filters': [53, 46, 76], 'filter_sizes': [7, 3, 2], 'learning_rate': 0.0023590770845924934, 'fully_connected': 1, 'dropout': 1, 'fitness': 0.3504, 'num_conv_layers': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [00:12<00:00,  7.80batch/s, training_loss=3.544]\n",
      "Epoch 2/5: 100%|██████████| 98/98 [00:12<00:00,  7.94batch/s, training_loss=3.013]\n",
      "Epoch 3/5: 100%|██████████| 98/98 [00:12<00:00,  7.96batch/s, training_loss=2.981]\n",
      "Epoch 4/5: 100%|██████████| 98/98 [00:12<00:00,  8.02batch/s, training_loss=2.674]\n",
      "Epoch 5/5: 100%|██████████| 98/98 [00:12<00:00,  8.00batch/s, training_loss=2.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 4 mejores son: \n",
      " [{'filters': [53, 46, 76], 'filter_sizes': [7, 3, 2], 'learning_rate': 0.0023590770845924934, 'fully_connected': 1, 'dropout': 1, 'fitness': 0.3345, 'num_conv_layers': 3}, {'num_conv_layers': 3, 'filters': [22, 33, 23], 'filter_sizes': [3, 3, 5], 'learning_rate': 0.006266445364796719, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.2651}]\n",
      "Padre 1: {'filters': [53, 46, 76], 'filter_sizes': [7, 3, 2], 'learning_rate': 0.0023590770845924934, 'fully_connected': 1, 'dropout': 1, 'fitness': 0.3345, 'num_conv_layers': 3} --- Padre 2: {'num_conv_layers': 3, 'filters': [22, 33, 23], 'filter_sizes': [3, 3, 5], 'learning_rate': 0.006266445364796719, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.2651}\n"
     ]
    }
   ],
   "source": [
    "population_sol = genetic_algorithm(population, train_loader, val_loader, device, max_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuo {'num_conv_layers': 3, 'filters': [82, 102, 90], 'filter_sizes': [6, 5, 5], 'learning_rate': 0.001575109008157176, 'fully_connected': 0, 'dropout': 2, 'fitness': 0.362} \n",
      "Individuo {'num_conv_layers': 3, 'filters': [53, 46, 76], 'filter_sizes': [7, 3, 2], 'learning_rate': 0.0023590770845924934, 'fully_connected': 0, 'dropout': 1, 'fitness': 0.387} \n"
     ]
    }
   ],
   "source": [
    "for individual in top_models:\n",
    "    print(f\"Individuo {individual} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
